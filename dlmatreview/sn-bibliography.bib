@book{callister2021materials,
  title={Materials science and engineering: an introduction},
  author={Callister, William D and Rethwisch, David G and Blicblau, A and Bruggeman, K and Cortie, M and Long, John and Hart, J and Marceau, Ross and Ryan, M and Parvizi, Reza and others},
  year={2021},
  publisher={wiley}
}
@article{kusche2019large,
  title={Large-area, high-resolution characterisation and classification of damage mechanisms in dual-phase steel using deep learning},
  author={Kusche, Carl and Reclik, Tom and Freund, Martina and Al-Samman, Talal and Kerzel, Ulrich and Korte-Kerzel, Sandra},
  journal={PloS one},
  volume={14},
  number={5},
  pages={e0216493},
  year={2019},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{Grazulis2009,
author = "Gra{\v{z}}ulis, Saulius and Chateigner, Daniel and Downs, Robert T. and Yokochi, A. F. T. and Quir{\'{o}}s, Miguel and Lutterotti, Luca and Manakova, Elena and Butkus, Justas and Moeck, Peter and Le Bail, Armel",
title = "{Crystallography Open Database {--} an open-access collection of crystal structures}",
journal = "Journal of Applied Crystallography",
year = "2009",
volume = "42",
number = "4",
pages = "726--729",
month = "Aug",
doi = {10.1107/S0021889809016690},
url = {http://dx.doi.org/10.1107/S0021889809016690},
}
@article{aversa2018first,
  title={The first annotated set of scanning electron microscopy images for nanoscience},
  author={Aversa, Rossella and Modarres, Mohammad Hadi and Cozzini, Stefano and Ciancio, Regina and Chiusole, Alberto},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}

@misc{schlichtkrull2017modeling,
      title={Modeling Relational Data with Graph Convolutional Networks}, 
      author={Michael Schlichtkrull and Thomas N. Kipf and Peter Bloem and Rianne van den Berg and Ivan Titov and Max Welling},
      year={2017},
      eprint={1703.06103},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{yao2018tensormol,
  title={The TensorMol-0.1 model chemistry: a neural network augmented with long-range physics},
  author={Yao, Kun and Herr, John E and Toth, David W and Mckintyre, Ryker and Parkhill, John},
  journal={Chemical science},
  volume={9},
  number={8},
  pages={2261--2269},
  year={2018},
  publisher={Royal Society of Chemistry}
}
@article{LiDeepChemStable2019,
author = {Li, Xiuming and Yan, Xin and Gu, Qiong and Zhou, Huihao and Wu, Di and Xu, Jun},
title = {DeepChemStable: Chemical Stability Prediction with an Attention-Based Graph Convolution Network},
journal = {Journal of Chemical Information and Modeling},
volume = {59},
number = {3},
pages = {1044-1049},
year = {2019},
doi = {10.1021/acs.jcim.8b00672},
    note ={PMID: 30764613},

URL = { 
        https://doi.org/10.1021/acs.jcim.8b00672
    
},
eprint = { 
        https://doi.org/10.1021/acs.jcim.8b00672
    
}
}

@article{oboyle_dalke_2018, place={Cambridge}, title={DeepSMILES: An Adaptation of SMILES for Use in Machine-Learning of Chemical Structures}, DOI={10.26434/chemrxiv.7097960.v1}, journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={O'Boyle, Noel and Dalke, Andrew}, year={2018}} This content is a preprint and has not been peer-reviewed.

@article{green2021deepfrag,
  title={DeepFrag: a deep convolutional neural network for fragment-based lead optimization},
  author={Green, Harrison and Koes, David Ryan and Durrant, Jacob D},
  journal={Chemical Science},
  year={2021},
  publisher={Royal Society of Chemistry}
}


@article{acquarelliConvolutionalNeuralNetworks2017,
  title = {Convolutional Neural Networks for Vibrational Spectroscopic Data Analysis},
  author = {Acquarelli, Jacopo and {van Laarhoven}, Twan and Gerretzen, Jan and Tran, Thanh N. and Buydens, Lutgarde M. C. and Marchiori, Elena},
  year = {2017},
  month = feb,
  journal = {Analytica Chimica Acta},
  volume = {954},
  pages = {22--31},
  issn = {0003-2670},
  doi = {10.1016/j.aca.2016.12.010},
  abstract = {In this work we show that convolutional neural networks (CNNs) can be efficiently used to classify vibrational spectroscopic data and identify important spectral regions. CNNs are the current state-of-the-art in image classification and speech recognition and can learn interpretable representations of the data. These characteristics make CNNs a good candidate for reducing the need for preprocessing and for highlighting important spectral regions, both of which are crucial steps in the analysis of vibrational spectroscopic data. Chemometric analysis of vibrational spectroscopic data often relies on preprocessing methods involving baseline correction, scatter correction and noise removal, which are applied to the spectra prior to model building. Preprocessing is a critical step because even in simple problems using `reasonable' preprocessing methods may decrease the performance of the final model. We develop a new CNN based method and provide an accompanying publicly available software. It is based on a simple CNN architecture with a single convolutional layer (a so-called shallow CNN). Our method outperforms standard classification algorithms used in chemometrics (e.g. PLS) in terms of accuracy when applied to non-preprocessed test data (86\% average accuracy compared to the 62\% achieved by PLS), and it achieves better performance even on preprocessed test data (96\% average accuracy compared to the 89\% achieved by PLS). For interpretability purposes, our method includes a procedure for finding important spectral regions, thereby facilitating qualitative interpretation of results.},
  language = {en},
  keywords = {Convolutional neural networks,Preprocessing,Vibrational spectroscopy},
  file = {/Users/chichen/Zotero/storage/7HHXFA9L/Acquarelli et al. - 2017 - Convolutional neural networks for vibrational spec.pdf;/Users/chichen/Zotero/storage/V7FI97ZW/S0003267016314842.html}
}

@article{aguiarCrystallographicPredictionDiffraction2020,
  title = {Crystallographic Prediction from Diffraction and Chemistry Data for Higher Throughput Classification Using Machine Learning},
  author = {Aguiar, Jeffery A. and Gong, Matthew L. and Tasdizen, Tolga},
  year = {2020},
  month = feb,
  journal = {Computational Materials Science},
  volume = {173},
  pages = {109409},
  issn = {0927-0256},
  doi = {10.1016/j.commatsci.2019.109409},
  abstract = {Simultaneously capturing material structure and chemistry in the form of accessible data is often advantageous for drawing correlations and enhancing our understanding of measurable materials behavior and properties. Unfortunately, in many cases, accessing data at the scale required, is highly multidimensional and sparse by the historical and evolving nature of materials science. To mitigate difficulties, we develop and employ methods of data analytics in conjunction with open accessible chemistry and structure datasets, to classify and reduce the amount of data needed for extracting useful descriptors from multidimensional techniques. The construction and systematic ablation of our model highlights the potential for dimensional reduction in data sampling, improved classification, and identification of correlations among material crystallography and chemistry.},
  language = {en},
  keywords = {Data analytics,Machine learning,Material informatics,Materials discovery,Microscopy},
  file = {/Users/chichen/Zotero/storage/M4Q3PAK5/Aguiar et al. - 2020 - Crystallographic prediction from diffraction and c.pdf}
}

@article{bankoDeepLearningVisualization2021,
  title = {Deep Learning for Visualization and Novelty Detection in Large {{X}}-Ray Diffraction Datasets},
  author = {Banko, Lars and Maffettone, Phillip M. and Naujoks, Dennis and Olds, Daniel and Ludwig, Alfred},
  year = {2021},
  month = apr,
  journal = {arXiv:2104.04392 [cond-mat, physics:physics]},
  eprint = {2104.04392},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, physics:physics},
  abstract = {We apply variational autoencoders (VAE) to X-ray diffraction (XRD) data analysis on both simulated and experimental thin-film data. We show that crystal structure representations learned by a VAE reveal latent information, such as the structural similarity of textured diffraction patterns. While other artificial intelligence (AI) agents are effective at classifying XRD data into known phases, a similarly conditioned VAE is uniquely effective at knowing what it does not know, rapidly identifying novel phases and mixtures. These capabilities demonstrate that a VAE is a valuable AI agent for materials discovery and understanding XRD measurements both on-the-fly and during post hoc analysis.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Materials Science,Physics - Data Analysis; Statistics and Probability},
  file = {/Users/chichen/Zotero/storage/QJ8CCVLT/Banko et al. - 2021 - Deep learning for visualization and novelty detect.pdf;/Users/chichen/Zotero/storage/846W3UIG/2104.html}
}

@article{bankoDeepLearningVisualization2021a,
  title = {Deep Learning for Visualization and Novelty Detection in Large {{X}}-Ray Diffraction Datasets},
  author = {Banko, Lars and Maffettone, Phillip M. and Naujoks, Dennis and Olds, Daniel and Ludwig, Alfred},
  year = {2021},
  month = jul,
  journal = {npj Computational Materials},
  volume = {7},
  number = {1},
  pages = {1--6},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-021-00575-9},
  abstract = {We apply variational autoencoders (VAE) to X-ray diffraction (XRD) data analysis on both simulated and experimental thin-film data. We show that crystal structure representations learned by a VAE reveal latent information, such as the structural similarity of textured diffraction patterns. While other artificial intelligence (AI) agents are effective at classifying XRD data into known phases, a similarly conditioned VAE is uniquely effective at knowing what it doesn't know: it can rapidly identify data outside the distribution it was trained on, such as novel phases and mixtures. These capabilities demonstrate that a VAE is a valuable AI agent for aiding materials discovery and understanding XRD measurements both `on-the-fly' and during post hoc analysis.},
  copyright = {2021 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods Subject\_term\_id: characterization-and-analytical-techniques;computational-methods},
  file = {/Users/chichen/Zotero/storage/N9LEBMZM/Banko et al. - 2021 - Deep learning for visualization and novelty detect.pdf;/Users/chichen/Zotero/storage/DMDEYFI4/s41524-021-00575-9.html}
}

@article{carboneMachineLearningXRayAbsorption2020a,
  title = {Machine-{{Learning X}}-{{Ray Absorption Spectra}} to {{Quantitative Accuracy}}},
  author = {Carbone, Matthew R. and Topsakal, Mehmet and Lu, Deyu and Yoo, Shinjae},
  year = {2020},
  month = apr,
  journal = {Physical Review Letters},
  volume = {124},
  number = {15},
  pages = {156401},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.124.156401},
  abstract = {Simulations of excited state properties, such as spectral functions, are often computationally expensive and therefore not suitable for high-throughput modeling. As a proof of principle, we demonstrate that graph-based neural networks can be used to predict the x-ray absorption near-edge structure spectra of molecules to quantitative accuracy. Specifically, the predicted spectra reproduce nearly all prominent peaks, with 90\% of the predicted peak locations within 1 eV of the ground truth. Besides its own utility in spectral analysis and structure inference, our method can be combined with structure search algorithms to enable high-throughput spectrum sampling of the vast material configuration space, which opens up new pathways to material design and discovery.},
  file = {/Users/chichen/Zotero/storage/ALUJBWKD/Carbone et al. - 2020 - Machine-Learning X-Ray Absorption Spectra to Quant.pdf;/Users/chichen/Zotero/storage/2BU7A3E2/PhysRevLett.124.html}
}

@misc{andrejevic2020machine,
      title={Machine learning spectral indicators of topology}, 
      author={Nina Andrejevic and Jovana Andrejevic and Chris H. Rycroft and Mingda Li},
      year={2020},
      eprint={2003.00994},
      archivePrefix={arXiv},
      primaryClass={cond-mat.dis-nn}
}

@article{stein_soedarmadji_newhouse_guevarra_gregoire_2019, title={Synthesis, optical imaging, and absorption spectroscopy data for 179072 metal oxides}, volume={6}, DOI={10.1038/s41597-019-0019-4}, number={1}, journal={Scientific Data}, author={Stein, Helge S. and Soedarmadji, Edwin and Newhouse, Paul F. and Guevarra, Dan and Gregoire, John M.}, year={2019}}


@article{jainAtomicpositionIndependentDescriptor2018,
  title = {Atomic-Position Independent Descriptor for Machine Learning of Material Properties},
  author = {Jain, Ankit and Bligaard, Thomas},
  year = {2018},
  month = dec,
  journal = {Physical Review B},
  volume = {98},
  number = {21},
  pages = {214112},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevB.98.214112},
  abstract = {The high-throughput screening of periodic inorganic solids using machine learning methods requires atomic positions to encode structural and compositional details into appropriate material descriptors. These atomic positions are not available a priori for new materials, which severely limits exploration of novel materials. We overcome this limitation by using only crystallographic symmetry information in the structural description of materials. We show that for materials with identical structural symmetry, machine learning is trivial, and accuracies similar to that of density functional theory calculations can be achieved by using only atomic numbers in the material description. For machine learning of formation energies of bulk crystalline solids, this simple material descriptor is able to achieve prediction mean absolute errors of only 0.07 eV/at on a test dataset consisting of more than 85 000 diverse materials. This atomic-position independent material descriptor presents a new route of materials discovery wherein millions of materials can be screened by training a machine learning model over a drastically reduced subspace of materials.},
  file = {/Users/chichen/Zotero/storage/UZHUS3LE/Jain and Bligaard - 2018 - Atomic-position independent descriptor for machine.pdf;/Users/chichen/Zotero/storage/CQII5BNL/PhysRevB.98.html}
}

@misc{goodall2021rapid,
      title={Rapid Discovery of Novel Materials by Coordinate-free Coarse Graining}, 
      author={Rhys E. A. Goodall and Abhijith S. Parackal and Felix A. Faber and Rickard Armiento and Alpha A. Lee},
      year={2021},
      eprint={2106.11132},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci}
}


@article{zuoAcceleratingMaterialsDiscovery2021,
  title = {Accelerating {{Materials Discovery}} with {{Bayesian Optimization}} and {{Graph Deep Learning}}},
  author = {Zuo, Yunxing and Qin, Mingde and Chen, Chi and Ye, Weike and Li, Xiangguo and Luo, Jian and Ong, Shyue Ping},
  year = {2021},
  month = apr,
  journal = {arXiv:2104.10242 [cond-mat]},
  eprint = {2104.10242},
  eprinttype = {arxiv},
  primaryclass = {cond-mat},
  abstract = {Machine learning (ML) models utilizing structure-based features provide an efficient means for accurate property predictions across diverse chemical spaces. However, obtaining equilibrium crystal structures typically requires expensive density functional theory (DFT) calculations, which limits ML-based exploration to either known crystals or a small number of hypothetical crystals. Here, we demonstrate that the application of Bayesian optimization with symmetry constraints using a graph deep learning energy model can be used to perform "DFT-free" relaxations of crystal structures. Using this approach to significantly improve the accuracy of ML-predicted formation energies and elastic moduli of hypothetical crystals, two novel ultra-incompressible hard materials MoWC2 (P63/mmc) and ReWB (Pca21) were identified and successfully synthesized via in-situ reactive spark plasma sintering from a screening of 399,960 transition metal borides and carbides. This work addresses a critical bottleneck to accurate property predictions for hypothetical materials, paving the way to ML-accelerated discovery of new materials with exceptional properties.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Materials Science},
  file = {/Users/chichen/Zotero/storage/MAFKUDF9/Zuo et al. - 2021 - Accelerating Materials Discovery with Bayesian Opt.pdf;/Users/chichen/Zotero/storage/33GH8CYX/2104.html}
}



@article{hammer_norskov_2000, title={Theoretical surface science and catalysis—calculations and concepts}, DOI={10.1016/s0360-0564(02)45013-4}, journal={Advances in Catalysis Impact of Surface Science on Catalysis}, author={Hammer, B. and Nørskov, J.k.}, year={2000}, pages={71–129}}

@article{kostka_selzer_gasteiger_2001, title={A Combined Application of Reaction Prediction and Infrared Spectra Simulation for the Identification of Degradation Products of s-Triazine Herbicides}, volume={7}, DOI={}, number={10}, journal={Chemistry}, author={Kostka, Thomas and Selzer, Paul and Gasteiger, Johann}, year={2001}, pages={2254–2260}}


@article{ghosh_rinke_2019, title={Deep Learning Spectroscopy: Neural Networks for Molecular Excitation Spectra}, volume={6}, DOI={10.1002/advs.201801367}, number={9}, journal={Advanced Science}, author={Ghosh, Kunal and Stuke, Annika and Todorović, Milica and Jørgensen, Peter Bjørn and Schmidt, Mikkel N. and Vehtari, Aki and Rinke, Patrick}, year={2019}, pages={1801367}}


@article{selzer_gasteiger_thomas_salzer_2000, title={Rapid Access to Infrared Reference Spectra of Arbitrary Organic Compounds: Scope and Limitations of an Approach to the Simulation of Infrared Spectra by Neural Networks}, volume={6}, DOI={10.1002/(sici)1521-3765(20000303)6:5<920::aid-chem920>3.0.co;2-w}, number={5}, journal={Chemistry - A European Journal}, author={Selzer, Paul and Gasteiger, Johann and Thomas, Henrik and Salzer, Reiner}, year={2000}, pages={920–927}}

@article{chenDirectPredictionPhonon2021,
  title = {Direct Prediction of Phonon Density of States with {{Euclidean}} Neural Networks},
  author = {Chen, Zhantao and Andrejevic, Nina and Smidt, Tess and Ding, Zhiwei and Chi, Yen-Ting and Nguyen, Quynh T. and Alatas, Ahmet and Kong, Jing and Li, Mingda},
  year = {2021},
  month = jun,
  journal = {Advanced Science},
  volume = {8},
  number = {12},
  eprint = {2009.05163},
  eprinttype = {arxiv},
  pages = {2004214},
  issn = {2198-3844, 2198-3844},
  doi = {10.1002/advs.202004214},
  abstract = {Machine learning has demonstrated great power in materials design, discovery, and property prediction. However, despite the success of machine learning in predicting discrete properties, challenges remain for continuous property prediction. The challenge is aggravated in crystalline solids due to crystallographic symmetry considerations and data scarcity. Here we demonstrate the direct prediction of phonon density of states using only atomic species and positions as input. We apply Euclidean neural networks, which by construction are equivariant to 3D rotations, translations, and inversion and thereby capture full crystal symmetry, and achieve high-quality prediction using a small training set of \$\textbackslash sim 10\^\{3\}\$ examples with over 64 atom types. Our predictive model reproduces key features of experimental data and even generalizes to materials with unseen elements,and is naturally suited to efficiently predict alloy systems without additional computational cost. We demonstrate the potential of our network by predicting a broad number of high phononic specific heat capacity materials. Our work indicates an efficient approach to explore materials' phonon structure, and can further enable rapid screening for high-performance thermal storage materials and phonon-mediated superconductors.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Physics - Computational Physics},
  file = {/Users/chichen/Zotero/storage/6QUYW5BV/Chen et al. - 2021 - Direct prediction of phonon density of states with.pdf;/Users/chichen/Zotero/storage/TI5TZ7AC/2009.html}
}


@article{cooper2019design,
  title={Design-to-device approach affords panchromatic co-sensitized solar cells},
  author={Cooper, Christopher B and Beard, Edward J and V{\'a}zquez-Mayagoitia, {\'A}lvaro and Stan, Liliana and Stenning, Gavin BG and Nye, Daniel W and Vigil, Julian A and Tomar, Tina and Jia, Jingwen and Bodedla, Govardhana B and others},
  journal={Advanced Energy Materials},
  volume={9},
  number={5},
  pages={1802820},
  year={2019},
  publisher={Wiley Online Library}
}
@article{decost2019high,
  title={High throughput quantitative metallography for complex microstructures using deep learning: A case study in ultrahigh carbon steel},
  author={DeCost, Brian L and Lei, Bo and Francis, Toby and Holm, Elizabeth A},
  journal={Microscopy and Microanalysis},
  volume={25},
  number={1},
  pages={21--29},
  year={2019},
  publisher={Cambridge University Press}
}
@article{azimi2018advanced,
  title={Advanced steel microstructural classification by deep learning methods},
  author={Azimi, Seyed Majid and Britz, Dominik and Engstler, Michael and Fritz, Mario and M{\"u}cklich, Frank},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--14},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{modarres2017neural,
  title={Neural network for nanoscience scanning electron microscope image recognition},
  author={Modarres, Mohammad Hadi and Aversa, Rossella and Cozzini, Stefano and Ciancio, Regina and Leto, Angelo and Brandino, Giuseppe Piero},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={1--12},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{chenDirectPredictionPhonon2021a,
  title = {Direct Prediction of Phonon Density of States with {{Euclidean}} Neural Networks},
  author = {Chen, Zhantao and Andrejevic, Nina and Smidt, Tess and Ding, Zhiwei and Chi, Yen-Ting and Nguyen, Quynh T. and Alatas, Ahmet and Kong, Jing and Li, Mingda},
  year = {2021},
  month = jun,
  journal = {Advanced Science},
  volume = {8},
  number = {12},
  eprint = {2009.05163},
  eprinttype = {arxiv},
  pages = {2004214},
  issn = {2198-3844, 2198-3844},
  doi = {10.1002/advs.202004214},
  abstract = {Machine learning has demonstrated great power in materials design, discovery, and property prediction. However, despite the success of machine learning in predicting discrete properties, challenges remain for continuous property prediction. The challenge is aggravated in crystalline solids due to crystallographic symmetry considerations and data scarcity. Here we demonstrate the direct prediction of phonon density of states using only atomic species and positions as input. We apply Euclidean neural networks, which by construction are equivariant to 3D rotations, translations, and inversion and thereby capture full crystal symmetry, and achieve high-quality prediction using a small training set of \$\textbackslash sim 10\^\{3\}\$ examples with over 64 atom types. Our predictive model reproduces key features of experimental data and even generalizes to materials with unseen elements,and is naturally suited to efficiently predict alloy systems without additional computational cost. We demonstrate the potential of our network by predicting a broad number of high phononic specific heat capacity materials. Our work indicates an efficient approach to explore materials' phonon structure, and can further enable rapid screening for high-performance thermal storage materials and phonon-mediated superconductors.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Physics - Computational Physics},
  file = {/Users/chichen/Zotero/storage/AKS52NUC/Chen et al. - 2021 - Direct prediction of phonon density of states with.pdf;/Users/chichen/Zotero/storage/8ZK9X9US/2009.html}
}

@article{chenMachineLearningNeutron2021a,
  title = {Machine Learning on Neutron and X-Ray Scattering and Spectroscopies},
  author = {Chen, Zhantao and Andrejevic, Nina and Drucker, Nathan C. and Nguyen, Thanh and Xian, R. Patrick and Smidt, Tess and Wang, Yao and Ernstorfer, Ralph and Tennant, D. Alan and Chan, Maria and Li, Mingda},
  year = {2021},
  month = sep,
  journal = {Chemical Physics Reviews},
  volume = {2},
  number = {3},
  pages = {031301},
  publisher = {{American Institute of Physics}},
  doi = {10.1063/5.0049111},
  abstract = {Neutron and x-ray scattering represent two classes of state-of-the-art materials characterization techniques that measure materials structural and dynamical properties with high precision. These techniques play critical roles in understanding a wide variety of materials systems from catalysts to polymers, nanomaterials to macromolecules, and energy materials to quantum materials. In recent years, neutron and x-ray scattering have received a significant boost due to the development and increased application of machine learning to materials problems. This article reviews the recent progress in applying machine learning techniques to augment various neutron and x-ray techniques, including neutron scattering, x-ray absorption, x-ray scattering, and photoemission. We highlight the integration of machine learning methods into the typical workflow of scattering experiments, focusing on problems that challenge traditional analysis approaches but are addressable through machine learning, including leveraging the knowledge of simple materials to model more complicated systems, learning with limited data or incomplete labels, identifying meaningful spectra and materials representations, mitigating spectral noise, and others. We present an outlook on a few emerging roles machine learning may play in broad types of scattering and spectroscopic problems in the foreseeable future.},
  file = {/Users/chichen/Zotero/storage/GLZ6KIMV/Chen et al. - 2021 - Machine learning on neutron and x-ray scattering a.pdf}
}

@article{chenMachineLearningNeutron2021b,
  title = {Machine Learning on Neutron and X-Ray Scattering and Spectroscopies},
  author = {Chen, Zhantao and Andrejevic, Nina and Drucker, Nathan C. and Nguyen, Thanh and Xian, R. Patrick and Smidt, Tess and Wang, Yao and Ernstorfer, Ralph and Tennant, D. Alan and Chan, Maria and Li, Mingda},
  year = {2021},
  month = sep,
  journal = {Chemical Physics Reviews},
  volume = {2},
  number = {3},
  pages = {031301},
  publisher = {{American Institute of Physics}},
  doi = {10.1063/5.0049111},
  file = {/Users/chichen/Zotero/storage/QDJ6IP47/Chen et al. - 2021 - Machine learning on neutron and x-ray scattering a.pdf}
}

@inproceedings{conroyQualitativeQuantitativeAnalysis2005,
  title = {Qualitative and Quantitative Analysis of Chlorinated Solvents Using {{Raman}} Spectroscopy and Machine Learning},
  booktitle = {Opto-{{Ireland}} 2005: Optical Sensing and Spectroscopy},
  author = {Conroy, Jennifer and Ryder, Alan G. and Leger, Marc N. and Hennessey, Kenneth and Madden, Michael G.},
  year = {2005},
  month = jun,
  volume = {5826},
  pages = {131--142},
  publisher = {{International Society for Optics and Photonics}},
  doi = {10.1117/12.605056},
  abstract = {The unambiguous identification and quantification of hazardous materials is of increasing importance in many sectors such as waste disposal, pharmaceutical manufacturing, and environmental protection. One particular problem in waste disposal and chemical manufacturing is the identification of solvents into chlorinated or non-chlorinated. In this work we have used Raman spectroscopy as the basis for a discrimination and quantification method for chlorinated solvents. Raman spectra of an extensive collection of solvent mixtures (200+) were collected using a JY-Horiba LabRam, infinity with a 488 nm excitation source. The solvent mixtures comprised of several chlorinated solvents: dichloromethane, chloroform, and 1,1,1-trichloroethane, mixed with solvents such as toluene, cyclohexane and/or acetone. The spectra were then analysed using a variety of chemometric techniques (Principal Component Analysis and Principal Component Regression) and machine learning (Neural Networks and Genetic Programming). In each case models were developed to identify the presence of chlorinated solvents in mixtures at levels of \textasciitilde 5\%, to identify the type of chlorinated solvent and then to accurately quantify the amount of chlorinated solvent.},
  file = {/Users/chichen/Zotero/storage/AW7D3REX/Conroy et al. - 2005 - Qualitative and quantitative analysis of chlorinat.pdf;/Users/chichen/Zotero/storage/AHUUZBBD/12.605056.html}
}

@article{dongDeepConvolutionalNeural2021,
  title = {A Deep Convolutional Neural Network for Real-Time Full Profile Analysis of Big Powder Diffraction Data},
  author = {Dong, Hongyang and Butler, Keith T. and Matras, Dorota and Price, Stephen W. T. and Odarchenko, Yaroslav and Khatry, Rahul and Thompson, Andrew and Middelkoop, Vesna and Jacques, Simon D. M. and Beale, Andrew M. and Vamvakeros, Antonis},
  year = {2021},
  month = may,
  journal = {npj Computational Materials},
  volume = {7},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-021-00542-4},
  abstract = {We present Parameter Quantification Network (PQ-Net), a regression deep convolutional neural network providing quantitative analysis of powder X-ray diffraction patterns from multi-phase systems. The network is tested against simulated and experimental datasets of increasing complexity with the last one being an X-ray diffraction computed tomography dataset of a multi-phase Ni-Pd/CeO2-ZrO2/Al2O3 catalytic material system consisting of ca. 20,000 diffraction patterns. It is shown that the network predicts accurate scale factor, lattice parameter and crystallite size maps for all phases, which are comparable to those obtained through full profile analysis using the Rietveld method, also providing a reliable uncertainty measure on the results. The main advantage of PQ-Net is its ability to yield these results orders of magnitude faster showing its potential as a tool for real-time diffraction data analysis during in situ/operando experiments.},
  copyright = {2021 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Chemistry;Materials science Subject\_term\_id: chemistry;materials-science},
  file = {/Users/chichen/Zotero/storage/HYLWPAL8/Dong et al. - 2021 - A deep convolutional neural network for real-time .pdf;/Users/chichen/Zotero/storage/WT9NP8I8/s41524-021-00542-4.html}
}

@article{fukuharaFeatureVisualizationRaman2019,
  title = {Feature Visualization of {{Raman}} Spectrum Analysis with Deep Convolutional Neural Network},
  author = {Fukuhara, Masashi and Fujiwara, Kazuhiko and Maruyama, Yoshihiro and Itoh, Hiroyasu},
  year = {2019},
  month = dec,
  journal = {Analytica Chimica Acta},
  volume = {1087},
  pages = {11--19},
  issn = {0003-2670},
  doi = {10.1016/j.aca.2019.08.064},
  abstract = {We demonstrate a recognition and feature visualization method that uses a deep convolutional neural network for Raman spectrum analysis. The visualization is achieved by calculating important regions in the spectra from weights in pooling and fully-connected layers. The method is first examined for simple Lorentzian spectra, then applied to the spectra of pharmaceutical compounds and numerically mixed amino acids. We investigate the effects of the size and number of convolution filters on the extracted regions for Raman-peak signals using the Lorentzian spectra. It is confirmed that the Raman peak contributes to the recognition by visualizing the extracted features. A near-zero weight value is obtained at the background level region, which appears to be used for baseline correction. Common component extraction is confirmed by an evaluation of numerically mixed amino acid spectra. High weight values at the common peaks and negative values at the distinctive peaks appear, even though the model is given one-hot vectors as the training labels (without a mix ratio). This proposed method is potentially suitable for applications such as the validation of trained models, ensuring the reliability of common component extraction from compound samples for spectral analysis.},
  language = {en},
  keywords = {Convolutional neural networks,Feature visualization,Raman spectrum,Spectrum recognition},
  file = {/Users/chichen/Zotero/storage/YJSCHXM7/Fukuhara et al. - 2019 - Feature visualization of Raman spectrum analysis w.pdf}
}

@article{fungMachineLearnedFeatures2021,
  title = {Machine Learned Features from Density of States for Accurate Adsorption Energy Prediction},
  author = {Fung, Victor and Hu, Guoxiang and Ganesh, P. and Sumpter, Bobby G.},
  year = {2021},
  month = jan,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {88},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-20342-6},
  abstract = {Materials databases generated by high-throughput computational screening, typically using density functional theory (DFT), have become valuable resources for discovering new heterogeneous catalysts, though the computational cost associated with generating them presents a crucial roadblock. Hence there is a significant demand for developing descriptors or features, in lieu of DFT, to accurately predict catalytic properties, such as adsorption energies. Here, we demonstrate an approach to predict energies using a convolutional neural network-based machine learning model to automatically obtain key features from the electronic density of states (DOS). The model, DOSnet, is evaluated for a diverse set of adsorbates and surfaces, yielding a mean absolute error on the order of 0.1\,eV. In addition, DOSnet can provide physically meaningful predictions and insights by predicting responses to external perturbations to the electronic structure without additional DFT calculations, paving the way for the accelerated discovery of materials and catalysts by exploration of the electronic space.},
  copyright = {2021 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Catalysis;Computational chemistry;Materials for energy and catalysis Subject\_term\_id: catalysis;computational-chemistry;materials-for-energy-and-catalysis},
  file = {/Users/chichen/Zotero/storage/T7M5C6NR/Fung et al. - 2021 - Machine learned features from density of states fo.pdf;/Users/chichen/Zotero/storage/TJJTQHPX/s41467-020-20342-6.html}
}

@article{hellenbrandtInorganicCrystalStructure2004,
  title = {The {{Inorganic Crystal Structure Database}} ({{ICSD}})\textemdash{{Present}} and {{Future}}},
  author = {Hellenbrandt, Mariette},
  year = {2004},
  month = jan,
  journal = {Crystallography Reviews},
  volume = {10},
  number = {1},
  pages = {17--22},
  publisher = {{Taylor \& Francis}},
  issn = {0889-311X},
  doi = {10.1080/08893110410001664882},
  abstract = {The Inorganic Crystal Structure Database (ICSD) is a comprehensive collection of crystal structure entries for inorganic materials. ICSD is produced by Fachinformationszentrum Karlsruhe, Germany, and the National Institute of Standards and Technology, US. The WWW interface is developed in cooperation with the Institut Laue-Langevin, Grenoble. The ICSD is disseminated in computerized formats with scientific software tools to exploit the content of the database. ICSD includes records of all inorganic crystal structures with atomic coordinates published since 1913. The data base contains 70 102 records as of July 2003. All data are recorded by experts and are checked several times. Apart from updating, data integrity and completeness are important objectives. Incorporation of missing structures, evaluation and correction of data, with the help of authors, users and experts are ongoing activities. This review article gives an overview of the product portfolio and the current activities.},
  keywords = {Crystal structure,Database,Inorganic compounds,Inorganic Crystal Structure Database (ICSD)},
  annotation = {\_eprint: https://doi.org/10.1080/08893110410001664882},
  file = {/Users/chichen/Zotero/storage/TFNK522E/08893110410001664882.html}
}

@article{hoRapidIdentificationPathogenic2019,
  title = {Rapid Identification of Pathogenic Bacteria Using {{Raman}} Spectroscopy and Deep Learning},
  author = {Ho, Chi-Sing and Jean, Neal and Hogan, Catherine A. and Blackmon, Lena and Jeffrey, Stefanie S. and Holodniy, Mark and Banaei, Niaz and Saleh, Amr A. E. and Ermon, Stefano and Dionne, Jennifer},
  year = {2019},
  month = oct,
  journal = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {4927},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12898-9},
  abstract = {Raman optical spectroscopy promises label-free bacterial detection, identification, and antibiotic susceptibility testing in a single step. However, achieving clinically relevant speeds and accuracies remains challenging due to weak Raman signal from bacterial cells and numerous bacterial species and phenotypes. Here we generate an extensive dataset of bacterial Raman spectra and apply deep learning approaches to accurately identify 30 common bacterial pathogens. Even on low signal-to-noise spectra, we achieve average isolate-level accuracies exceeding 82\% and antibiotic treatment identification accuracies of 97.0{$\pm$}0.3\%. We also show that this approach distinguishes between methicillin-resistant and -susceptible isolates of Staphylococcus aureus (MRSA and MSSA) with 89{$\pm$}0.1\% accuracy. We validate our results on clinical isolates from 50 patients. Using just 10 bacterial spectra from each patient isolate, we achieve treatment identification accuracies of 99.7\%. Our approach has potential for culture-free pathogen identification and antibiotic susceptibility testing, and could be readily extended for diagnostics on blood, urine, and sputum.},
  copyright = {2019 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Clinical microbiology;Machine learning;Pathogens;Raman spectroscopy Subject\_term\_id: clinical-microbiology;machine-learning;pathogens;raman-spectroscopy},
  file = {/Users/chichen/Zotero/storage/K2Y5PLIH/Ho et al. - 2019 - Rapid identification of pathogenic bacteria using .pdf}
}

@article{houstonRobustClassificationHighDimensional2020,
  title = {Robust {{Classification}} of {{High}}-{{Dimensional Spectroscopy Data Using Deep Learning}} and {{Data Synthesis}}},
  author = {Houston, James and Glavin, Frank G. and Madden, Michael G.},
  year = {2020},
  month = apr,
  journal = {Journal of Chemical Information and Modeling},
  volume = {60},
  number = {4},
  pages = {1936--1954},
  publisher = {{American Chemical Society}},
  issn = {1549-9596},
  doi = {10.1021/acs.jcim.9b01037},
  abstract = {This paper presents a new approach to classification of high-dimensional spectroscopy data and demonstrates that it outperforms other current state-of-the art approaches. The specific task we consider is identifying whether samples contain chlorinated solvents or not, based on their Raman spectra. We also examine robustness to classification of outlier samples that are not represented in the training set (negative outliers). A novel application of a locally connected neural network (NN) for the binary classification of spectroscopy data is proposed and demonstrated to yield improved accuracy over traditionally popular algorithms. Additionally, we present the ability to further increase the accuracy of the locally connected NN algorithm through the use of synthetic training spectra, and we investigate the use of autoencoder based one-class classifiers and outlier detectors. Finally, a two-step classification process is presented as an alternative to the binary and one-class classification paradigms. This process combines the locally connected NN classifier, the use of synthetic training data, and an autoencoder based outlier detector to produce a model which is shown to both produce high classification accuracy and be robust in the presence of negative outliers.},
  file = {/Users/chichen/Zotero/storage/NQWB8PMC/Houston et al. - 2020 - Robust Classification of High-Dimensional Spectros.pdf;/Users/chichen/Zotero/storage/4X2T8MSB/acs.jcim.html}
}

@article{kanoCarefulAnalysisXRD2020,
  title = {Careful Analysis of {{XRD}} Patterns with {{Attention}}},
  author = {Kano, Koichi and Segi, Takashi and Ozono, Hiroshi},
  year = {2020},
  month = jun,
  journal = {arXiv:2006.01451 [cs, stat]},
  eprint = {2006.01451},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {The important peaks related to the physical properties of a lithium ion rechargeable battery were extracted from the measured X ray diffraction spectrum by a convolutional neural network based on the Attention mechanism. Among the deep features, the lattice constant of the cathodic active material was selected as a cell voltage predictor, and the crystallographic behavior of the active anodic and cathodic materials revealed the rate property during the charge discharge states. The machine learning automatically selected the significant peaks from the experimental spectrum. Applying the Attention mechanism with appropriate objective variables in multi task trained models, one can selectively visualize the correlations between interesting physical properties. As the deep features are automatically defined, this approach can adapt to the conditions of various physical experiments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/chichen/Zotero/storage/DZZJQVQA/Kano et al. - 2020 - Careful analysis of XRD patterns with Attention.pdf;/Users/chichen/Zotero/storage/FERQQZSF/2006.html}
}

@article{Kaufmann2020PhaseID,
  doi = {10.1017/s1431927620001506},
  url = {https://doi.org/10.1017/s1431927620001506},
  year = {2020},
  month = may,
  publisher = {Cambridge University Press ({CUP})},
  volume = {26},
  number = {3},
  pages = {447--457},
  author = {Kevin Kaufmann and Chaoyi Zhu and Alexander S. Rosengarten and Kenneth S. Vecchio},
  title = {Deep Neural Network Enabled Space Group Identification in {EBSD}},
  journal = {Microscopy and Microanalysis}
}

@article{kaufmannSearchingHighEntropy2020,
  title = {Searching for High Entropy Alloys: {{A}} Machine Learning Approach},
  shorttitle = {Searching for High Entropy Alloys},
  author = {Kaufmann, Kevin and Vecchio, Kenneth S.},
  year = {2020},
  month = oct,
  journal = {Acta Materialia},
  volume = {198},
  pages = {178--222},
  issn = {1359-6454},
  doi = {10.1016/j.actamat.2020.07.065},
  abstract = {For the past decade, considerable research effort has been devoted toward computationally identifying and experimentally verifying single phase, high-entropy systems.~ However, predicting the resultant crystal structure(s) ``in silico'' remains a major challenge. Previous studies have primarily used density functional theory to obtain correlated parameters and fit them to existing data, but this is impractical given the extensive regions of unexplored composition space and considerable computational cost. A rapidly developing area of materials science is the application of machine learning to accelerate materials discovery and reduce computational and experimental costs. Machine learning has inherent advantages over traditional modeling, owing to its flexibility as new data becomes available and its rapid ability to construct relationships between input data and target outputs. In this article, we propose a novel high-throughput approach, called ``ML-HEA'', for~coupling thermodynamic and chemical features with a random forest machine learning model for predicting the solid solution forming ability. The model can be a primary tool or integrated into existing alloy discovery workflows. The ML-HEA method is validated by comparing the results with reliable experimental data for binary, ternary, quaternary, and quinary systems. Comparison to other modeling approaches, including CALPHAD and the LTVC model, are also made to assess the performance of the machine learning model on labeled and unlabeled data. The uncertainty of the model in predicting the resultant phase of each composition is explored via the output of individual predictor trees. Importantly, the developed model can be immediately applied to explore material space in an unconstrained manner, and is readily updated to reflect the results of new experiments.},
  language = {en},
  keywords = {Computational model,High entropy systems,Machine learning,Solid solution},
  file = {/Users/chichen/Zotero/storage/E263XBGG/Kaufmann and Vecchio - 2020 - Searching for high entropy alloys A machine learn.pdf}
}

@article{leeDatadrivenXRDAnalysis2021,
  title = {A Data-Driven {{XRD}} Analysis Protocol for Phase Identification and Phase-Fraction Prediction of Multiphase Inorganic Compounds},
  author = {Lee, Jin-Woong and Bae Park, Woon and Kim, Minseuk and Singh, Satendra Pal and Pyo, Myoungho and Sohn, Kee-Sun},
  year = {2021},
  journal = {Inorganic Chemistry Frontiers},
  volume = {8},
  number = {10},
  pages = {2492--2504},
  publisher = {{Royal Society of Chemistry}},
  doi = {10.1039/D0QI01513J},
  language = {en},
  file = {/Users/chichen/Zotero/storage/28M3D595/Lee et al. - 2021 - A data-driven XRD analysis protocol for phase iden.pdf}
}

@article{hawizy2011chemicaltagger,
  title={ChemicalTagger: A tool for semantic text-mining in chemistry},
  author={Hawizy, Lezan and Jessop, David M and Adams, Nico and Murray-Rust, Peter},
  journal={Journal of cheminformatics},
  volume={3},
  number={1},
  pages={1--13},
  year={2011},
  publisher={Springer}
}
@article{leaman2015tmchem,
  title={tmChem: a high performance approach for chemical named entity recognition and normalization},
  author={Leaman, Robert and Wei, Chih-Hsuan and Lu, Zhiyong},
  journal={Journal of cheminformatics},
  volume={7},
  number={1},
  pages={1--10},
  year={2015},
  publisher={BioMed Central}
}
@article{kim2017materials,
  title={Materials synthesis insights from scientific literature via text extraction and machine learning},
  author={Kim, Edward and Huang, Kevin and Saunders, Adam and McCallum, Andrew and Ceder, Gerbrand and Olivetti, Elsa},
  journal={Chemistry of Materials},
  volume={29},
  number={21},
  pages={9436--9444},
  year={2017},
  publisher={ACS Publications}
}
@article{jessop2011oscar4,
  title={OSCAR4: a flexible architecture for chemical text-mining},
  author={Jessop, David M and Adams, Sam E and Willighagen, Egon L and Hawizy, Lezan and Murray-Rust, Peter},
  journal={Journal of cheminformatics},
  volume={3},
  number={1},
  pages={1--12},
  year={2011},
  publisher={BioMed Central}
}
@article{kononova2019text,
  title={Text-mined dataset of inorganic materials synthesis recipes},
  author={Kononova, Olga and Huo, Haoyan and He, Tanjin and Rong, Ziqin and Botari, Tiago and Sun, Wenhao and Tshitoyan, Vahe and Ceder, Gerbrand},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={1--11},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{olivetti2020data,
  title={Data-driven materials research enabled by natural language processing and information extraction},
  author={Olivetti, Elsa A and Cole, Jacqueline M and Kim, Edward and Kononova, Olga and Ceder, Gerbrand and Han, Thomas Yong-Jin and Hiszpanski, Anna M},
  journal={Applied Physics Reviews},
  volume={7},
  number={4},
  pages={041317},
  year={2020},
  publisher={AIP Publishing LLC}
}
@article{tayfuroglu2019silico,
  title={In silico investigation into H2 uptake in MOFs: combined text/data mining and structural calculations},
  author={Tayfuroglu, Omer and Kocak, Abdulkadir and Zorlu, Yunus},
  journal={Langmuir},
  volume={36},
  number={1},
  pages={119--129},
  year={2019},
  publisher={ACS Publications}
}
@article{beard2019comparative,
  title={Comparative dataset of experimental and computational attributes of UV/vis absorption spectra},
  author={Beard, Edward J and Sivaraman, Ganesh and V{\'a}zquez-Mayagoitia, {\'A}lvaro and Vishwanath, Venkatram and Cole, Jacqueline M},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={1--11},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{huang2020database,
  title={A database of battery materials auto-generated using ChemDataExtractor},
  author={Huang, Shu and Cole, Jacqueline M},
  journal={Scientific Data},
  volume={7},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{court2018auto,
  title={Auto-generated materials database of Curie and N{\'e}el temperatures via semi-supervised relationship extraction},
  author={Court, Callum J and Cole, Jacqueline M},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{park2018text,
  title={Text mining metal--organic framework papers},
  author={Park, Sanghoon and Kim, Baekjun and Choi, Sihoon and Boyd, Peter G and Smit, Berend and Kim, Jihan},
  journal={Journal of chemical information and modeling},
  volume={58},
  number={2},
  pages={244--251},
  year={2018},
  publisher={ACS Publications}
}
@article{kononova2021opportunities,
  title={Opportunities and challenges of text mining in aterials research},
  author={Kononova, Olga and He, Tanjin and Huo, Haoyan and Trewartha, Amalie and Olivetti, Elsa A and Ceder, Gerbrand},
  journal={Iscience},
  volume={24},
  number={3},
  year={2021},
  publisher={Elsevier}
}
@article{ho2020using,
  title={Using word embeddings in abstracts to accelerate metallocene catalysis polymerization research},
  author={Ho, David and Shkolnik, Albert S and Ferraro, Neil J and Rizkin, Benjamin A and Hartman, Ryan L},
  journal={Computers \& Chemical Engineering},
  volume={141},
  pages={107026},
  year={2020},
  publisher={Elsevier}
}
@article{yahyaoglu2021phase,
  title={Phase-Transition-Enhanced Thermoelectric Transport in Rickardite Mineral Cu3--x Te2},
  author={Yahyaoglu, Mujde and Ozen, Melis and Prots, Yurii and El Hamouli, Oussama and Tshitoyan, Vahe and Ji, Huiwen and Burkhardt, Ulrich and Lenoir, Bertrand and Snyder, G Jeffrey and Jain, Anubhav and others},
  journal={Chemistry of Materials},
  volume={33},
  number={5},
  pages={1832--1841},
  year={2021},
  publisher={ACS Publications}
}
@article{haque2020effect,
  title={Effect of electron-phonon scattering, pressure and alloying on the thermoelectric performance of TmCu $ \_3 $ Ch $ \_4 $(Tm= V, Nb, Ta; Ch= S, Se, Te)},
  author={Haque, Enamul},
  journal={arXiv preprint arXiv:2010.08461},
  year={2020}
}
@article{viennois2020anisotropic,
  title={Anisotropic low-energy vibrational modes as an effect of cage geometry in the binary barium silicon clathrate B a 24 S i 100},
  author={Viennois, Romain and Koza, Michael Marek and Debord, R{\'e}gis and Toulemonde, Pierre and Mutka, Hannu and Pailhes, Stephane},
  journal={Physical Review B},
  volume={101},
  number={22},
  pages={224302},
  year={2020},
  publisher={APS}
}
@article{yamamoto2020first,
  title={First-principles study of thermoelectric properties of mixed iodide perovskite Cs (B, B') I3 (B, B'= Ge, Sn, and Pb)},
  author={Yamamoto, K and Narita, G and Yamasaki, J and Iikubo, S},
  journal={Journal of Physics and Chemistry of Solids},
  volume={140},
  pages={109372},
  year={2020},
  publisher={Elsevier}
}
@article{jong2020manifestation,
  title={Manifestation of the thermoelectric properties in Ge-based halide perovskites},
  author={Jong, Un-Gi and Yu, Chol-Jun and Kye, Yun-Hyok and Hong, Song-Nam and Kim, Hyon-Gyong},
  journal={Physical Review Materials},
  volume={4},
  number={7},
  pages={075403},
  year={2020},
  publisher={APS}
}
@article{wang2019ultralow,
  title={Ultralow lattice thermal conductivity and electronic properties of monolayer 1T phase semimetal SiTe2 and SnTe2},
  author={Wang, Yi and Gao, Zhibin and Zhou, Jun},
  journal={Physica E: Low-dimensional Systems and Nanostructures},
  volume={108},
  pages={53--59},
  year={2019},
  publisher={Elsevier}
}
@article{yang2018low,
  title={Low lattice thermal conductivity and excellent thermoelectric behavior in Li3Sb and Li3Bi},
  author={Yang, Xiuxian and Dai, Zhenhong and Zhao, Yinchang and Liu, Jianye and Meng, Sheng},
  journal={Journal of Physics: Condensed Matter},
  volume={30},
  number={42},
  pages={425401},
  year={2018},
  publisher={IOP Publishing}
}
@article{de2020machine,
  title={Machine-learning-guided discovery of the gigantic magnetocaloric effect in HoB 2 near the hydrogen liquefaction temperature},
  author={de Castro, Pedro Baptista and Terashima, Kensei and Yamamoto, Takafumi D and Hou, Zhufeng and Iwasaki, Suguru and Matsumoto, Ryo and Adachi, Shintaro and Saito, Yoshito and Song, Peng and Takeya, Hiroyuki and others},
  journal={NPG Asia Materials},
  volume={12},
  number={1},
  pages={1--7},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{kim2020inorganic,
  title={Inorganic materials synthesis planning with literature-trained neural networks},
  author={Kim, Edward and Jensen, Zach and van Grootel, Alexander and Huang, Kevin and Staib, Matthew and Mysore, Sheshera and Chang, Haw-Shiuan and Strubell, Emma and McCallum, Andrew and Jegelka, Stefanie and others},
  journal={Journal of chemical information and modeling},
  volume={60},
  number={3},
  pages={1194--1201},
  year={2020},
  publisher={ACS Publications}
}
@article{kim2017virtual,
  title={Virtual screening of inorganic materials synthesis parameters with deep learning},
  author={Kim, Edward and Huang, Kevin and Jegelka, Stefanie and Olivetti, Elsa},
  journal={npj Computational Materials},
  volume={3},
  number={1},
  pages={1--9},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{tshitoyan2019unsupervised,
  title={Unsupervised word embeddings capture latent knowledge from materials science literature},
  author={Tshitoyan, Vahe and Dagdelen, John and Weston, Leigh and Dunn, Alexander and Rong, Ziqin and Kononova, Olga and Persson, Kristin A and Ceder, Gerbrand and Jain, Anubhav},
  journal={Nature},
  volume={571},
  number={7763},
  pages={95--98},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{he2020similarity,
  title={Similarity of precursors in solid-state synthesis as text-mined from scientific literature},
  author={He, Tanjin and Sun, Wenhao and Huo, Haoyan and Kononova, Olga and Rong, Ziqin and Tshitoyan, Vahe and Botari, Tiago and Ceder, Gerbrand},
  journal={Chemistry of Materials},
  volume={32},
  number={18},
  pages={7861--7873},
  year={2020},
  publisher={ACS Publications}
}
@article{vaucher2020automated,
  title={Automated extraction of chemical synthesis actions from experimental procedures},
  author={Vaucher, Alain C and Zipoli, Federico and Geluykens, Joppe and Nair, Vishnu H and Schwaller, Philippe and Laino, Teodoro},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{weston2019named,
  title={Named entity recognition and normalization applied to large-scale information extraction from the materials science literature},
  author={Weston, Leigh and Tshitoyan, Vahe and Dagdelen, John and Kononova, Olga and Trewartha, Amalie and Persson, Kristin A and Ceder, Gerbrand and Jain, Anubhav},
  journal={Journal of chemical information and modeling},
  volume={59},
  number={9},
  pages={3692--3702},
  year={2019},
  publisher={ACS Publications}
}
@article{rocktaschel2012chemspot,
  title={ChemSpot: a hybrid system for chemical named entity recognition},
  author={Rockt{\"a}schel, Tim and Weidlich, Michael and Leser, Ulf},
  journal={Bioinformatics},
  volume={28},
  number={12},
  pages={1633--1640},
  year={2012},
  publisher={Oxford University Press}
}
@article{corbett2018chemlistem,
  title={Chemlistem: chemical named entity recognition using recurrent neural networks},
  author={Corbett, Peter and Boyle, John},
  journal={Journal of cheminformatics},
  volume={10},
  number={1},
  pages={1--9},
  year={2018},
  publisher={Springer}
}
@article{swain2016chemdataextractor,
  title={ChemDataExtractor: a toolkit for automated extraction of chemical information from the scientific literature},
  author={Swain, Matthew C and Cole, Jacqueline M},
  journal={Journal of chemical information and modeling},
  volume={56},
  number={10},
  pages={1894--1904},
  year={2016},
  publisher={ACS Publications}
}
@article{leeDeeplearningTechniquePhase2020,
  title = {A Deep-Learning Technique for Phase Identification in Multiphase Inorganic Compounds Using Synthetic {{XRD}} Powder Patterns},
  author = {Lee, Jin-Woong and Park, Woon Bae and Lee, Jin Hee and Singh, Satendra Pal and Sohn, Kee-Sun},
  year = {2020},
  month = jan,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {86},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13749-3},
  abstract = {Here we report a facile, prompt protocol based on deep-learning techniques to sort out intricate phase identification and quantification problems in complex multiphase inorganic compounds. We simulate plausible powder X-ray diffraction (XRD) patterns for 170 inorganic compounds in the Sr-Li-Al-O quaternary compositional pool, wherein promising LED phosphors have been recently discovered. Finally, 1,785,405 synthetic XRD patterns are prepared by combinatorically mixing the simulated powder XRD patterns of 170 inorganic compounds. Convolutional neural network (CNN) models are built and eventually trained using this large prepared dataset. The fully trained CNN model promptly and accurately identifies the constituent phases in complex multiphase inorganic compounds. Although the CNN is trained using the simulated XRD data, a test with real experimental XRD data returns an accuracy of nearly 100\% for phase identification and 86\% for three-step-phase-fraction quantification.},
  copyright = {2020 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Computational methods;Inorganic chemistry;X-ray diffraction Subject\_term\_id: computational-methods;inorganic-chemistry;x-ray-diffraction},
  file = {/Users/chichen/Zotero/storage/ICAMDM5Z/Lee et al. - 2020 - A deep-learning technique for phase identification.pdf;/Users/chichen/Zotero/storage/CQPXDHZW/s41467-019-13749-3.html}
}

@article{liuDeepConvolutionalNeural2017,
  title = {Deep Convolutional Neural Networks for {{Raman}} Spectrum Recognition: A Unified Solution},
  shorttitle = {Deep Convolutional Neural Networks for {{Raman}} Spectrum Recognition},
  author = {Liu, Jinchao and Osadchy, Margarita and Ashton, Lorna and Foster, Michael and Solomon, Christopher J. and Gibson, Stuart J.},
  year = {2017},
  month = oct,
  journal = {Analyst},
  volume = {142},
  number = {21},
  pages = {4067--4074},
  publisher = {{The Royal Society of Chemistry}},
  issn = {1364-5528},
  doi = {10.1039/C7AN01371J},
  abstract = {Machine learning methods have found many applications in Raman spectroscopy, especially for the identification of chemical species. However, almost all of these methods require non-trivial preprocessing such as baseline correction and/or PCA as an essential step. Here we describe our unified solution for the identification of chemical species in which a convolutional neural network is trained to automatically identify substances according to their Raman spectrum without the need for preprocessing. We evaluated our approach using the RRUFF spectral database, comprising mineral sample data. Superior classification performance is demonstrated compared with other frequently used machine learning algorithms including the popular support vector machine method.},
  language = {en},
  file = {/Users/chichen/Zotero/storage/RVXHI4PK/Liu et al. - 2017 - Deep convolutional neural networks for Raman spect.pdf;/Users/chichen/Zotero/storage/Q3TDHTAU/c7an01371j.html}
}
@article{de2019resolution,
  title={Resolution enhancement in scanning electron microscopy using deep learning},
  author={de Haan, Kevin and Ballard, Zachary S and Rivenson, Yair and Wu, Yichen and Ozcan, Aydogan},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--7},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{vlcek2019learning,
  title={Learning from imperfections: predicting structure and thermodynamics from atomic imaging of fluctuations},
  author={Vlcek, Lukas and Ziatdinov, Maxim and Maksov, Artem and Tselev, Alexander and Baddorf, Arthur P and Kalinin, Sergei V and Vasudevan, Rama K},
  journal={ACS nano},
  volume={13},
  number={1},
  pages={718--727},
  year={2019},
  publisher={ACS Publications}
}
@article{ziatdinov2017learning,
  title={Learning surface molecular structures via machine vision},
  author={Ziatdinov, Maxim and Maksov, Artem and Kalinin, Sergei V},
  journal={npj Computational Materials},
  volume={3},
  number={1},
  pages={1--9},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{rashidi2018autonomous,
  title={Autonomous scanning probe microscopy in situ tip conditioning through machine learning},
  author={Rashidi, Mohammad and Wolkow, Robert A},
  journal={ACS nano},
  volume={12},
  number={6},
  pages={5185--5189},
  year={2018},
  publisher={ACS Publications}
}
@book{koch2002determination,
  title={Determination of core structure periodicity and point defect density along dislocations},
  author={Koch, Christoph Tobias},
  year={2002},
  publisher={Arizona State University}
}
@article{ophus2017fast,
  title={A fast image simulation algorithm for scanning transmission electron microscopy},
  author={Ophus, Colin},
  journal={Advanced structural and chemical imaging},
  volume={3},
  number={1},
  pages={1--11},
  year={2017},
  publisher={SpringerOpen}
}
@article{von2020zerocostdl4mic,
  title={ZeroCostDL4Mic: an open platform to simplify access and use of Deep-Learning in Microscopy},
  author={Von Chamier, Lucas and Jukkala, Johanna and Spahn, Christoph and Lerche, Martina and Hern{\'a}ndez-P{\'e}rez, Sara and Mattila, Pieta K and Karinou, Eleni and Holden, Seamus and Solak, Ahmet Can and Krull, Alexander and others},
  journal={BioRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}
@article{macleod2020self,
  title={Self-driving laboratory for accelerated discovery of thin-film materials},
  author={MacLeod, Benjamin P and Parlane, Fraser GL and Morrissey, Thomas D and H{\"a}se, Florian and Roch, Lo{\"\i}c M and Dettelbach, Kevan E and Moreira, Raphaell and Yunker, Lars PE and Rooney, Michael B and Deeth, Joseph R and others},
  journal={Science Advances},
  volume={6},
  number={20},
  pages={eaaz8867},
  year={2020},
  publisher={American Association for the Advancement of Science}
}
@article{roch2018chemos,
  title={ChemOS: orchestrating autonomous experimentation},
  author={Roch, Lo{\"\i}c M and H{\"a}se, Florian and Kreisbeck, Christoph and Tamayo-Mendoza, Teresa and Yunker, Lars PE and Hein, Jason E and Aspuru-Guzik, Al{\'a}n},
  journal={Science Robotics},
  volume={3},
  number={19},
  pages={eaat5559},
  year={2018},
  publisher={American Association for the Advancement of Science}
}
@article{szymanski2021toward,
  title={Toward autonomous design and synthesis of novel inorganic materials},
  author={Szymanski, Nathan and Zeng, Yan and Huo, Haoyan and Bartel, Chris and Kim, Haegyum and Ceder, Gerbrand},
  journal={Materials Horizons},
  year={2021},
  publisher={Royal Society of Chemistry}
}
@article{choudhary2021computational,
  title={Computational scanning tunneling microscope image database},
  author={Choudhary, Kamal and Garrity, Kevin F and Camp, Charles and Kalinin, Sergei V and Vasudevan, Rama and Ziatdinov, Maxim and Tavazza, Francesca},
  journal={Scientific data},
  volume={8},
  number={1},
  pages={1--9},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{he2015towards,
  title={Towards 3D mapping of BO6 octahedron rotations at perovskite heterointerfaces, unit cell by unit cell},
  author={He, Qian and Ishikawa, Ryo and Lupini, Andrew R and Qiao, Liang and Moon, Eun J and Ovchinnikov, Oleg and May, Steven J and Biegalski, Michael D and Borisevich, Albina Y},
  journal={Acs Nano},
  volume={9},
  number={8},
  pages={8412--8419},
  year={2015},
  publisher={ACS Publications}
}
@article{maksov2019deep,
  title={Deep learning analysis of defect and phase evolution during electron beam-induced transformations in WS 2},
  author={Maksov, Artem and Dyck, Ondrej and Wang, Kai and Xiao, Kai and Geohegan, David B and Sumpter, Bobby G and Vasudevan, Rama K and Jesse, Stephen and Kalinin, Sergei V and Ziatdinov, Maxim},
  journal={npj Computational Materials},
  volume={5},
  number={1},
  pages={1--8},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{dgllife,
    title={DGL-LifeSci: An Open-Source Toolkit for Deep Learning on Graphs in Life Science},
    author={Mufei Li and Jinjing Zhou and Jiajing Hu and Wenxuan Fan and Yangkang Zhang and Yaxin Gu and George Karypis},
    year={2021},
    journal={arXiv preprint arXiv:2106.14232}
}
@article{madsen2018deep,
  title={A deep learning approach to identify local structures in atomic-resolution transmission electron microscopy images},
  author={Madsen, Jacob and Liu, Pei and Kling, Jens and Wagner, Jakob Birkedal and Hansen, Thomas Willum and Winther, Ole and Schi{\o}tz, Jakob},
  journal={Advanced Theory and Simulations},
  volume={1},
  number={8},
  pages={1800037},
  year={2018},
  publisher={Wiley Online Library}
}
@article{roberts2019deep,
  title={Deep learning for semantic segmentation of defects in advanced STEM images of steels},
  author={Roberts, Graham and Haile, Simon Y and Sainju, Rajat and Edwards, Danny J and Hutchinson, Brian and Zhu, Yuanyuan},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{lussierDeepLearningArtificial2020,
  title = {Deep Learning and Artificial Intelligence Methods for {{Raman}} and Surface-Enhanced {{Raman}} Scattering},
  author = {Lussier, F{\'e}lix and Thibault, Vincent and Charron, Benjamin and Wallace, Gregory Q. and Masson, Jean-Francois},
  year = {2020},
  month = mar,
  journal = {TrAC Trends in Analytical Chemistry},
  volume = {124},
  pages = {115796},
  issn = {0165-9936},
  doi = {10.1016/j.trac.2019.115796},
  abstract = {Machine learning is shaping up our lives in many ways. In analytical sciences, machine learning provides an unprecedented opportunity to extract information from complex or big datasets in chromatography, mass spectrometry, NMR, and spectroscopy, among others. This is especially the case in Raman and surface-enhanced Raman scattering (SERS) techniques where vibrational spectra of complex chemical mixtures are acquired as large datasets for the analysis or imaging of chemical systems. The classical linear methods of processing the information no longer suffice and thus machine learning methods for extracting the chemical information from Raman and SERS experiments have been implemented recently. In this review, we will provide a brief overview of the most common machine learning techniques employed in Raman, a guideline for new users to implement machine learning in their data analysis process, and an overview of modern applications of machine learning in Raman and SERS.},
  language = {en},
  keywords = {Artificial intelligence,Artificial neural network,Deep learning,Machine learning,Raman,Sensors,SERS,Surface enhanced Raman scattering}
}
@article{ying2019gnnexplainer,
  title={Gnnexplainer: Generating explanations for graph neural networks},
  author={Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={9240},
  year={2019},
  publisher={NIH Public Access}
}
@inproceedings{maddenMachineLearningMethods2003,
  title = {Machine Learning Methods for Quantitative Analysis of Raman Spectroscopy Data},
  booktitle = {Opto-{{Ireland}} 2002: Optics and Photonics Technologies and {{Applications}}},
  author = {Madden, Michael G. and Ryder, Alan G.},
  year = {2003},
  month = aug,
  volume = {4876},
  pages = {1130--1139},
  publisher = {{International Society for Optics and Photonics}},
  doi = {10.1117/12.464039},
  abstract = {The automated identification and quantification of illicit materials using Raman spectroscopy is of significant importance for law enforcement agencies. This paper explores the use of Machine Learning (ML) methods in comparison with standard statistical regression techniques for developing automated identification methods. In this work, the ML task is broken into two sub-tasks, data reduction and prediction. In well-conditioned data, the number of samples should be much larger than the number of attributes per sample, to limit the degrees of freedom in predictive models. In this spectroscopy data, the opposite is normally true. Predictive models based on such data have a high number of degrees of freedom, which increases the risk of models over-fitting to the sample data and having poor predictive power. In the work described here, an approach to data reduction based on Genetic Algorithms is described. For the prediction sub-task, the objective is to estimate the concentration of a component in a mixture, based on its Raman spectrum and the known concentrations of previously seen mixtures. Here, Neural Networks and k-Nearest Neighbours are used for prediction. Preliminary results are presented for the problem of estimating the concentration of cocaine in solid mixtures, and compared with previously published results in which statistical analysis of the same dataset was performed. Finally, this paper demonstrates how more accurate results may be achieved by using an ensemble of prediction techniques.},
  file = {/Users/chichen/Zotero/storage/AU3QVBPY/Madden and Ryder - 2003 - Machine learning methods for quantitative analysis.pdf;/Users/chichen/Zotero/storage/TR8NUAU7/12.464039.html}
}

@article{maffettoneCrystallographyCompanionAgent2021a,
  title = {Crystallography Companion Agent for High-Throughput Materials Discovery},
  author = {Maffettone, Phillip M. and Banko, Lars and Cui, Peng and Lysogorskiy, Yury and Little, Marc A. and Olds, Daniel and Ludwig, Alfred and Cooper, Andrew I.},
  year = {2021},
  month = apr,
  journal = {Nature Computational Science},
  volume = {1},
  number = {4},
  pages = {290--297},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00059-2},
  abstract = {The discovery of new structural and functional materials is driven by phase identification, often using X-ray diffraction (XRD). Automation has accelerated the rate of XRD measurements, greatly outpacing XRD analysis techniques that remain manual, time-consuming, error-prone and impossible to scale. With the advent of autonomous robotic scientists or self-driving laboratories, contemporary techniques prohibit the integration of XRD. Here, we describe a computer program for the autonomous characterization of XRD data, driven by artificial intelligence (AI), for the discovery of new materials. Starting from structural databases, we train an ensemble model using a physically accurate synthetic dataset, which outputs probabilistic classifications\textemdash rather than absolutes\textemdash to overcome the overconfidence in traditional neural networks. This AI agent behaves as a companion to the researcher, improving accuracy and offering substantial time savings. It is demonstrated on a diverse set of organic and inorganic materials characterization challenges. This method is directly applicable to inverse design approaches and robotic discovery systems, and can be immediately considered for other forms of characterization such as spectroscopy and the pair distribution function.},
  copyright = {2021 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  language = {en},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods;X-ray diffraction Subject\_term\_id: characterization-and-analytical-techniques;computational-methods;x-ray-diffraction},
  file = {/Users/chichen/Zotero/storage/MSHWDGCE/Maffettone et al. - 2021 - Crystallography companion agent for high-throughpu.pdf}
}

@article{maffettoneCrystallographyCompanionAgent2021b,
  title = {Crystallography Companion Agent for High-Throughput Materials Discovery},
  author = {Maffettone, Phillip M. and Banko, Lars and Cui, Peng and Lysogorskiy, Yury and Little, Marc A. and Olds, Daniel and Ludwig, Alfred and Cooper, Andrew I.},
  year = {2021},
  month = apr,
  journal = {Nature Computational Science},
  volume = {1},
  number = {4},
  eprint = {2008.00283},
  eprinttype = {arxiv},
  pages = {290--297},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00059-2},
  abstract = {The discovery of new structural and functional materials is driven by phase identification, often using X-ray diffraction (XRD). Automation has accelerated the rate of XRD measurements, greatly outpacing XRD analysis techniques that remain manual, time-consuming, error-prone, and impossible to scale. With the advent of autonomous robotic scientists or self-driving labs, contemporary techniques prohibit the integration of XRD. Here, we describe a computer program for the autonomous characterization of XRD data, driven by artificial intelligence (AI), for the discovery of new materials. Starting from structural databases, we train an ensemble model using a physically accurate synthetic dataset, which output probabilistic classifications -- rather than absolutes -- to overcome the overconfidence in traditional neural networks. This AI agent behaves as a companion to the researcher, improving accuracy and offering significant time savings. It was demonstrated on a diverse set of organic and inorganic materials characterization challenges. This innovation is directly applicable to inverse design approaches, robotic discovery systems, and can be immediately considered for other forms of characterization such as spectroscopy and the pair distribution function.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Materials Science},
  file = {/Users/chichen/Zotero/storage/EM3X6S57/Maffettone et al. - 2021 - Crystallography companion agent for high-throughpu.pdf}
}

@article{maffettoneCrystallographyCompanionAgent2021c,
  title = {Crystallography Companion Agent for High-Throughput Materials Discovery},
  author = {Maffettone, Phillip M. and Banko, Lars and Cui, Peng and Lysogorskiy, Yury and Little, Marc A. and Olds, Daniel and Ludwig, Alfred and Cooper, Andrew I.},
  year = {2021},
  month = apr,
  journal = {Nature Computational Science},
  volume = {1},
  number = {4},
  pages = {290--297},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00059-2},
  abstract = {The discovery of new structural and functional materials is driven by phase identification, often using X-ray diffraction (XRD). Automation has accelerated the rate of XRD measurements, greatly outpacing XRD analysis techniques that remain manual, time-consuming, error-prone and impossible to scale. With the advent of autonomous robotic scientists or self-driving laboratories, contemporary techniques prohibit the integration of XRD. Here, we describe a computer program for the autonomous characterization of XRD data, driven by artificial intelligence (AI), for the discovery of new materials. Starting from structural databases, we train an ensemble model using a physically accurate synthetic dataset, which outputs probabilistic classifications\textemdash rather than absolutes\textemdash to overcome the overconfidence in traditional neural networks. This AI agent behaves as a companion to the researcher, improving accuracy and offering substantial time savings. It is demonstrated on a diverse set of organic and inorganic materials characterization challenges. This method is directly applicable to inverse design approaches and robotic discovery systems, and can be immediately considered for other forms of characterization such as spectroscopy and the pair distribution function.},
  copyright = {2021 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  language = {en},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods;X-ray diffraction Subject\_term\_id: characterization-and-analytical-techniques;computational-methods;x-ray-diffraction},
  file = {/Users/chichen/Zotero/storage/FJWL6GG8/Maffettone et al. - 2021 - Crystallography companion agent for high-throughpu.pdf;/Users/chichen/Zotero/storage/J3TYMKTF/s43588-021-00059-2.html}
}

@article{mahmoudLearningElectronicDensity2020,
  title = {Learning the Electronic Density of States in Condensed Matter},
  author = {Mahmoud, Chiheb Ben and Anelli, Andrea and Cs{\'a}nyi, G{\'a}bor and Ceriotti, Michele},
  year = {2020},
  month = dec,
  journal = {Physical Review B},
  volume = {102},
  number = {23},
  eprint = {2006.11803},
  eprinttype = {arxiv},
  pages = {235130},
  issn = {2469-9950, 2469-9969},
  doi = {10.1103/PhysRevB.102.235130},
  abstract = {The electronic density of states (DOS) quantifies the distribution of the energy levels that can be occupied by electrons in a quasiparticle picture, and is central to modern electronic structure theory. It also underpins the computation and interpretation of experimentally observable material properties such as optical absorption and electrical conductivity. We discuss the challenges inherent in the construction of a machine-learning (ML) framework aimed at predicting the DOS as a combination of local contributions that depend in turn on the geometric configuration of neighbours around each atom, using quasiparticle energy levels from density functional theory as training data. We present a challenging case study that includes configurations of silicon spanning a broad set of thermodynamic conditions, ranging from bulk structures to clusters, and from semiconducting to metallic behavior. We compare different approaches to represent the DOS, and the accuracy of predicting quantities such as the Fermi level, the DOS at the Fermi level, or the band energy, either directly or as a side-product of the evaluation of the DOS. The performance of the model depends crucially on the smoothening of the DOS, and there is a tradeoff to be made between the systematic error associated with the smoothening and the error in the ML model for a specific structure. We demonstrate the usefulness of this approach by computing the density of states of a large amorphous silicon sample, for which it would be prohibitively expensive to compute the DOS by direct electronic structure calculations, and show how the atom-centred decomposition of the DOS that is obtained through our model can be used to extract physical insights into the connections between structural and electronic features.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Materials Science,Statistics - Machine Learning},
  file = {/Users/chichen/Zotero/storage/DLK3SYHJ/Mahmoud et al. - 2020 - Learning the electronic density of states in conde.pdf;/Users/chichen/Zotero/storage/395KYD6X/2006.html}
}

@article{miracleEmergingCapabilitiesHighThroughput2021,
  title = {Emerging {{Capabilities}} for the {{High}}-{{Throughput Characterization}} of {{Structural Materials}}},
  author = {Miracle, Daniel B. and Li, Mu and Zhang, Zhaohan and Mishra, Rohan and Flores, Katharine M.},
  year = {2021},
  journal = {Annual Review of Materials Research},
  volume = {51},
  number = {1},
  pages = {131--164},
  doi = {10.1146/annurev-matsci-080619-022100},
  abstract = {Structural materials have lagged behind other classes in the use of combinatorial and high-throughput (CHT) methods for rapid screening and alloy development. The dual complexities of composition and microstructure are responsible for this, along with the need to produce bulk-like, defect-free materials libraries. This review evaluates recent progress in CHT evaluations for structural materials. High-throughput computations can augment or replace experiments and accelerate data analysis. New synthesis methods, including additive manufacturing, can rapidly produce composition gradients or arrays of discrete alloys-on-demand in bulk form, and new experimental methods have been validated for nearly all essential structural materials properties. The remaining gaps are CHT measurement of bulk tensile strength, ductility, and melting temperature and production of microstructural libraries. A search strategy designed forstructural materials gains efficiency by performing two layers of evaluations before addressing microstructure, and this review closes with a future vision of the autonomous, closed-loop CHT exploration of structural materials.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-matsci-080619-022100},
  file = {/Users/chichen/Zotero/storage/D257UJ83/Miracle et al. - 2021 - Emerging Capabilities for the High-Throughput Char.pdf}
}

@article{mizoguchiMachineLearningApproaches2020,
  title = {Machine Learning Approaches for {{ELNES}}/{{XANES}}},
  author = {Mizoguchi, Teruyasu and Kiyohara, Shin},
  year = {2020},
  month = apr,
  journal = {Microscopy},
  volume = {69},
  number = {2},
  pages = {92--109},
  issn = {2050-5701},
  doi = {10.1093/jmicro/dfz109},
  abstract = {Materials characterization is indispensable for materials development. In particular, spectroscopy provides atomic configuration, chemical bonding and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material. Despite its importance, the interpretation of spectra using human-driven methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the rapid increase in experimental spectral data. To overcome the limitations of such methods, we develop new data-driven approaches based on machine learning. Specifically, we use hierarchical clustering, a decision tree and a feedforward neural network to investigate the electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as local measurement of material functions.},
  file = {/Users/chichen/Zotero/storage/NGGSI2NF/Mizoguchi and Kiyohara - 2020 - Machine learning approaches for ELNESXANES.pdf;/Users/chichen/Zotero/storage/LMM2KRZ8/5714813.html}
}

@inproceedings{oconnellClassificationTargetAnalyte2005,
  title = {Classification of a Target Analyte in Solid Mixtures Using Principal Component Analysis, Support Vector Machines, and {{Raman}} Spectroscopy},
  booktitle = {Opto-Ireland 2005: Optical Sensing and Spectroscopy},
  author = {O'Connell, Marie-Louise and Howley, Tom and Ryder, Alan G. and Leger, Marc N. and Madden, Michael G.},
  year = {2005},
  month = jun,
  volume = {5826},
  pages = {340--350},
  publisher = {{International Society for Optics and Photonics}},
  doi = {10.1117/12.605156},
  abstract = {The quantitative analysis of illicit materials using Raman spectroscopy is of widespread interest for law enforcement and healthcare applications. One of the difficulties faced when analysing illicit mixtures is the fact that the narcotic can be mixed with many different cutting agents. This obviously complicates the development of quantitative analytical methods. In this work we demonstrate some preliminary efforts to try and account for the wide variety of potential cutting agents, by discrimination between the target substance and a wide range of excipients. Near-infrared Raman spectroscopy (785 nm excitation) was employed to analyse 217 samples, a number of them consisting of a target analyte (acetaminophen) mixed with excipients of different concentrations by weight. The excipients used were sugars (maltose, glucose, lactose, sorbitol), inorganic materials (talcum powder, sodium bicarbonate, magnesium sulphate), and food products (caffeine, flour). The spectral data collected was subjected to a number of pre-treatment statistical methods including first derivative and normalisation transformations, to make the data more suitable for analysis. Various methods were then used to discriminate the target analytes, these included Principal Component Analysis (PCA), Principal Component Regression (PCR) and Support Vector Machines.},
  file = {/Users/chichen/Zotero/storage/55F829K2/O'Connell et al. - 2005 - Classification of a target analyte in solid mixtur.pdf;/Users/chichen/Zotero/storage/A3M8ASKB/12.605156.html}
}

@article{oviedoFastInterpretableClassification2019,
  title = {Fast and Interpretable Classification of Small {{X}}-Ray Diffraction Datasets Using Data Augmentation and Deep Neural Networks},
  author = {Oviedo, Felipe and Ren, Zekun and Sun, Shijing and Settens, Charles and Liu, Zhe and Hartono, Noor Titan Putri and Ramasamy, Savitha and DeCost, Brian L. and Tian, Siyu I. P. and Romano, Giuseppe and Gilad Kusne, Aaron and Buonassisi, Tonio},
  year = {2019},
  month = may,
  journal = {npj Computational Materials},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-019-0196-x},
  abstract = {X-ray diffraction (XRD) data acquisition and analysis is among the most time-consuming steps in the development cycle of novel thin-film materials. We propose a machine learning-enabled approach to predict crystallographic dimensionality and space group from a limited number of thin-film XRD patterns. We overcome the scarce data problem intrinsic to novel materials development by coupling a supervised machine learning approach with a model-agnostic, physics-informed data augmentation strategy using simulated data from the Inorganic Crystal Structure Database (ICSD) and experimental data. As a test case, 115 thin-film metal-halides spanning three dimensionalities and seven space groups are synthesized and classified. After testing various algorithms, we develop and implement an all convolutional neural network, with cross-validated accuracies for dimensionality and space group classification of 93 and 89\%, respectively. We propose average class activation maps, computed from a global average pooling layer, to allow high model interpretability by human experimentalists, elucidating the root causes of misclassification. Finally, we systematically evaluate the maximum XRD pattern step size (data acquisition rate) before loss of predictive accuracy occurs, and determine it to be 0.16\textdegree{} 2\texttheta, which enables an XRD pattern to be obtained and classified in 5.5\,min or less.},
  copyright = {2019 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods;Synthesis and processing Subject\_term\_id: characterization-and-analytical-techniques;computational-methods;synthesis-and-processing},
  file = {/Users/chichen/Zotero/storage/K3XGTC2X/Oviedo et al. - 2019 - Fast and interpretable classification of small X-r.pdf;/Users/chichen/Zotero/storage/3LF8T7LQ/s41524-019-0196-x.html}
}

@article{oviedoFastInterpretableClassification2019a,
  title = {Fast and Interpretable Classification of Small {{X}}-Ray Diffraction Datasets Using Data Augmentation and Deep Neural Networks},
  author = {Oviedo, Felipe and Ren, Zekun and Sun, Shijing and Settens, Charles and Liu, Zhe and Hartono, Noor Titan Putri and Ramasamy, Savitha and DeCost, Brian L. and Tian, Siyu I. P. and Romano, Giuseppe and Gilad Kusne, Aaron and Buonassisi, Tonio},
  year = {2019},
  month = may,
  journal = {npj Computational Materials},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-019-0196-x},
  abstract = {X-ray diffraction (XRD) data acquisition and analysis is among the most time-consuming steps in the development cycle of novel thin-film materials. We propose a machine learning-enabled approach to predict crystallographic dimensionality and space group from a limited number of thin-film XRD patterns. We overcome the scarce data problem intrinsic to novel materials development by coupling a supervised machine learning approach with a model-agnostic, physics-informed data augmentation strategy using simulated data from the Inorganic Crystal Structure Database (ICSD) and experimental data. As a test case, 115 thin-film metal-halides spanning three dimensionalities and seven space groups are synthesized and classified. After testing various algorithms, we develop and implement an all convolutional neural network, with cross-validated accuracies for dimensionality and space group classification of 93 and 89\%, respectively. We propose average class activation maps, computed from a global average pooling layer, to allow high model interpretability by human experimentalists, elucidating the root causes of misclassification. Finally, we systematically evaluate the maximum XRD pattern step size (data acquisition rate) before loss of predictive accuracy occurs, and determine it to be 0.16\textdegree{} 2\texttheta, which enables an XRD pattern to be obtained and classified in 5.5\,min or less.},
  copyright = {2019 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods;Synthesis and processing Subject\_term\_id: characterization-and-analytical-techniques;computational-methods;synthesis-and-processing},
  file = {/Users/chichen/Zotero/storage/H79LJEH7/Oviedo et al. - 2019 - Fast and interpretable classification of small X-r.pdf}
}

@article{parkClassificationCrystalStructure2017,
  title = {Classification of Crystal Structure Using a Convolutional Neural Network},
  author = {Park, W. B. and Chung, J. and Jung, J. and Sohn, K. and Singh, S. P. and Pyo, M. and Shin, N. and Sohn, K.-S.},
  year = {2017},
  month = jul,
  journal = {IUCrJ},
  volume = {4},
  number = {4},
  pages = {486--494},
  publisher = {{International Union of Crystallography}},
  issn = {2052-2525},
  doi = {10.1107/S205225251700714X},
  abstract = {A deep machine-learning technique based on a convolutional neural network (CNN) is introduced. It has been used for the classification of powder X-ray diffraction (XRD) patterns in terms of crystal system, extinction group and space group. About 150\hspace{0.25em}000 powder XRD patterns were collected and used as input for the CNN with no handcrafted engineering involved, and thereby an appropriate CNN architecture was obtained that allowed determination of the crystal system, extinction group and space group. In sharp contrast with the traditional use of powder XRD pattern analysis, the CNN never treats powder XRD patterns as a deconvoluted and discrete peak position or as intensity data, but instead the XRD patterns are regarded as nothing but a pattern similar to a picture. The CNN interprets features that humans cannot recognize in a powder XRD pattern. As a result, accuracy levels of 81.14, 83.83 and 94.99\% were achieved for the space-group, extinction-group and crystal-system classifications, respectively. The well trained CNN was then used for symmetry identification of unknown novel inorganic compounds.},
  copyright = {http://creativecommons.org/licenses/by/2.0/uk},
  language = {en},
  file = {/Users/chichen/Zotero/storage/L2DJ9L8Z/Park et al. - 2017 - Classification of crystal structure using a convol.pdf;/Users/chichen/Zotero/storage/FAFIR6AG/index.html}
}

@article{ramakrishnanQuantumChemistryStructures2014,
  title = {Quantum Chemistry Structures and Properties of 134 Kilo Molecules},
  author = {Ramakrishnan, Raghunathan and Dral, Pavlo O. and Rupp, Matthias and {von Lilienfeld}, O. Anatole},
  year = {2014},
  month = aug,
  journal = {Scientific Data},
  volume = {1},
  number = {1},
  pages = {140022},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2014.22},
  abstract = {Computational de novo design of new drugs and materials requires rigorous and unbiased exploration of chemical compound space. However, large uncharted territories persist due to its size scaling combinatorially with molecular size. We report computed geometric, energetic, electronic, and thermodynamic properties for 134k stable small organic molecules made up of CHONF. These molecules correspond to the subset of all 133,885 species with up to nine heavy atoms (CONF) out of the GDB-17 chemical universe of 166 billion organic molecules. We report geometries minimal in energy, corresponding harmonic frequencies, dipole moments, polarizabilities, along with energies, enthalpies, and free energies of atomization. All properties were calculated at the B3LYP/6-31G(2df,p) level of quantum chemistry. Furthermore, for the predominant stoichiometry, C7H10O2, there are 6,095 constitutional isomers among the 134k molecules. We report energies, enthalpies, and free energies of atomization at the more accurate G4MP2 level of theory for all of them. As such, this data set provides quantum chemical properties for a relevant, consistent, and comprehensive chemical space of small organic molecules. This database may serve the benchmarking of existing methods, development of new methods, such as hybrid quantum mechanics/machine learning, and systematic identification of structure-property relationships.},
  copyright = {2014 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Computational chemistry;Density functional theory;Quantum chemistry Subject\_term\_id: computational-chemistry;density-functional-theory;quantum-chemistry},
  file = {/Users/chichen/Zotero/storage/DQNCQ62C/Ramakrishnan et al. - 2014 - Quantum chemistry structures and properties of 134.pdf;/Users/chichen/Zotero/storage/SVL94QFV/sdata201422.html}
}

@article{ramirezApplicationsMachineLearning2020,
  title = {Applications of Machine Learning in Spectroscopy},
  author = {Ramirez, Carlos A. Meza and Greenop, Michael and Ashton, Lorna and ur Rehman, Ihtesham},
  year = {2020},
  month = dec,
  journal = {Applied Spectroscopy Reviews},
  volume = {0},
  number = {0},
  pages = {1--31},
  publisher = {{Taylor \& Francis}},
  issn = {0570-4928},
  doi = {10.1080/05704928.2020.1859525},
  abstract = {The way to analyze data in spectroscopy has changed substantially. At the same time, data science has evolved to the point where spectroscopy can find space to be housed, adapted and be functional. The integration of the two sciences has introduced a knowledge gap between data scientists who know about advanced machine learning techniques and spectroscopists who have a solid background in chemometrics. To reach a symbiosis, the knowledge gap requires bridging. This review article focuses on introducing data science subjects to non-specialist spectroscopists, or those unfamiliar with the subject. The article will explain concepts that are covered in machine learning, such as supervised learning, unsupervised learning, deep learning, and most importantly, the difference between machine learning and artificial intelligence. This article also includes examples of published spectroscopy research, in which some of the concepts explained here are applied. Machine learning together with spectroscopy can provide a useful, fast, and efficient tool to analyze samples of interest both for industrial and research purposes.},
  keywords = {artificial intelligence,chemometrics,data science,Infrared and Raman spectroscopy,Machine learning},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/05704928.2020.1859525},
  file = {/Users/chichen/Zotero/storage/V2UKE88I/05704928.2020.html}
}

@article{rankineDeepNeuralNetwork2020,
  title = {A {{Deep Neural Network}} for the {{Rapid Prediction}} of {{X}}-Ray {{Absorption Spectra}}},
  author = {Rankine, C. D. and Madkhali, M. M. M. and Penfold, T. J.},
  year = {2020},
  month = may,
  journal = {The Journal of Physical Chemistry A},
  volume = {124},
  number = {21},
  pages = {4263--4270},
  publisher = {{American Chemical Society}},
  issn = {1089-5639},
  doi = {10.1021/acs.jpca.0c03723},
  abstract = {X-ray spectroscopy delivers strong impact across the physical and biological sciences by providing end users with highly detailed information about the electronic and geometric structure of matter. To decode this information in challenging cases, e.g., in operando catalysts, batteries, and temporally evolving systems, advanced theoretical calculations are necessary. The complexity and resource requirements often render these out of reach for end users, and therefore, the data are often not interpreted exhaustively, leaving a wealth of valuable information unexploited. In this paper, we introduce supervised machine learning of X-ray absorption spectra through the development of a deep neural network (DNN) that is able to estimate Fe K-edge X-ray absorption near-edge structure spectra in less than a second with no input beyond geometric information about the local environment of the absorption site. We predict peak positions with sub-eV accuracy and peak intensities with errors over an order of magnitude smaller than the spectral variations that the model is engineered to capture. The performance of the DNN is promising, as illustrated by its application to the structural refinement of tris(bipyridine)iron(II) and nitrosylmyoglobin, but also highlights areas on which future developments should focus.},
  file = {/Users/chichen/Zotero/storage/KISXXVNP/Rankine et al. - 2020 - A Deep Neural Network for the Rapid Prediction of .pdf;/Users/chichen/Zotero/storage/USMKWDZU/acs.jpca.html}
}

@article{rehrParameterfreeCalculationsXray2010,
  title = {Parameter-Free Calculations of {{X}}-Ray Spectra with {{FEFF9}}},
  author = {Rehr, John J. and Kas, Joshua J. and Vila, Fernando D. and Prange, Micah P. and Jorissen, Kevin},
  year = {2010},
  month = may,
  journal = {Physical Chemistry Chemical Physics},
  volume = {12},
  number = {21},
  pages = {5503--5513},
  publisher = {{The Royal Society of Chemistry}},
  issn = {1463-9084},
  doi = {10.1039/B926434E},
  abstract = {We briefly review our implementation of the real-space Green's function (RSGF) approach for calculations of X-ray spectra, focusing on recently developed parameter free models for dominant many-body effects. Although the RSGF approach has been widely used both for near edge (XANES) and extended (EXAFS) ranges, previous implementations relied on semi-phenomenological methods, e.g., the plasmon-pole model for the self-energy, the final-state rule for screened core hole effects, and the correlated Debye model for vibrational damping. Here we describe how these approximations can be replaced by efficient ab initio models including a many-pole model of the self-energy, inelastic losses and multiple-electron excitations; a linear response approach for the core hole; and a Lanczos approach for Debye\textendash Waller effects. We also discuss the implementation of these models and software improvements within the FEFF9 code, together with a number of examples.},
  language = {en},
  file = {/Users/chichen/Zotero/storage/PHU7RF2E/b926434e.html}
}

@article{rojatExplainableArtificialIntelligence2021,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}) on {{TimeSeries Data}}: {{A Survey}}},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}}) on {{TimeSeries Data}}},
  author = {Rojat, Thomas and Puget, Rapha{\"e}l and Filliat, David and Del Ser, Javier and Gelin, Rodolphe and {D{\'i}az-Rodr{\'i}guez}, Natalia},
  year = {2021},
  month = apr,
  journal = {arXiv:2104.00950 [cs]},
  eprint = {2104.00950},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Most of state of the art methods applied on time series consist of deep learning methods that are too complex to be interpreted. This lack of interpretability is a major drawback, as several applications in the real world are critical tasks, such as the medical field or the autonomous driving field. The explainability of models applied on time series has not gather much attention compared to the computer vision or the natural language processing fields. In this paper, we present an overview of existing explainable AI (XAI) methods applied on time series and illustrate the type of explanations they produce. We also provide a reflection on the impact of these explanation methods to provide confidence and trust in the AI systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/chichen/Zotero/storage/H753I9XC/Rojat et al. - 2021 - Explainable Artificial Intelligence (XAI) on TimeS.pdf;/Users/chichen/Zotero/storage/XSJXYQKT/2104.html}
}

@article{schmeideTechnetiumImmobilizationChukanovite2021,
  title = {Technetium Immobilization by Chukanovite and Its Oxidative Transformation Products: {{Neural}} Network Analysis of {{EXAFS}} Spectra},
  shorttitle = {Technetium Immobilization by Chukanovite and Its Oxidative Transformation Products},
  author = {Schmeide, Katja and Rossberg, Andr{\'e} and Bok, Frank and Shams Aldin Azzam, Salim and Weiss, Stephan and Scheinost, Andreas C.},
  year = {2021},
  month = may,
  journal = {Science of The Total Environment},
  volume = {770},
  pages = {145334},
  issn = {0048-9697},
  doi = {10.1016/j.scitotenv.2021.145334},
  abstract = {The uptake of the fission product technetium (Tc) by chukanovite, an FeII hydroxy carbonate mineral formed as a carbon steel corrosion product in anoxic and carbonate-rich environments, was studied under anoxic, alkaline to hyperalkaline conditions representative for nuclear waste repositories in deep geological formations with cement-based inner linings. The retention potential of chukanovite towards TcVII is high in the pH range 7.8 to 12.6, evidenced by high solid-water distribution coefficients, log Rd~\textasciitilde ~6, and independent of ionic strength (0.1 or 1~M NaCl). Using Tc K-edge X-ray absorption spectroscopy (XAS) two series of samples were investigated, Tc chukanovite sorption samples and coprecipitates, prepared with varying Tc loadings, pH values and contact times. From the resulting 37 XAS spectra, spectral endmembers and their dependence on chemical parameters were derived by self-organizing (Kohonen) maps (SOM), a neural network-based approach of machine learning. X-ray absorption near-edge structure (XANES) data confirmed the complete reduction of TcVII to TcIV by chukanovite under all experimental conditions. Consistent with mineralogical phases identified by X-ray diffraction (XRD), SOM analysis of the extended X-ray absorption fine-structure (EXAFS) spectra revealed the presence of three species in the sorption samples, the speciation predominately controlled by pH: Between pH~7.8 and 11.8, TcO2-dimers form inner-sphere sorption complexes at the surface of the initial chukanovite as well as on the surface of secondary magnetite formed due to redox reaction. At pH~{$\geq~$}11.9, TcIV is incorporated in a mixed, chukanovite-like, Fe/Tc hydroxy carbonate precipitate. The same species formed when using the coprecipitation approach. Reoxidation of sorption samples resulted in a small remobilization of Tc, demonstrating that both the original chukanovite mineral and its oxidative transformation products, magnetite and goethite, contribute to the immobilization of Tc in the long term, thus strongly attenuating its environmental transport.},
  language = {en},
  keywords = {Goethite,Machine learning,Magnetite,Redox,XAS,XRD},
  file = {/Users/chichen/Zotero/storage/NRAPP6FG/Schmeide et al. - 2021 - Technetium immobilization by chukanovite and its o.pdf;/Users/chichen/Zotero/storage/4BX7GFZ4/S0048969721004010.html}
}

@article{schuetzkeEnhancingDeeplearningTraining2021,
  title = {Enhancing Deep-Learning Training for Phase Identification in Powder {{X}}-Ray Diffractograms},
  author = {Schuetzke, J. and Benedix, A. and Mikut, R. and Reischl, M.},
  year = {2021},
  month = may,
  journal = {IUCrJ},
  volume = {8},
  number = {3},
  pages = {408--420},
  publisher = {{International Union of Crystallography}},
  issn = {2052-2525},
  doi = {10.1107/S2052252521002402},
  abstract = {A framework is described for the efficient and realistic simulation of X-ray diffraction scans to train machine- or deep-learning models like convolutional neural networks for the automatic phase-identification task in multiphase compounds.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  language = {en},
  file = {/Users/chichen/Zotero/storage/5QFQ6EE7/Schuetzke et al. - 2021 - Enhancing deep-learning training for phase identif.pdf}
}

@article{suzukiSymmetryPredictionKnowledge2020,
  title = {Symmetry Prediction and Knowledge Discovery from {{X}}-Ray Diffraction Patterns Using an Interpretable Machine Learning Approach},
  author = {Suzuki, Yuta and Hino, Hideitsu and Hawai, Takafumi and Saito, Kotaro and Kotsugi, Masato and Ono, Kanta},
  year = {2020},
  month = dec,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {21790},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-77474-4},
  abstract = {Determination of crystal system and space group in the initial stages of crystal structure analysis forms a bottleneck in material science workflow that often requires manual tuning. Herein we propose a machine-learning (ML)-based approach for crystal system and space group classification based on powder X-ray diffraction (XRD) patterns as a proof of concept using simulated patterns. Our tree-ensemble-based ML model works with nearly or over 90\% accuracy for crystal system classification, except for triclinic cases, and with 88\% accuracy for space group classification with five candidates. We also succeeded in quantifying empirical knowledge vaguely shared among experts, showing the possibility for data-driven discovery of unrecognised characteristics embedded in experimental data by using an interpretable ML approach.},
  copyright = {2020 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Structure of solids and liquids Subject\_term\_id: characterization-and-analytical-techniques;structure-of-solids-and-liquids},
  file = {/Users/chichen/Zotero/storage/MVX3VDTA/Suzuki et al. - 2020 - Symmetry prediction and knowledge discovery from X.pdf}
}

@article{szymanskiProbabilisticDeepLearning2021,
  title = {Probabilistic {{Deep Learning Approach}} to {{Automate}} the {{Interpretation}} of {{Multi}}-Phase {{Diffraction Spectra}}},
  author = {Szymanski, Nathan J. and Bartel, Christopher J. and Zeng, Yan and Tu, Qingsong and Ceder, Gerbrand},
  year = {2021},
  month = jun,
  journal = {Chemistry of Materials},
  volume = {33},
  number = {11},
  pages = {4204--4215},
  publisher = {{American Chemical Society}},
  issn = {0897-4756},
  doi = {10.1021/acs.chemmater.1c01071},
  abstract = {Autonomous synthesis and characterization of inorganic materials require the automatic and accurate analysis of X-ray diffraction spectra. For this task, we designed a probabilistic deep learning algorithm to identify complex multi-phase mixtures. At the core of this algorithm lies an ensemble convolutional neural network trained on simulated diffraction spectra, which are systematically augmented with physics-informed perturbations to account for artifacts that can arise during experimental sample preparation and synthesis. Larger perturbations associated with off-stoichiometry are also captured by supplementing the training set with hypothetical solid solutions. Spectra containing mixtures of materials are analyzed with a newly developed branching algorithm that utilizes the probabilistic nature of the neural network to explore suspected mixtures and identify the set of phases that maximize confidence in the prediction. Our model is benchmarked on simulated and experimentally measured diffraction spectra, showing exceptional performance with accuracies exceeding those given by previously reported methods based on profile matching and deep learning. We envision that the algorithm presented here may be integrated in experimental workflows to facilitate the high-throughput and autonomous discovery of inorganic materials.},
  file = {/Users/chichen/Zotero/storage/2A6WLNG8/Szymanski et al. - 2021 - Probabilistic Deep Learning Approach to Automate t.pdf;/Users/chichen/Zotero/storage/7EWR73NK/acs.chemmater.html}
}

@article{TheoreticalSurfaceScience2000,
  title = {Theoretical Surface Science and Catalysis\textemdash Calculations and Concepts},
  year = {2000},
  month = jan,
  journal = {Advances in Catalysis},
  volume = {45},
  pages = {71--129},
  publisher = {{Academic Press}},
  issn = {0360-0564},
  doi = {10.1016/S0360-0564(02)45013-4},
  abstract = {The application of density functional theory to calculate adsorption properties, reaction pathways, and activation energies for surface chemical react\ldots},
  language = {en},
  file = {/Users/chichen/Zotero/storage/4SG2UPEL/S0360056402450134.html}
}

@inproceedings{tianRapidAccurateThin2020,
  title = {Rapid and {{Accurate Thin Film Thickness Extraction}} via {{UV}}-{{Vis}} and {{Machine Learning}}},
  booktitle = {2020 47th {{IEEE Photovoltaic Specialists Conference}} ({{PVSC}})},
  author = {Tian, Siyu Isaac Parker and Liu, Zhe and Chellappan, Vijila and Lim, Yee-Fun and Ren, Zekun and Oviedo, Felipe and Teo, B. Heng and Thapa, Janak and Dutta, Rajdeep and MacLeod, Benjamin P and Parlane, Fraser G. L. and Senthilnath, J. and Berlinguette, Curtis P. and Buonassisi, Tonio},
  year = {2020},
  month = jun,
  pages = {0128--0132},
  issn = {0160-8371},
  doi = {10.1109/PVSC45281.2020.9300634},
  abstract = {Thin-film processes are ubiquitous in photovoltaics research and are increasingly incorporated into high-throughput experimentation (HTE) equipment. However, HTE is limited by the slowest steps, and accurate thickness measurements have emerged as a bottleneck. This study demonstrates rapid yet accurate thin-film thickness extraction by leveraging machine learning (ML) in combination with non-destructive optical measurements (UV-Vis). We achieve 86.9\% accuracy of thickness prediction within 10-percentage-error bounds on simulated data.},
  keywords = {artificial intelligence,autonomous lab,ellipsometry,Feature extraction,high-throughput,HTE,Inverse problems,machine learning,Mathematical model,optical properties,Predictive models,refractive index,Shape,spectrophotometry,Task analysis,thickness,thin film,Training,UV-Vis},
  file = {/Users/chichen/Zotero/storage/XW2H7SUP/Tian et al. - 2020 - Rapid and Accurate Thin Film Thickness Extraction .pdf}
}

@article{timoshenkosubnano2018,
author = {Timoshenko, Janis and Halder, Avik and Yang, Bing and Seifert, Soenke and Pellin, Michael J. and Vajda, Stefan and Frenkel, Anatoly I.},
title = {Subnanometer Substructures in Nanoassemblies Formed from Clusters under a Reactive Atmosphere Revealed Using Machine Learning},
journal = {The Journal of Physical Chemistry C},
volume = {122},
number = {37},
pages = {21686-21693},
year = {2018},
doi = {10.1021/acs.jpcc.8b07952},

URL = { 
        https://doi.org/10.1021/acs.jpcc.8b07952
    
},
eprint = { 
        https://doi.org/10.1021/acs.jpcc.8b07952
    
}

}

@article{timoshenkoNeuralNetworkApproach2018,
  title = {Neural {{Network Approach}} for {{Characterizing Structural Transformations}} by {{X}}-{{Ray Absorption Fine Structure Spectroscopy}}},
  author = {Timoshenko, Janis and Anspoks, Andris and Cintins, Arturs and Kuzmin, Alexei and Purans, Juris and Frenkel, Anatoly I.},
  year = {2018},
  month = may,
  journal = {Physical Review Letters},
  volume = {120},
  number = {22},
  pages = {225502},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.120.225502},
  abstract = {The knowledge of the coordination environment around various atomic species in many functional materials provides a key for explaining their properties and working mechanisms. Many structural motifs and their transformations are difficult to detect and quantify in the process of work (operando conditions), due to their local nature, small changes, low dimensionality of the material, and/or extreme conditions. Here we use an artificial neural network approach to extract the information on the local structure and its in situ changes directly from the x-ray absorption fine structure spectra. We illustrate this capability by extracting the radial distribution function (RDF) of atoms in ferritic and austenitic phases of bulk iron across the temperature-induced transition. Integration of RDFs allows us to quantify the changes in the iron coordination and material density, and to observe the transition from a body-centered to a face-centered cubic arrangement of iron atoms. This method is attractive for a broad range of materials and experimental conditions.},
  file = {/Users/chichen/Zotero/storage/IXTLKDWQ/Timoshenko et al. - 2018 - Neural Network Approach for Characterizing Structu.pdf}
}

@article{ewels_sikora_serin_ewels_lajaunie_2016, title={A Complete Overhaul of the Electron Energy-Loss Spectroscopy and X-Ray Absorption Spectroscopy Database: eelsdb.eu}, volume={22}, DOI={10.1017/S1431927616000179}, number={3}, journal={Microscopy and Microanalysis}, publisher={Cambridge University Press}, author={Ewels, Philip and Sikora, Thierry and Serin, Virginie and Ewels, Chris P. and Lajaunie, Luc}, year={2016}, pages={717–724}}

@article{timoshenkoSupervisedMachineLearningBasedDetermination2017,
  title = {Supervised {{Machine}}-{{Learning}}-{{Based Determination}} of {{Three}}-{{Dimensional Structure}} of {{Metallic Nanoparticles}}},
  author = {Timoshenko, Janis and Lu, Deyu and Lin, Yuewei and Frenkel, Anatoly I.},
  year = {2017},
  month = oct,
  journal = {The Journal of Physical Chemistry Letters},
  volume = {8},
  number = {20},
  pages = {5091--5098},
  publisher = {{American Chemical Society}},
  doi = {10.1021/acs.jpclett.7b02364},
  abstract = {Tracking the structure of heterogeneous catalysts under operando conditions remains a challenge due to the paucity of experimental techniques that can provide atomic-level information for catalytic metal species. Here we report on the use of X-ray absorption near-edge structure (XANES) spectroscopy and supervised machine learning (SML) for refining the 3D geometry of metal catalysts. SML is used to unravel the hidden relationship between the XANES features and catalyst geometry. To train our SML method, we rely on ab initio XANES simulations. Our approach allows one to solve the structure of a metal catalyst from its experimental XANES, as demonstrated here by reconstructing the average size, shape, and morphology of well-defined platinum nanoparticles. This method is applicable to the determination of the nanoparticle structure in operando studies and can be generalized to other nanoscale systems. It also allows on-the-fly XANES analysis and is a promising approach for high-throughput and time-dependent studies.}
}

@article{tiongIdentificationCrystalSymmetry2020,
  title = {Identification of Crystal Symmetry from Noisy Diffraction Patterns by a Shape Analysis and Deep Learning},
  author = {Tiong, Leslie Ching Ow and Kim, Jeongrae and Han, Sang Soo and Kim, Donghun},
  year = {2020},
  month = dec,
  journal = {npj Computational Materials},
  volume = {6},
  number = {1},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-020-00466-5},
  abstract = {The robust and automated determination of crystal symmetry is of utmost importance in material characterization and analysis. Recent studies have shown that deep learning (DL) methods can effectively reveal the correlations between X-ray or electron-beam diffraction patterns and crystal symmetry. Despite their promise, most of these studies have been limited to identifying relatively few classes into which a target material may be grouped. On the other hand, the DL-based identification of crystal symmetry suffers from a drastic drop in accuracy for problems involving classification into tens or hundreds of symmetry classes (e.g., up to 230 space groups), severely limiting its practical usage. Here, we demonstrate that a combined approach of shaping diffraction patterns and implementing them in a multistream DenseNet (MSDN) substantially improves the accuracy of classification. Even with an imbalanced dataset of 108,658 individual crystals sampled from 72 space groups, our model achieves 80.12\,{$\pm$}\,0.09\% space group classification accuracy, outperforming conventional benchmark models by 17\textendash 27 percentage points (\%p). The enhancement can be largely attributed to the pattern shaping strategy, through which the subtle changes in patterns between symmetrically close crystal systems (e.g., monoclinic vs. orthorhombic or trigonal vs. hexagonal) are well differentiated. We additionally find that the MSDN architecture is advantageous for capturing patterns in a richer but less redundant manner relative to conventional convolutional neural networks. The proposed protocols in regard to both input descriptor processing and DL architecture enable accurate space group classification and thus improve the practical usage of the DL approach in crystal symmetry identification.},
  copyright = {2020 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Characterization and analytical techniques;Computational methods;Imaging techniques Subject\_term\_id: characterization-and-analytical-techniques;computational-methods;imaging-techniques},
  file = {/Users/chichen/Zotero/storage/V3Z2MPAB/Tiong et al. - 2020 - Identification of crystal symmetry from noisy diff.pdf}
}

@article{torrisiRandomForestMachine2020,
  title = {Random Forest Machine Learning Models for Interpretable {{X}}-Ray Absorption near-Edge Structure Spectrum-Property Relationships},
  author = {Torrisi, Steven B. and Carbone, Matthew R. and Rohr, Brian A. and Montoya, Joseph H. and Ha, Yang and Yano, Junko and Suram, Santosh K. and Hung, Linda},
  year = {2020},
  month = jul,
  journal = {npj Computational Materials},
  volume = {6},
  number = {1},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-020-00376-6},
  abstract = {X-ray absorption spectroscopy (XAS) produces a wealth of information about the local structure of materials, but interpretation of spectra often relies on easily accessible trends and prior assumptions about the structure. Recently, researchers have demonstrated that machine learning models can automate this process to predict the coordinating environments of absorbing atoms from their XAS spectra. However, machine learning models are often difficult to interpret, making it challenging to determine when they are valid and whether they are consistent with physical theories. In this work, we present three main advances to the data-driven analysis of XAS spectra: we demonstrate the efficacy of random forests in solving two new property determination tasks (predicting Bader charge and mean nearest neighbor distance), we address how choices in data representation affect model interpretability and accuracy, and we show that multiscale featurization can elucidate the regions and trends in spectra that encode various local properties. The multiscale featurization transforms the spectrum into a vector of polynomial-fit features, and is contrasted with the commonly-used ``pointwise'' featurization that directly uses the entire spectrum as input. We find that across thousands of transition metal oxide spectra, the relative importance of features describing the curvature of the spectrum can be localized to individual energy ranges, and we can separate the importance of constant, linear, quadratic, and cubic trends, as well as the white line energy. This work has the potential to assist rigorous theoretical interpretations, expedite experimental data collection, and automate analysis of XAS spectra, thus accelerating the discovery of new functional materials.},
  copyright = {2020 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Atomistic models;Characterization and analytical techniques;Structure of solids and liquids;Theoretical chemistry Subject\_term\_id: atomistic-models;characterization-and-analytical-techniques;structure-of-solids-and-liquids;theoretical-chemistry},
  file = {/Users/chichen/Zotero/storage/TDQH9X47/Torrisi et al. - 2020 - Random forest machine learning models for interpre.pdf;/Users/chichen/Zotero/storage/QJLQ4UNK/s41524-020-00376-6.html}
}

@article{utimulaMachineLearningClusteringTechnique2020,
  title = {Machine-{{Learning Clustering Technique Applied}} to {{Powder X}}-{{Ray Diffraction Patterns}} to {{Distinguish Compositions}} of {{ThMn12}}-{{Type Alloys}}},
  author = {Utimula, Keishu and Hunkao, Rutchapon and Yano, Masao and Kimoto, Hiroyuki and Hongo, Kenta and Kawaguchi, Shogo and Suwanna, Sujin and Maezono, Ryo},
  year = {2020},
  journal = {Advanced Theory and Simulations},
  volume = {3},
  number = {7},
  pages = {2000039},
  issn = {2513-0390},
  doi = {10.1002/adts.202000039},
  abstract = {A clustering technique is applied using dynamic-time-wrapping (DTW) analysis to X-ray diffraction (XRD) spectrum patterns in order to identify the microscopic structures of substituents introduced into the main phase of magnetic alloys. The clustering technique is found to perform well, identifying the concentrations of the substituents with success rates of {$\approx$}90\%. This level of performance is attributed to the capability of DTW processing to filter out irrelevant information such as the peak intensities (due to the uncontrollability of diffraction conditions in polycrystalline samples) and the uniform shift of peak positions (due to the thermal expansion of lattices). The established framework is not limited to the system treated in this work, but is widely applicable to systems the properties of which are to be tuned by atomic substitutions within a phase. The framework has a broader potential to predict properties such as magnetic moments, optical spectra etc.) from observed XRD patterns, by predicting such properties evaluated from predicted microscopic local structure.},
  language = {en},
  keywords = {dynamic time wrapping,machine learning,magnetic alloys},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adts.202000039},
  file = {/Users/chichen/Zotero/storage/Q64WKVLW/Utimula et al. - 2020 - Machine-Learning Clustering Technique Applied to P.pdf}
}

@article{deepfreak2019,
  author    = {Artur L. F. Souza and
               Leonardo B. Oliveira and
               Sabine Hollatz and
               Matthew Feldman and
               Kunle Olukotun and
               James M. Holton and
               Aina E. Cohen and
               Luigi Nardi},
  title     = {DeepFreak: Learning Crystallography Diffraction Patterns with Automated
               Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1904.11834},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.11834},
  eprinttype = {arXiv},
  eprint    = {1904.11834},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-11834.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kim_tiong_kim_han_2021, title={Deep Learning-Based Prediction of Material Properties Using Chemical Compositions and Diffraction Patterns as Experimentally Accessible Inputs}, volume={12}, DOI={10.1021/acs.jpclett.1c02305}, number={34}, journal={The Journal of Physical Chemistry Letters}, author={Kim, Jeongrae and Tiong, Leslie Ching Ow and Kim, Donghun and Han, Sang Soo}, year={2021}, pages={8376–8383}}

@article{meyer_dellby_hachtel_lovejoy_mittelberger_krivanek_2019, title={Nion Swift: Open Source Image Processing Software for Instrument Control, Data Acquisition, Organization, Visualization, and Analysis Using Python.}, volume={25}, DOI={10.1017/s143192761900134x}, number={S2}, journal={Microscopy and Microanalysis}, author={Meyer, Chris and Dellby, Niklas and Hachtel, Jordan A. and Lovejoy, Tracy and Mittelberger, Andreas and Krivanek, Ondrej}, year={2019}, pages={122–123}}

@article{maxim_jesse_sumpter_kalinin_dyck_2020, title={Tracking atomic structure evolution during directed electron beam induced Si-atom motion in graphene via deep machine learning}, volume={32}, DOI={10.1088/1361-6528/abb8a6}, number={3}, journal={Nanotechnology}, author={Maxim, Ziatdinov and Jesse, Stephen and Sumpter, Bobby G and Kalinin, Sergei V and Dyck, Ondrej}, year={2020}, pages={035703}}

@article{elhefnawy_li_wang_li_2020, title={DeepFrag-k: a fragment-based deep learning approach for protein fold recognition}, volume={21}, DOI={10.1186/s12859-020-3504-z}, number={S6}, journal={BMC Bioinformatics}, author={Elhefnawy, Wessam and Li, Min and Wang, Jianxin and Li, Yaohang}, year={2020}}

@inproceedings{Gardner2017AllenNLP,
  title={AllenNLP: A Deep Semantic Natural Language Processing Platform},
  author={Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord
    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and
    Michael Schmitz and Luke S. Zettlemoyer},
  year={2017},
  Eprint = {arXiv:1803.07640},
}

@article{xue_2010, title={Steven Bird, Evan Klein and Edward Loper. Natural Language Processing with Python. OReilly Media, Inc.2009. ISBN: 978-0-596-51649-9.}, volume={17}, DOI={10.1017/s1351324910000306}, number={3}, journal={Natural Language Engineering}, author={Xue, Nianwen}, year={2010}, pages={419–424}}

@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}

@article{decost_hecht_francis_webler_picard_holm_2017, title={UHCSDB: UltraHigh Carbon Steel Micrograph DataBase}, volume={6}, DOI={10.1007/s40192-017-0097-0}, number={2}, journal={Integrating Materials and Manufacturing Innovation}, author={Decost, Brian L. and Hecht, Matthew D. and Francis, Toby and Webler, Bryan A. and Picard, Yoosuf N. and Holm, Elizabeth A.}, year={2017}, pages={197–205}}

@article{decost_lei_francis_holm_2019, title={High Throughput Quantitative Metallography for Complex Microstructures Using Deep Learning: A Case Study in Ultrahigh Carbon Steel}, volume={25}, DOI={10.1017/s1431927618015635}, number={1}, journal={Microscopy and Microanalysis}, author={Decost, Brian L. and Lei, Bo and Francis, Toby and Holm, Elizabeth A.}, year={2019}, pages={21–29}}


@article{wangRapidIdentificationXray2020,
  title = {Rapid {{Identification}} of {{X}}-Ray {{Diffraction Patterns Based}} on {{Very Limited Data}} by {{Interpretable Convolutional Neural Networks}}},
  author = {Wang, Hong and Xie, Yunchao and Li, Dawei and Deng, Heng and Zhao, Yunxin and Xin, Ming and Lin, Jian},
  year = {2020},
  month = apr,
  journal = {Journal of Chemical Information and Modeling},
  volume = {60},
  number = {4},
  pages = {2004--2011},
  publisher = {{American Chemical Society}},
  issn = {1549-9596},
  doi = {10.1021/acs.jcim.0c00020},
  abstract = {Large volumes of data from material characterizations call for rapid and automatic data analysis to accelerate materials discovery. Herein, we report a convolutional neural network (CNN) that was trained based on theoretical data and very limited experimental data for fast identification of experimental X-ray diffraction (XRD) patterns of metal\textendash organic frameworks (MOFs). To augment the data for training the model, noise was extracted from experimental data and shuffled; then it was merged with the main peaks that were extracted from theoretical spectra to synthesize new spectra. For the first time, one-to-one material identification was achieved. Theoretical MOFs patterns (1012) were augmented to a whole data set of 72 864 samples. It was then randomly shuffled and split into training (58 292 samples) and validation (14 572 samples) data sets at a ratio of 4:1. For the task of discriminating, the optimized model showed the highest identification accuracy of 96.7\% for the top 5 ranking on a test data set of 30 hold-out samples. Neighborhood component analysis (NCA) on the experimental XRD samples shows that the samples from the same material are clustered in groups in the NCA map. Analysis on the class activation maps of the last CNN layer further discloses the mechanism by which the CNN model successfully identifies individual MOFs from the XRD patterns. This CNN model trained by the data augmentation technique would not only open numerous potential applications for identifying XRD patterns for different materials, but also pave avenues to autonomously analyze data by other characterization tools such as FTIR, Raman, and NMR spectroscopies.},
  file = {/Users/chichen/Zotero/storage/HXIXLUHH/Wang et al. - 2020 - Rapid Identification of X-ray Diffraction Patterns.pdf;/Users/chichen/Zotero/storage/TXMFF28U/acs.jcim.html}
}

@article{yangDeepLearningVibrational2019,
  title = {Deep Learning for Vibrational Spectral Analysis: {{Recent}} Progress and a Practical Guide},
  shorttitle = {Deep Learning for Vibrational Spectral Analysis},
  author = {Yang, Jie and Xu, Jinfan and Zhang, Xiaolei and Wu, Chiyu and Lin, Tao and Ying, Yibin},
  year = {2019},
  month = nov,
  journal = {Analytica Chimica Acta},
  volume = {1081},
  pages = {6--17},
  issn = {0003-2670},
  doi = {10.1016/j.aca.2019.06.012},
  abstract = {The development of chemometrics aims to provide an effective analysis approach for data generated by advanced analytical instruments. The success of existing analytical approaches in spectral analysis still relies on preprocessing and feature selection techniques to remove signal artifacts based on prior experiences. Data-driven deep learning analysis has been developed and successfully applied in many domains in the last few years. How to integrate deep learning with spectral analysis received increased attention for chemometrics. Approximately 20 recently published studies demonstrate that deep neural networks can learn critical patterns from raw spectra, which significantly reduces the demand for feature engineering. The composition of multiple processing layers improves the fitting and feature extraction capability and makes them applicable to various analytical tasks. This advance offers a new solution for chemometrics toward resolving challenges related to spectral data with rapidly increased sample numbers from various sources. We further provide a practical guide to the development of a deep convolutional neural network-based analytical workflow. The design of the network structure, tuning the hyperparameters in the training process, and repeatability of results is mainly discussed. Future studies are needed on interpretability and repeatability of the deep learning approach in spectral analysis.},
  language = {en},
  keywords = {Analysis,Artificial intelligence,Chemometrics,Convolutional neural network,Deep learning,Spectroscopy},
  file = {/Users/chichen/Zotero/storage/QB29FI3I/S0003267019307342.html}
}

@article{yangDeepLearningVibrational2019a,
  title = {Deep Learning for Vibrational Spectral Analysis: {{Recent}} Progress and a Practical Guide},
  shorttitle = {Deep Learning for Vibrational Spectral Analysis},
  author = {Yang, Jie and Xu, Jinfan and Zhang, Xiaolei and Wu, Chiyu and Lin, Tao and Ying, Yibin},
  year = {2019},
  month = nov,
  journal = {Analytica Chimica Acta},
  volume = {1081},
  pages = {6--17},
  issn = {0003-2670},
  doi = {10.1016/j.aca.2019.06.012},
  abstract = {The development of chemometrics aims to provide an effective analysis approach for data generated by advanced analytical instruments. The success of existing analytical approaches in spectral analysis still relies on preprocessing and feature selection techniques to remove signal artifacts based on prior experiences. Data-driven deep learning analysis has been developed and successfully applied in many domains in the last few years. How to integrate deep learning with spectral analysis received increased attention for chemometrics. Approximately 20 recently published studies demonstrate that deep neural networks can learn critical patterns from raw spectra, which significantly reduces the demand for feature engineering. The composition of multiple processing layers improves the fitting and feature extraction capability and makes them applicable to various analytical tasks. This advance offers a new solution for chemometrics toward resolving challenges related to spectral data with rapidly increased sample numbers from various sources. We further provide a practical guide to the development of a deep convolutional neural network-based analytical workflow. The design of the network structure, tuning the hyperparameters in the training process, and repeatability of results is mainly discussed. Future studies are needed on interpretability and repeatability of the deep learning approach in spectral analysis.},
  language = {en},
  keywords = {Analysis,Artificial intelligence,Chemometrics,Convolutional neural network,Deep learning,Spectroscopy}
}

@article{zalogaCrystalSymmetryClassification2020,
  title = {Crystal Symmetry Classification from Powder {{X}}-Ray Diffraction Patterns Using a Convolutional Neural Network},
  author = {Zaloga, Alexander N. and Stanovov, Vladimir V. and Bezrukova, Oksana E. and Dubinin, Petr S. and Yakimov, Igor S.},
  year = {2020},
  month = dec,
  journal = {Materials Today Communications},
  volume = {25},
  pages = {101662},
  issn = {2352-4928},
  doi = {10.1016/j.mtcomm.2020.101662},
  abstract = {A convolutional artificial neural network was applied to identify crystal systems and symmetry space groups by full-profile X-ray diffraction patterns calculated from crystal structures of the ICSD 2017 database. The database contains 192 004 crystal structures; 80 \% of them were used as a training dataset, and the other 20 \% were used as a test dataset to establish the accuracy of classification. The neural network identified crystal systems correctly for 90.02 \% of structures and space groups for 79.82 \% of structures from the test dataset. Factors affecting the classification accuracy were established. The first, nonlinear normalization of intensities of diffraction peaks increases the accuracy, and the second, the accuracy depends on the number of structures represented in each space group.},
  language = {en},
  keywords = {Artificial neural networks,Crystal systems,Powder diffraction,Space groups},
  file = {/Users/chichen/Zotero/storage/89W3PA2W/Zaloga et al. - 2020 - Crystal symmetry classification from powder X-ray .pdf}
}

@article{zhangKnockdownCytochromeP4502019,
  title = {Knockdown of Cytochrome {{P450 CYP6}} Family Genes Increases Susceptibility to Carbamates and Pyrethroids in the Migratory Locust, {{Locusta}} Migratoria},
  author = {Zhang, Xueyao and Dong, Jie and Wu, Haihua and Zhang, Haihan and Zhang, Jianzhen and Ma, Enbo},
  year = {2019},
  month = may,
  journal = {Chemosphere},
  volume = {223},
  pages = {48--57},
  issn = {0045-6535},
  doi = {10.1016/j.chemosphere.2019.02.011},
  abstract = {Insect cytochrome P450 monooxygenase (CYP) plays a key role in the detoxification of insecticides. In this study, four cDNA sequences of CYP6 genes were identified and characterized. Transcription levels of LmCYP6HC1 and LmCYP6HCL1 were high in first- and fourth-instar nymph stages, respectively. LmCYP6HN1 was primarily expressed in the egg to third-instar nymph stages, while LmCYP6HQ1 was predominantly expressed in the stages from fourth-instar nymph to the adult. The four CYP6 genes were predominantly distributed in the antenna, brain, fat body, integument, and hemolymph. Piperonyl butoxide exposure inhibited total CYP activity and synergized the toxicity of carbamates and pyrethroids. Knockdown of LmCYP6HL1, LmCYP6HN1, and LmCYP6HQ1 increased nymph mortality following exposure to carbaryl, and silencing of LmCYP6HC1, LmCYP6HL1, LmCYP6HN1, and LmCYP6HQ1 comprehensively raised nymph mortality following exposure to fluvalinate. Knockdown of LmCYP6HL1 or LmCYP6HN1 significantly increased nymph mortality following exposure to cypermethrin or fenvalerate, respectively. These results suggest that the CYP6 family plays a key role in determining the susceptibility of Locusta migratoria to both carbamates and pyrethroids.},
  language = {en},
  keywords = {Carbamates,Cytochrome P450 monooxygenase,Pyrethroids,Susceptibility},
  file = {/Users/chichen/Zotero/storage/446VVWP4/S0045653519302279.html}
}
@article{stanev2018machine,
  title={Machine learning modeling of superconducting critical temperature},
  author={Stanev, Valentin and Oses, Corey and Kusne, A Gilad and Rodriguez, Efrain and Paglione, Johnpierre and Curtarolo, Stefano and Takeuchi, Ichiro},
  journal={npj Computational Materials},
  volume={4},
  number={1},
  pages={1--14},
  year={2018},
  publisher={Nature Publishing Group}
}
@inproceedings{zhaoApplicationMachineLearning2018,
  title = {Application of Machine Learning to X-Ray Diffraction-Based Classification},
  booktitle = {Anomaly {{Detection}} and {{Imaging}} with {{X}}-{{Rays}} ({{ADIX}}) {{III}}},
  author = {Zhao, Bi and Wolter, Scott and Greenberg, Joel A.},
  year = {2018},
  month = may,
  volume = {10632},
  pages = {1063205},
  publisher = {{International Society for Optics and Photonics}},
  doi = {10.1117/12.2304683},
  abstract = {X-ray diffraction-based baggage screening provides the potential for the material sensitivity needed to realize high detection probabilities and low false alarm rates. However, the combination of noisy signals, variability in the XRD form factors based on slight material differences, and incomplete material libraries lead to decreased system performance. By using a machine learning classification approach to XRD-based explosives detection, we show that the probability of error can be reduced relative to traditional, correlation-based classifiers. This improved performance exists at a variety of noise levels and degrees of library completeness, and indicates a path toward increased XRD-based classifier robustness.},
  file = {/Users/chichen/Zotero/storage/56KR69YN/Zhao et al. - 2018 - Application of machine learning to x-ray diffracti.pdf;/Users/chichen/Zotero/storage/NTGQRSKS/12.2304683.html}
}

@article{zhaoQualitativeIdentificationTea2006,
  title = {Qualitative Identification of Tea Categories by near Infrared Spectroscopy and Support Vector Machine},
  author = {Zhao, Jiewen and Chen, Quansheng and Huang, Xingyi and Fang, C. H.},
  year = {2006},
  month = jun,
  journal = {Journal of Pharmaceutical and Biomedical Analysis},
  volume = {41},
  number = {4},
  pages = {1198--1204},
  issn = {0731-7085},
  doi = {10.1016/j.jpba.2006.02.053},
  abstract = {Near-infrared (NIR) spectroscopy has been successfully utilized for the rapid identification of green, black and Oolong tea. The spectral features of each tea category are reasonably differentiated in the NIR region, and the spectral differences provided enough qualitative spectral information for the identification of tea. Support vector machine (SVM) as the pattern recognition was applied to identify three tea categories in this study. The top five principal components (PCs) were extracted as the input of SVM classifiers by principal component analysis (PCA). The RBF SVM classifiers and the polynomial SVM classifiers were studied comparatively in this experiment. The best experimental results were obtained using the radial basis function (RBF) SVM classifier with {$\sigma$}=0.5. The accuracies of identification were all more than 90\% for three tea categories. Finally, compared with the back propagation artificial neural network (BP-ANN) approach, SVM algorithm showed its excellent generalization for identification results. The overall results show that NIR spectroscopy combined with SVM can be efficiently utilized for rapid and simple identification of the tea categories.},
  language = {en},
  keywords = {Identification,NIR spectroscopy,Support vector machine,Tea},
  file = {/Users/chichen/Zotero/storage/7D7BB3TQ/S0731708506002329.html}
}

@article{zhengAutomatedGenerationEnsemblelearned2018,
  title = {Automated Generation and Ensemble-Learned Matching of {{X}}-Ray Absorption Spectra},
  author = {Zheng, Chen and Mathew, Kiran and Chen, Chi and Chen, Yiming and Tang, Hanmei and Dozier, Alan and Kas, Joshua J. and Vila, Fernando D. and Rehr, John J. and Piper, Louis F. J. and Persson, Kristin A. and Ong, Shyue Ping},
  year = {2018},
  month = mar,
  journal = {npj Computational Materials},
  volume = {4},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2057-3960},
  doi = {10.1038/s41524-018-0067-x},
  abstract = {X-ray absorption spectroscopy (XAS) is a widely used materials characterization technique to determine oxidation states, coordination environment, and other local atomic structure information. Analysis of XAS relies on comparison of measured spectra to reliable reference spectra. However, existing databases of XAS spectra are highly limited both in terms of the number of reference spectra available as well as the breadth of chemistry coverage. In this work, we report the development of XASdb, a large database of computed reference XAS, and an Ensemble-Learned Spectra IdEntification (ELSIE) algorithm for the matching of spectra. XASdb currently hosts more than 800,000 K-edge X-ray absorption near-edge spectra (XANES) for over 40,000 materials from the open-science Materials Project database. We discuss a high-throughput automation framework for FEFF calculations, built on robust, rigorously benchmarked parameters. FEFF is a computer program uses a real-space Green's function approach to calculate X-ray absorption spectra. We will demonstrate that the ELSIE algorithm, which combines 33 weak ``learners'' comprising a set of preprocessing steps and a similarity metric, can achieve up to 84.2\% accuracy in identifying the correct oxidation state and coordination environment of a test set of 19 K-edge XANES spectra encompassing a diverse range of chemistries and crystal structures. The XASdb with the ELSIE algorithm has been integrated into a web application in the Materials Project, providing an important new public resource for the analysis of XAS to all materials researchers. Finally, the ELSIE algorithm itself has been made available as part of veidt, an open source machine-learning library for materials science.},
  copyright = {2018 The Author(s)},
  language = {en},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Atomistic models;Computational methods Subject\_term\_id: atomistic-models;computational-methods},
  file = {/Users/chichen/Zotero/storage/3SFHGCHL/Zheng et al. - 2018 - Automated generation and ensemble-learned matching.pdf;/Users/chichen/Zotero/storage/B4C4LUYS/s41524-018-0067-x.html}
}

@article{zhengRandomForestModels2020,
  title = {Random {{Forest Models}} for {{Accurate Identification}} of {{Coordination Environments}} from {{X}}-{{Ray Absorption Near}}-{{Edge Structure}}},
  author = {Zheng, Chen and Chen, Chi and Chen, Yiming and Ong, Shyue Ping},
  year = {2020},
  month = may,
  journal = {Patterns},
  volume = {1},
  number = {2},
  pages = {100013},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2020.100013},
  abstract = {Analyzing coordination environments using X-ray absorption spectroscopy has broad applications in solid-state physics and material chemistry. Here, we show that random forest models trained on 190,000 K-edge X-ray absorption near-edge structure (XANES) spectra can identify the main atomic coordination environment with a high accuracy of 85.4\% and all associated coordination environments with a high Jaccard score of 81.8\% for 33 cation elements in oxides, significantly outperforming other machine-learning models. In a departure from prior works, the coordination environment is described as a distribution over 25 distinct coordination motifs with coordination numbers ranging from 1 to 12. More importantly, we show that the random forest models can be used to predict coordination environments from experimental K-edge XANES with minimal loss in accuracy. A drop-variable feature importance analysis highlights the key roles that the pre-edge and main-peak regions play in coordination environment identification.},
  language = {en},
  keywords = {coordination environment,feature importance,machine learning,materials,random forest,X-ray absorption spectroscopy,XANES},
  file = {/Users/chichen/Zotero/storage/RMRT2RFW/Zheng et al. - 2020 - Random Forest Models for Accurate Identification o.pdf;/Users/chichen/Zotero/storage/FRI6ZQ6P/S2666389920300131.html}
}

@article{Noh2019,
  doi = {10.1016/j.matt.2019.08.017},
  url = {https://doi.org/10.1016/j.matt.2019.08.017},
  year = {2019},
  month = nov,
  publisher = {Elsevier {BV}},
  volume = {1},
  number = {5},
  pages = {1370--1384},
  author = {Juhwan Noh and Jaehoon Kim and Helge S. Stein and Benjamin Sanchez-Lengeling and John M. Gregoire and Alan Aspuru-Guzik and Yousung Jung},
  title = {Inverse Design of Solid-State Materials via a Continuous Representation},
  journal = {Matter}
}
@article{Kim2020,
  doi = {10.1021/acscentsci.0c00426},
  url = {https://doi.org/10.1021/acscentsci.0c00426},
  year = {2020},
  month = jul,
  publisher = {American Chemical Society ({ACS})},
  volume = {6},
  number = {8},
  pages = {1412--1420},
  author = {Sungwon Kim and Juhwan Noh and Geun Ho Gu and Alan Aspuru-Guzik and Yousung Jung},
  title = {Generative Adversarial Networks for Crystal Structure Prediction},
  journal = {{ACS} Central Science}
}

@article{chemicalvae,
author = {Gómez-Bombarelli, Rafael and Wei, Jennifer N. and Duvenaud, David and Hernández-Lobato, José Miguel and Sánchez-Lengeling, Benjamín and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and Aspuru-Guzik, Alán},
title = {Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules},
journal = {ACS Central Science},
volume = {4},
number = {2},
pages = {268-276},
year = {2018},
doi = {10.1021/acscentsci.7b00572},
    note ={PMID: 29532027},

URL = { 
        https://doi.org/10.1021/acscentsci.7b00572
    
},
eprint = { 
        https://doi.org/10.1021/acscentsci.7b00572
    
}

}


@article{wuMoleculeNetBenchmarkMolecular2018,
  title = {{{MoleculeNet}}: A Benchmark for Molecular Machine Learning},
  volume = {9},
  shorttitle = {{{MoleculeNet}}},
  language = {en},
  number = {2},
  journal = {Chem. Sci.},
  doi = {10.1039/C7SC02664A},
  author = {Wu, Zhenqin and Ramsundar, Bharath and N. Feinberg, Evan and Gomes, Joseph and Geniesse, Caleb and S. Pappu, Aneesh and Leswing, Karl and Pande, Vijay},
  year = {2018},
  pages = {513-530},
  file = {/Users/yxzuo/Zotero/storage/JF6Z694I/Wu et al. - 2018 - MoleculeNet a benchmark for molecular machine lea.pdf;/Users/yxzuo/Zotero/storage/7WTV263W/c7sc02664a.html}
}

@incollection{duvenaudConvolutionalNetworksGraphs2015,
  title = {Convolutional Networks on Graphs for Learning Molecular Fingerprints},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {{Curran Associates, Inc.}},
  author = {Duvenaud, David K and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and {Aspuru-Guzik}, Alan and Adams, Ryan P},
  editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
  year = {2015},
  pages = {2224--2232},
}

@article{ARTRITH2016135,
title = {An implementation of artificial neural-network potentials for atomistic materials simulations: Performance for TiO2},
journal = {Computational Materials Science},
volume = {114},
pages = {135-150},
year = {2016},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2015.11.047},
url = {https://www.sciencedirect.com/science/article/pii/S0927025615007806},
author = {Nongnuch Artrith and Alexander Urban},
keywords = {Machine learning, Artificial neural networks, Atomistic simulations, Titanium dioxide (TiO), Behler–Parrinello},
abstract = {Machine learning interpolation of atomic potential energy surfaces enables the nearly automatic construction of highly accurate atomic interaction potentials. Here we discuss the Behler–Parrinello approach that is based on artificial neural networks (ANNs) and detail the implementation of the method in the free and open-source atomic energy network (ænet) package. The construction and application of ANN potentials using ænet is demonstrated at the example of titanium dioxide (TiO2), an industrially relevant and well-studied material. We show that the accuracy of lattice parameters, energies, and bulk moduli predicted by the resulting TiO2 ANN potential is excellent for the reference phases that were used in its construction (rutile, anatase, and brookite) and examine the potential’s capabilities for the prediction of the high-pressure phases columbite (α-PbO2 structure) and baddeleyite (ZrO2 structure).}
}
@article{eshet2010ab,
  title={Ab initio quality neural-network potential for sodium},
  author={Eshet, Hagai and Khaliullin, Rustam Z and K{\"u}hne, Thomas D and Behler, J{\"o}rg and Parrinello, Michele},
  journal={Physical Review B},
  volume={81},
  number={18},
  pages={184107},
  year={2010},
  publisher={APS}
}
@article{xue2021reaxff,
  title={ReaxFF-MPNN machine learning potential: a combination of reactive force field and message passing neural networks},
  author={Xue, Li-Yuan and Guo, Feng and Wen, Yu-Shi and Feng, Shi-Quan and Huang, Xiao-Na and Guo, Lei and Li, Heng-Shuai and Cui, Shou-Xin and Zhang, Gui-Qing and Wang, Qing-Lin},
  journal={Physical Chemistry Chemical Physics},
  volume={23},
  number={35},
  pages={19457--19464},
  year={2021},
  publisher={Royal Society of Chemistry}
}
@article{chmiela2018towards,
  title={Towards exact molecular dynamics simulations with machine-learned force fields},
  author={Chmiela, Stefan and Sauceda, Huziel E and M{\"u}ller, Klaus-Robert and Tkatchenko, Alexandre},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{park2021accurate,
  title={Accurate and scalable graph neural network force field and molecular dynamics with direct force architecture},
  author={Park, Cheol Woo and Kornbluth, Mordechai and Vandermause, Jonathan and Wolverton, Chris and Kozinsky, Boris and Mailoa, Jonathan P},
  journal={npj Computational Materials},
  volume={7},
  number={1},
  pages={1--9},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{pun2019physically,
  title={Physically informed artificial neural networks for atomistic modeling of materials},
  author={Pun, GP Purja and Batra, R and Ramprasad, R and Mishin, Y},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={1--10},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{khaliullin2010graphite,
  title={Graphite-diamond phase coexistence study employing a neural-network mapping of the ab initio potential energy surface},
  author={Khaliullin, Rustam Z and Eshet, Hagai and K{\"u}hne, Thomas D and Behler, J{\"o}rg and Parrinello, Michele},
  journal={Physical Review B},
  volume={81},
  number={10},
  pages={100103},
  year={2010},
  publisher={APS}
}
@article{artrith2016implementation,
  title={An implementation of artificial neural-network potentials for atomistic materials simulations: Performance for TiO2},
  author={Artrith, Nongnuch and Urban, Alexander},
  journal={Computational Materials Science},
  volume={114},
  pages={135--150},
  year={2016},
  publisher={Elsevier}
}
@article{WANG2018178,
title = {DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics},
journal = {Computer Physics Communications},
volume = {228},
pages = {178-184},
year = {2018},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2018.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0010465518300882},
author = {Han Wang and Linfeng Zhang and Jiequn Han and Weinan E},
keywords = {Many-body potential energy, Molecular dynamics, Deep neural networks},
abstract = {Recent developments in many-body potential energy representation via deep learning have brought new hopes to addressing the accuracy-versus-efficiency dilemma in molecular simulations. Here we describe DeePMD-kit, a package written in Python/C++ that has been designed to minimize the effort required to build deep learning based representation of potential energy and force field and to perform molecular dynamics. Potential applications of DeePMD-kit span from finite molecules to extended systems and from metallic systems to chemically bonded systems. DeePMD-kit is interfaced with TensorFlow, one of the most popular deep learning frameworks, making the training process highly automatic and efficient. On the other end, DeePMD-kit is interfaced with high-performance classical molecular dynamics and quantum (path-integral) molecular dynamics packages, i.e., LAMMPS and the i-PI, respectively. Thus, upon training, the potential energy and force field models can be used to perform efficient molecular simulations for different purposes. As an example of the many potential applications of the package, we use DeePMD-kit to learn the interatomic potential energy and forces of a water model using data obtained from density functional theory. We demonstrate that the resulted molecular dynamics model reproduces accurately the structural information contained in the original model.
Program summary
Program Title: DeePMD-kit Program Files doi: http://dx.doi.org/10.17632/hvfh9yvncf.1 Licensing provisions: LGPL Programming language: Python/C++ Nature of problem: Modeling the many-body atomic interactions by deep neural network models. Running molecular dynamics simulations with the models. Solution method: The Deep Potential for Molecular Dynamics (DeePMD) method is implemented based on the deep learning framework TensorFlow. Supports for using a DeePMD model in LAMMPS and i-PI, for classical and quantum (path integral) molecular dynamics are provided. Additional comments including Restrictions and Unusual features: The code defines a data protocol such that the energy, force, and virial calculated by different third-party molecular simulation packages can be easily processed and used as model training data.}
}
@article{ward2017including,
  title={Including crystal structure attributes in machine learning models of formation energies via Voronoi tessellations},
  author={Ward, Logan and Liu, Ruoqian and Krishna, Amar and Hegde, Vinay I and Agrawal, Ankit and Choudhary, Alok and Wolverton, Chris},
  journal={Physical Review B},
  volume={96},
  number={2},
  pages={024104},
  year={2017},
  publisher={APS}
}
@article{kearnes2016molecular,
  title={Molecular graph convolutions: moving beyond fingerprints},
  author={Kearnes, Steven and McCloskey, Kevin and Berndl, Marc and Pande, Vijay and Riley, Patrick},
  journal={Journal of computer-aided molecular design},
  volume={30},
  number={8},
  pages={595--608},
  year={2016},
  publisher={Springer}
}
@article{bartok2013representing,
  title={On representing chemical environments},
  author={Bart{\'o}k, Albert P and Kondor, Risi and Cs{\'a}nyi, G{\'a}bor},
  journal={Physical Review B},
  volume={87},
  number={18},
  pages={184115},
  year={2013},
  publisher={APS}
}
@article{rupp2012fast,
  title={Fast and accurate modeling of molecular atomization energies with machine learning},
  author={Rupp, Matthias and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert and Von Lilienfeld, O Anatole},
  journal={Physical review letters},
  volume={108},
  number={5},
  pages={058301},
  year={2012},
  publisher={APS}
}
@article{choudhary2020data,
  title={Data-driven discovery of 3D and 2D thermoelectric materials},
  author={Choudhary, Kamal and Garrity, Kevin F and Tavazza, Francesca},
  journal={Journal of Physics: Condensed Matter},
  volume={32},
  number={47},
  pages={475501},
  year={2020},
  publisher={IOP Publishing}
}
@article{choudhary2021high,
  title={High-throughput search for magnetic topological materials using spin-orbit spillage, machine learning, and experiments},
  author={Choudhary, Kamal and Garrity, Kevin F and Ghimire, Nirmal J and Anand, Naween and Tavazza, Francesca},
  journal={Physical Review B},
  volume={103},
  number={15},
  pages={155131},
  year={2021},
  publisher={APS}
}
@misc{choudhary2021atomistic,
      title={Atomistic Line Graph Neural Network for Improved Materials Property Predictions}, 
      author={Kamal Choudhary and Brian DeCost},
      year={2021},
      eprint={2106.01829},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci}
}

@inproceedings{song-etal-2018-graph,
    title = "A Graph-to-Sequence Model for {AMR}-to-Text Generation",
    author = "Song, Linfeng  and
      Zhang, Yue  and
      Wang, Zhiguo  and
      Gildea, Daniel",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1150",
    doi = "10.18653/v1/P18-1150",
    pages = "1616--1626",
    abstract = "The problem of AMR-to-text generation is to recover a text representing the same meaning as an input AMR graph. The current state-of-the-art method uses a sequence-to-sequence model, leveraging LSTM for encoding a linearized AMR structure. Although being able to model non-local semantic information, a sequence LSTM can lose information from the AMR graph structure, and thus facing challenges with large-graphs, which result in long sequences. We introduce a neural graph-to-sequence model, using a novel LSTM structure for directly encoding graph-level semantics. On a standard benchmark, our model shows superior results to existing methods in the literature.",
}

@article{mills2017deep,
  title={Deep learning and the Schr{\"o}dinger equation},
  author={Mills, Kyle and Spanner, Michael and Tamblyn, Isaac},
  journal={Physical Review A},
  volume={96},
  number={4},
  pages={042113},
  year={2017},
  publisher={APS}
}
@article{mcgibbon2017improving,
  title={Improving the accuracy of M{\o}ller-Plesset perturbation theory with neural networks},
  author={McGibbon, Robert T and Taube, Andrew G and Donchev, Alexander G and Siva, Karthik and Hern{\'a}ndez, Felipe and Hargus, Cory and Law, Ka-Hei and Klepeis, John L and Shaw, David E},
  journal={The Journal of chemical physics},
  volume={147},
  number={16},
  pages={161725},
  year={2017},
  publisher={AIP Publishing LLC}
}
@article{zhang2018deep,
  title={Deep potential molecular dynamics: a scalable model with the accuracy of quantum mechanics},
  author={Zhang, Linfeng and Han, Jiequn and Wang, Han and Car, Roberto and Weinan, E},
  journal={Physical review letters},
  volume={120},
  number={14},
  pages={143001},
  year={2018},
  publisher={APS}
}
@article{behler2011atom,
  title={Atom-centered symmetry functions for constructing high-dimensional neural network potentials},
  author={Behler, J{\"o}rg},
  journal={The Journal of chemical physics},
  volume={134},
  number={7},
  pages={074106},
  year={2011},
  publisher={American Institute of Physics}
}
@article{smith2017ani,
  title={ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost},
  author={Smith, Justin S and Isayev, Olexandr and Roitberg, Adrian E},
  journal={Chemical science},
  volume={8},
  number={4},
  pages={3192--3203},
  year={2017},
  publisher={Royal Society of Chemistry}
}
@article{ziatdinov2020causal,
  title={Causal analysis of competing atomistic mechanisms in ferroelectric materials from high-resolution scanning transmission electron microscopy data},
  author={Ziatdinov, Maxim and Nelson, Christopher T and Zhang, Xiaohang and Vasudevan, Rama K and Eliseev, Eugene and Morozovska, Anna N and Takeuchi, Ichiro and Kalinin, Sergei V},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{ward2018matminer,
  title={Matminer: An open source toolkit for materials data mining},
  author={Ward, Logan and Dunn, Alexander and Faghaninia, Alireza and Zimmermann, Nils ER and Bajaj, Saurabh and Wang, Qi and Montoya, Joseph and Chen, Jiming and Bystrom, Kyle and Dylla, Maxwell and others},
  journal={Computational Materials Science},
  volume={152},
  pages={60--69},
  year={2018},
  publisher={Elsevier}
}
@article{allen2015modelling,
  title={Modelling the inelastic scattering of fast electrons},
  author={Allen, Leslie J and Findlay, SD and others},
  journal={Ultramicroscopy},
  volume={151},
  pages={11--22},
  year={2015},
  publisher={Elsevier}
}
@article{madsen2021abtem,
  title={The abTEM code: transmission electron microscopy from first principles},
  author={Madsen, Jacob and Susi, Toma},
  journal={Open Research Europe},
  volume={1},
  number={24},
  pages={24},
  year={2021},
  publisher={F1000 Research Limited}
}
@article{savitzky2020py4dstem,
  title={py4DSTEM: A software package for multimodal analysis of four-dimensional scanning transmission electron microscopy datasets},
  author={Savitzky, Benjamin H and Hughes, Lauren A and Zeltmann, Steven E and Brown, Hamish G and Zhao, Shiteng and Pelz, Philipp M and Barnard, Edward S and Donohue, Jennifer and DaCosta, Luis Rangel and Pekin, Thomas C and others},
  journal={arXiv preprint arXiv:2003.09523},
  year={2020}
}


@article{somnath2019usid,
  title={USID and pycroscopy--Open source frameworks for storing and analyzing imaging and spectroscopy data},
  author={Somnath, Suhas and Smith, Chris R and Laanait, Nouamane and Vasudevan, Rama K and Jesse, Stephen},
  journal={Microscopy and Microanalysis},
  volume={25},
  number={S2},
  pages={220--221},
  year={2019},
  publisher={Cambridge University Press}
}
@book{saito2013computational,
  title={Computational materials design},
  author={Saito, Tetsuya},
  volume={34},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@article{kirklin2015open,
  title={The Open Quantum Materials Database (OQMD): assessing the accuracy of DFT formation energies},
  author={Kirklin, Scott and Saal, James E and Meredig, Bryce and Thompson, Alex and Doak, Jeff W and Aykol, Muratahan and R{\"u}hl, Stephan and Wolverton, Chris},
  journal={npj Computational Materials},
  volume={1},
  number={1},
  pages={1--15},
  year={2015},
  publisher={Nature Publishing Group}
}@article{weinreichproperties,
  title={Properties of alpha-Brass nanoparticles. 1. Neural network potential energy surface},
  author={Weinreich, Jan and Romer, Anton and Paleico,Martin Leandro and Behler, Jorg},
  journal={The Journal of Physical Chemistry C},
  volume={124},
  number={23},
  pages={12682--12695},
  year={2020},
  publisher={ACS Publications}
}
@article{hegde2020reproducibility,
  title={Reproducibility in high-throughput density functional theory: a comparison of AFLOW, Materials Project, and OQMD},
  author={Hegde, Vinay I and Borg, Christopher KH and del Rosario, Zachary and Kim, Yoolhee and Hutchinson, Maxwell and Antono, Erin and Ling, Julia and Saxe, Paul and Saal, James E and Meredig, Bryce},
  journal={arXiv preprint arXiv:2007.01988},
  year={2020}
}
@article{sussman1998protein,
  title={Protein Data Bank (PDB): database of three-dimensional structural information of biological macromolecules},
  author={Sussman, Joel L and Lin, Dawei and Jiang, Jiansheng and Manning, Nancy O and Prilusky, Jaime and Ritter, Otto and Abola, Enrique E},
  journal={Acta Crystallographica Section D: Biological Crystallography},
  volume={54},
  number={6},
  pages={1078--1084},
  year={1998},
  publisher={International Union of Crystallography}
}
@article{tyagi2015cancerppd,
  title={CancerPPD: a database of anticancer peptides and proteins},
  author={Tyagi, Atul and Tuknait, Abhishek and Anand, Priya and Gupta, Sudheer and Sharma, Minakshi and Mathur, Deepika and Joshi, Anshika and Singh, Sandeep and Gautam, Ankur and Raghava, Gajendra PS},
  journal={Nucleic acids research},
  volume={43},
  number={D1},
  pages={D837--D843},
  year={2015},
  publisher={Oxford University Press}
}
@article{lin2019bigsmiles,
  title={BigSMILES: a structurally-based line notation for describing macromolecules},
  author={Lin, Tzyy-Shyang and Coley, Connor W and Mochigase, Hidenobu and Beech, Haley K and Wang, Wencong and Wang, Zi and Woods, Eliot and Craig, Stephen L and Johnson, Jeremiah A and Kalow, Julia A and others},
  journal={ACS central science},
  volume={5},
  number={9},
  pages={1523--1531},
  year={2019},
  publisher={ACS Publications}
}
@article{mcnutt2021gnina,
  title={GNINA 1 molecular docking with deep learning},
  author={McNutt, Andrew T and Francoeur, Paul and Aggarwal, Rishal and Masuda, Tomohide and Meli, Rocco and Ragoza, Matthew and Sunseri, Jocelyn and Koes, David Ryan},
  journal={Journal of cheminformatics},
  volume={13},
  number={1},
  pages={1--20},
  year={2021},
  publisher={BioMed Central}
}

@article{gomez2018automatic,
  title={Automatic chemical design using a data-driven continuous representation of molecules},
  author={G{\'o}mez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and S{\'a}nchez-Lengeling, Benjam{\'\i}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Al{\'a}n},
  journal={ACS central science},
  volume={4},
  number={2},
  pages={268--276},
  year={2018},
  publisher={ACS Publications}
}

@article{hirohara2018convolutional,
  title={Convolutional neural network based on SMILES representation of compounds for detecting chemical motif},
  author={Hirohara, Maya and Saito, Yutaka and Koda, Yuki and Sato, Kengo and Sakakibara, Yasubumi},
  journal={BMC bioinformatics},
  volume={19},
  number={19},
  pages={83--94},
  year={2018},
  publisher={Springer}
}

@article{zitnick2020introduction,
  title={An introduction to electrocatalyst design using machine learning for renewable energy storage},
  author={Zitnick, C Lawrence and Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and Lavril, Thibaut and Palizhati, Aini and Riviere, Morgane and others},
  journal={arXiv preprint arXiv:2010.09435},
  year={2020}
}



@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@article{saal2013materials,
  title={Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD)},
  author={Saal, James E and Kirklin, Scott and Aykol, Muratahan and Meredig, Bryce and Wolverton, Christopher},
  journal={Jom},
  volume={65},
  number={11},
  pages={1501--1509},
  year={2013},
  publisher={Springer}
}
@article{de2019new,
  title={New frontiers for the materials genome initiative},
  author={de Pablo, Juan J and Jackson, Nicholas E and Webb, Michael A and Chen, Long-Qing and Moore, Joel E and Morgan, Dane and Jacobs, Ryan and Pollock, Tresa and Schlom, Darrell G and Toberer, Eric S and others},
  journal={npj Computational Materials},
  volume={5},
  number={1},
  pages={1--23},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{abdar2021review,
  title={A review of uncertainty quantification in deep learning: Techniques, applications and challenges},
  author={Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U Rajendra and others},
  journal={Information Fusion},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}
@article{fort2019deep,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02757},
  year={2019}
}
@article{ganaie2021ensemble,
  title={Ensemble deep learning: A review},
  author={Ganaie, MA and Hu, Minghui and others},
  journal={arXiv preprint arXiv:2104.02395},
  year={2021}
}
@inproceedings{jain2020maximizing,
  title={Maximizing overall diversity for improved uncertainty estimates in deep ensembles},
  author={Jain, Siddhartha and Liu, Ge and Mueller, Jonas and Gifford, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4264--4271},
  year={2020}
}
@inproceedings{wilson2016deep,
  title={Deep kernel learning},
  author={Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Artificial intelligence and statistics},
  pages={370--378},
  year={2016},
  organization={PMLR}
}
@article{hegde2018deep,
  title={Deep learning with differential Gaussian process flows},
  author={Hegde, Pashupati and Heinonen, Markus and L{\"a}hdesm{\"a}ki, Harri and Kaski, Samuel},
  journal={arXiv preprint arXiv:1810.04066},
  year={2018}
}
@inproceedings{rasmussen2003gaussian,
  title={Gaussian processes in machine learning},
  author={Rasmussen, Carl Edward},
  booktitle={Summer school on machine learning},
  pages={63--71},
  year={2003},
  organization={Springer}
}
@article{moon2021learning,
  title={Learning Multiple Quantiles with Neural Networks},
  author={Moon, Sang Jun and Jeon, Jong-June and Lee, Jason Sang Hun and Kim, Yongdai},
  journal={Journal of Computational and Graphical Statistics},
  pages={1--11},
  year={2021},
  publisher={Taylor \& Francis}
}
@article{lakshminarayanan2016simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={arXiv preprint arXiv:1612.01474},
  year={2016}
}
@article{seoh2020qualitative,
  title={Qualitative Analysis of Monte Carlo Dropout},
  author={Seoh, Ronald},
  journal={arXiv preprint arXiv:2007.01720},
  year={2020}
}


@inproceedings{zhang2020mix,
  title={Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning},
  author={Zhang, Jize and Kailkhura, Bhavya and Han, T Yong-Jin},
  booktitle={International Conference on Machine Learning},
  pages={11117--11128},
  year={2020},
  organization={PMLR}
}
@article{zhang2021leveraging,
  title={Leveraging Uncertainty from Deep Learning for Trustworthy Material Discovery Workflows},
  author={Zhang, Jize and Kailkhura, Bhavya and Han, T Yong-Jin},
  journal={ACS omega},
  volume={6},
  number={19},
  pages={12711--12721},
  year={2021},
  publisher={ACS Publications}
}
@inproceedings{teye2018bayesian,
  title={Bayesian uncertainty estimation for batch normalized deep networks},
  author={Teye, Mattias and Azizpour, Hossein and Smith, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={4907--4916},
  year={2018},
  organization={PMLR}
}
@article{mi1910training,
  title={Training-free uncertainty estimation for neural networks. arXiv 2019},
  author={Mi, L and Wang, H and Tian, Y and Shavit, N},
  journal={arXiv preprint arXiv:1910.04858}
}

@article{ward2016general,
  title={A general-purpose machine learning framework for predicting properties of inorganic materials},
  author={Ward, Logan and Agrawal, Ankit and Choudhary, Alok and Wolverton, Christopher},
  journal={npj Computational Materials},
  volume={2},
  number={1},
  pages={1--7},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{jha2018elemnet,
  title={Elemnet: Deep learning the chemistry of materials from only elemental composition},
  author={Jha, Dipendra and Ward, Logan and Paul, Arindam and Liao, Wei-keng and Choudhary, Alok and Wolverton, Chris and Agrawal, Ankit},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@inproceedings{jha2019irnet,
  title={IRNet: A general purpose deep residual regression framework for materials discovery},
  author={Jha, Dipendra and Ward, Logan and Yang, Zijiang and Wolverton, Christopher and Foster, Ian and Liao, Wei-keng and Choudhary, Alok and Agrawal, Ankit},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2385--2393},
  year={2019}
}

@article{putin2018reinforced,
  title={Reinforced adversarial neural computer for de novo molecular design},
  author={Putin, Evgeny and Asadulaev, Arip and Ivanenkov, Yan and Aladinskiy, Vladimir and Sanchez-Lengeling, Benjamin and Aspuru-Guzik, Al{\'a}n and Zhavoronkov, Alex},
  journal={Journal of chemical information and modeling},
  volume={58},
  number={6},
  pages={1194--1204},
  year={2018},
  publisher={ACS Publications}
}
@article{you2018graph,
  title={Graph convolutional policy network for goal-directed molecular graph generation},
  author={You, Jiaxuan and Liu, Bowen and Ying, Rex and Pande, Vijay and Leskovec, Jure},
  journal={arXiv preprint arXiv:1806.02473},
  year={2018}
}
@article{olivecrona2017molecular,
  title={Molecular de-novo design through deep reinforcement learning},
  author={Olivecrona, Marcus and Blaschke, Thomas and Engkvist, Ola and Chen, Hongming},
  journal={Journal of cheminformatics},
  volume={9},
  number={1},
  pages={1--14},
  year={2017},
  publisher={BioMed Central}
}
@article{ouyang2018sisso,
  title={SISSO: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates},
  author={Ouyang, Runhai and Curtarolo, Stefano and Ahmetcik, Emre and Scheffler, Matthias and Ghiringhelli, Luca M},
  journal={Physical Review Materials},
  volume={2},
  number={8},
  pages={083802},
  year={2018},
  publisher={APS}
}
@article{himanen2020dscribe,
  title={DScribe: Library of descriptors for machine learning in materials science},
  author={Himanen, Lauri and J{\"a}ger, Marc OJ and Morooka, Eiaki V and Canova, Filippo Federici and Ranawat, Yashasvi S and Gao, David Z and Rinke, Patrick and Foster, Adam S},
  journal={Computer Physics Communications},
  volume={247},
  pages={106949},
  year={2020},
  publisher={Elsevier}
}
@article{de2016comparing,
  title={Comparing molecules and solids across structural and alchemical space},
  author={De, Sandip and Bart{\'o}k, Albert P and Cs{\'a}nyi, G{\'a}bor and Ceriotti, Michele},
  journal={Physical Chemistry Chemical Physics},
  volume={18},
  number={20},
  pages={13754--13769},
  year={2016},
  publisher={Royal Society of Chemistry}
}

@article{krasnov2021transformer,
  title={Transformer-based artificial neural networks for the conversion between chemical notations},
  author={Krasnov, Lev and Khokhlov, Ivan and Fedorov, Maxim V and Sosnin, Sergey},
  journal={Scientific Reports},
  volume={11},
  number={1},
  pages={1--10},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{kim2019pubchem,
  title={PubChem 2019 update: improved access to chemical data},
  author={Kim, Sunghwan and Chen, Jie and Cheng, Tiejun and Gindulyte, Asta and He, Jia and He, Siqian and Li, Qingliang and Shoemaker, Benjamin A and Thiessen, Paul A and Yu, Bo and others},
  journal={Nucleic acids research},
  volume={47},
  number={D1},
  pages={D1102--D1109},
  year={2019},
  publisher={Oxford University Press}
}
@article{dix2007toxcast,
  title={The ToxCast program for prioritizing toxicity testing of environmental chemicals},
  author={Dix, David J and Houck, Keith A and Martin, Matthew T and Richard, Ann M and Setzer, R Woodrow and Kavlock, Robert J},
  journal={Toxicological sciences},
  volume={95},
  number={1},
  pages={5--12},
  year={2007},
  publisher={Oxford University Press}
}
@article{irwin2012zinc,
  title={ZINC: a free tool to discover chemistry for biology},
  author={Irwin, John J and Sterling, Teague and Mysinger, Michael M and Bolstad, Erin S and Coleman, Ryan G},
  journal={Journal of chemical information and modeling},
  volume={52},
  number={7},
  pages={1757--1768},
  year={2012},
  publisher={ACS Publications}
}
@article{lim2018molecular,
  title={Molecular generative model based on conditional variational autoencoder for de novo molecular design},
  author={Lim, Jaechang and Ryu, Seongok and Kim, Jin Woo and Kim, Woo Youn},
  journal={Journal of cheminformatics},
  volume={10},
  number={1},
  pages={1--9},
  year={2018},
  publisher={BioMed Central}
}
@article{saito2006spectral,
  title={Spectral database for organic compounds (SDBS)},
  author={Saito, T and Hayamizu, K and Yanagisawa, M and Yamamoto, O and Wasada, N and Someno, K and Kinugasa, S and Tanabe, K and Tamura, T and Hiraishi, J},
  journal={National Institute of Advanced Industrial Science and Technology (AIST), Japan},
  year={2006}
}
@article{linstrom2001nist,
  title={The NIST Chemistry WebBook: A chemical data resource on the internet},
  author={Linstrom, Peter J and Mallard, William G},
  journal={Journal of Chemical \& Engineering Data},
  volume={46},
  number={5},
  pages={1059--1063},
  year={2001},
  publisher={ACS Publications}
}
@article{krenn2020self,
  title={Self-Referencing Embedded Strings (SELFIES): A 100\% robust molecular string representation},
  author={Krenn, Mario and H{\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={4},
  pages={045024},
  year={2020},
  publisher={IOP Publishing}
}
@article{nouira2018crystalgan,
  title={Crystalgan: learning to discover crystallographic structures with generative adversarial networks},
  author={Nouira, Asma and Sokolovska, Nataliya and Crivello, Jean-Claude},
  journal={arXiv preprint arXiv:1810.11203},
  year={2018}
}
@article{sanchez2017optimizing,
  title={Optimizing distributions over molecular space. An objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC)},
  author={Sanchez-Lengeling, Benjamin and Outeiral, Carlos and Guimaraes, Gabriel L and Aspuru-Guzik, Alan},
  year={2017}
}
@inproceedings{jin2018junction,
  title={Junction tree variational autoencoder for molecular graph generation},
  author={Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},
  booktitle={International conference on machine learning},
  pages={2323--2332},
  year={2018},
  organization={PMLR}
}
@article{xu2015deep,
  title={Deep learning for drug-induced liver injury},
  author={Xu, Youjun and Dai, Ziwei and Chen, Fangjin and Gao, Shuaishi and Pei, Jianfeng and Lai, Luhua},
  journal={Journal of chemical information and modeling},
  volume={55},
  number={10},
  pages={2085--2093},
  year={2015},
  publisher={ACS Publications}
}
@article{lusci2013deep,
  title={Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules},
  author={Lusci, Alessandro and Pollastri, Gianluca and Baldi, Pierre},
  journal={Journal of chemical information and modeling},
  volume={53},
  number={7},
  pages={1563--1575},
  year={2013},
  publisher={ACS Publications}
}
@article{laugier2018predicting,
  title={Predicting thermoelectric properties from crystal graphs and material descriptors-first application for functional materials},
  author={Laugier, Leo and Bash, Daniil and Recatala, Jose and Ng, Hong Kuan and Ramasamy, Savitha and Foo, Chuan-Sheng and Chandrasekhar, Vijay R and Hippalgaonkar, Kedar},
  journal={arXiv preprint arXiv:1811.06219},
  year={2018}
}
@article{park2020developing,
  title={Developing an improved crystal graph convolutional neural network framework for accelerated materials discovery},
  author={Park, Cheol Woo and Wolverton, Chris},
  journal={Physical Review Materials},
  volume={4},
  number={6},
  pages={063801},
  year={2020},
  publisher={APS}
}
@article{goodall2020predicting,
  title={Predicting materials properties without crystal structure: Deep representation learning from stoichiometry},
  author={Goodall, Rhys EA and Lee, Alpha A},
  journal={Nature Communications},
  volume={11},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{Wang2021crabnet,
 author = {Wang, Anthony Yu-Tung and Kauwe, Steven K. and Murdock, Ryan J. and Sparks, Taylor D.},
 year = {2021},
 title = {Compositionally restricted attention-based network for materials property predictions},
 pages = {77},
 volume = {7},
 number = {1},
 doi = {10.1038/s41524-021-00545-1},
 publisher = {{Nature Publishing Group}},
 shortjournal = {npj Comput. Mater.},
 journal = {npj Computational Materials}
}

@Article{Gilmer2017,
  author  = {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
  title   = {Neural Message Passing for Quantum Chemistry},
  journal = {CoRR},
  year    = {2017}
}


@article{chmiela2017machine,
  title={Machine learning of accurate energy-conserving molecular force fields},
  author={Chmiela, Stefan and Tkatchenko, Alexandre and Sauceda, Huziel E and Poltavsky, Igor and Sch{\"u}tt, Kristof T and M{\"u}ller, Klaus-Robert},
  journal={Science advances},
  volume={3},
  number={5},
  pages={e1603015},
  year={2017},
  publisher={American Association for the Advancement of Science}
}
@article{thomas2018us,
  title={The US Federal Tox21 Program: A strategic and operational plan for continued leadership},
  author={Thomas, Russell S and Paules, Richard S and Simeonov, Anton and Fitzpatrick, Suzanne C and Crofton, Kevin M and Casey, Warren M and Mendrick, Donna L},
  journal={Altex},
  volume={35},
  number={2},
  pages={163},
  year={2018},
  publisher={NIH Public Access}
}
@article{johnson2006nist,
  title={NIST computational chemistry comparison and benchmark database},
  author={Johnson, Russell D and others},
  journal={http://srdata. nist. gov/cccbdb},
  year={2006}
}
@article{mobley2014freesolv,
  title={FreeSolv: a database of experimental and calculated hydration free energies, with input files},
  author={Mobley, David L and Guthrie, J Peter},
  journal={Journal of computer-aided molecular design},
  volume={28},
  number={7},
  pages={711--720},
  year={2014},
  publisher={Springer}
}
@article{khorshidi2016amp,
  title={Amp: A modular approach to machine learning in atomistic simulations},
  author={Khorshidi, Alireza and Peterson, Andrew A},
  journal={Computer Physics Communications},
  volume={207},
  pages={310--324},
  year={2016},
  publisher={Elsevier}
}

@article{yao2017intrinsic,
  title={Intrinsic bond energies from a bonds-in-molecules neural network},
  author={Yao, Kun and Herr, John E and Brown, Seth N and Parkhill, John},
  journal={The journal of physical chemistry letters},
  volume={8},
  number={12},
  pages={2689--2694},
  year={2017},
  publisher={ACS Publications}
}

@article{kolb2017discovering,
  title={Discovering charge density functionals and structure-property relationships with PROPhet: A general framework for coupling machine learning and first-principles methods},
  author={Kolb, Brian and Lentz, Levi C and Kolpak, Alexie M},
  journal={Scientific Reports},
  volume={7},
  number={1},
  pages={1--9},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{schutt2018schnetpack,
  title={SchNetPack: A deep learning toolbox for atomistic systems},
  author={Schutt, KT and Kessel, Pan and Gastegger, Michael and Nicoli, KA and Tkatchenko, Alexandre and M{\"u}ller, K-R},
  journal={Journal of chemical theory and computation},
  volume={15},
  number={1},
  pages={448--455},
  year={2018},
  publisher={ACS Publications}
}
@misc{long2021inverse,
      title={Inverse design of crystal structures for multicomponent systems}, 
      author={Teng Long and Yixuan Zhang and Nuno M. Fortunato and Chen Shen and Mian Dai and Hongbin Zhang},
      year={2021},
      eprint={2104.08040},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci}
}
@article{yang2021deep,
  title={Deep Learning-Assisted Quantification of Atomic Dopants and Defects in 2D Materials},
  author={Yang, Sang-Hyeok and Choi, Wooseon and Cho, Byeong Wook and Agyapong-Fordjour, Frederick Osei-Tutu and Park, Sehwan and Yun, Seok Joon and Kim, Hyung-Jin and Han, Young-Kyu and Lee, Young Hee and Kim, Ki Kang and others},
  journal={Advanced Science},
  pages={2101099},
  year={2021},
  publisher={Wiley Online Library}
}
@article{xie2018hierarchical,
  title={Hierarchical visualization of materials space with graph convolutional neural networks},
  author={Xie, Tian and Grossman, Jeffrey C},
  journal={The Journal of chemical physics},
  volume={149},
  number={17},
  pages={174111},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{xie2018crystal,
  title={Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties},
  author={Xie, Tian and Grossman, Jeffrey C},
  journal={Physical review letters},
  volume={120},
  number={14},
  pages={145301},
  year={2018},
  publisher={APS}
}
@article{talirz2020materials,
  title={Materials Cloud, a platform for open computational science},
  author={Talirz, Leopold and Kumbhar, Snehal and Passaro, Elsa and Yakutovich, Aliaksandr V and Granata, Valeria and Gargiulo, Fernando and Borelli, Marco and Uhrin, Martin and Huber, Sebastiaan P and Zoupanos, Spyros and others},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={1--12},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{chung2019advances,
  title={Advances, updates, and analytics for the computation-ready, experimental metal--organic framework database: CoRE MOF 2019},
  author={Chung, Yongchul G and Haldoupis, Emmanuel and Bucior, Benjamin J and Haranczyk, Maciej and Lee, Seulchan and Zhang, Hongda and Vogiatzis, Konstantinos D and Milisavljevic, Marija and Ling, Sanliang and Camp, Jeffrey S and others},
  journal={Journal of Chemical \& Engineering Data},
  volume={64},
  number={12},
  pages={5985--5998},
  year={2019},
  publisher={ACS Publications}
}

@article{rosen2021machine,
  title={Machine learning the quantum-chemical properties of metal--organic frameworks for accelerated materials discovery},
  author={Rosen, Andrew S and Iyer, Shaelyn M and Ray, Debmalya and Yao, Zhenpeng and Aspuru-Guzik, Al{\'a}n and Gagliardi, Laura and Notestein, Justin M and Snurr, Randall Q},
  journal={Matter},
  volume={4},
  number={5},
  pages={1578--1597},
  year={2021},
  publisher={Elsevier}
}
@article{benson2007binding,
  title={Binding MOAD, a high-quality protein--ligand database},
  author={Benson, Mark L and Smith, Richard D and Khazanov, Nickolay A and Dimcheff, Brandon and Beaver, John and Dresslar, Peter and Nerothin, Jason and Carlson, Heather A},
  journal={Nucleic acids research},
  volume={36},
  number={suppl\_1},
  pages={D674--D678},
  year={2007},
  publisher={Oxford University Press}
}
@article{thomas2018tensor,
  title={Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds},
  author={Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  journal={arXiv preprint arXiv:1802.08219},
  year={2018}
}

@misc{mario_geiger_2021_5006322,
  author       = {Mario Geiger and
                  Tess Smidt and
                  Alby M. and
                  Benjamin Kurt Miller and
                  Wouter Boomsma and
                  Bradley Dice and
                  Kostiantyn Lapchevskyi and
                  Maurice Weiler and
                  Michał Tyszkiewicz and
                  Simon Batzner and
                  Jes Frellsen and
                  Nuri Jung and
                  Sophia Sanborn and
                  Josh Rackers and
                  Michael Bailey},
  title        = {e3nn/e3nn: 2021-06-21},
  month        = jun,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.3.3},
  doi          = {10.5281/zenodo.5006322},
  url          = {https://doi.org/10.5281/zenodo.5006322}
}

@article{chen2019graph,
  title={Graph networks as a universal machine learning framework for molecules and crystals},
  author={Chen, Chi and Ye, Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping},
  journal={Chemistry of Materials},
  volume={31},
  number={9},
  pages={3564--3572},
  year={2019},
  publisher={ACS Publications}
}
@article{artrith2021best,
  title={Best practices in machine learning for chemistry},
  author={Artrith, Nongnuch and Butler, Keith T and Coudert, Fran{\c{c}}ois-Xavier and Han, Seungwu and Isayev, Olexandr and Jain, Anubhav and Walsh, Aron},
  journal={Nature Chemistry},
  volume={13},
  number={6},
  pages={505--508},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{bartel2020critical,
  title={A critical examination of compound stability predictions from machine-learned formation energies},
  author={Bartel, Christopher J and Trewartha, Amalie and Wang, Qi and Dunn, Alexander and Jain, Anubhav and Ceder, Gerbrand},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{chen2015mxnet,
  title={Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems},
  author={Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  journal={arXiv preprint arXiv:1512.01274},
  year={2015}
}

@misc{nistdisclaimer,title={Certain commercial equipment, instruments, or materials are identified in this paper in order to specify the experimental procedure adequately.  Such identification is not intended to imply recommendation or endorsement by NIST, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose.},
author={NIST\;disclaimer},
journal={}
}
@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ symposium on operating systems design and implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={8026--8037},
  year={2019}
}
@article{aykol2019materials,
  title={The materials research platform: defining the requirements from user stories},
  author={Aykol, Muratahan and Hummelsh{\o}j, Jens S and Anapolsky, Abraham and Aoyagi, Koutarou and Bazant, Martin Z and Bligaard, Thomas and Braatz, Richard D and Broderick, Scott and Cogswell, Daniel and Dagdelen, John and others},
  journal={Matter},
  volume={1},
  number={6},
  pages={1433--1438},
  year={2019},
  publisher={Elsevier}
}
@article{montans2019data,
  title={Data-driven modeling and learning in science and engineering},
  author={Mont{\'a}ns, Francisco J and Chinesta, Francisco and G{\'o}mez-Bombarelli, Rafael and Kutz, J Nathan},
  journal={Comptes Rendus M{\'e}canique},
  volume={347},
  number={11},
  pages={845--855},
  year={2019},
  publisher={Elsevier}
}
@book{rajan2013informatics,
  title={Informatics for materials science and engineering: data-driven discovery for accelerated experimentation and application},
  author={Rajan, Krishna},
  year={2013},
  publisher={Butterworth-Heinemann}
}
@article{himanen2019data,
  title={Data-driven materials science: status, challenges, and perspectives},
  author={Himanen, Lauri and Geurts, Amber and Foster, Adam Stuart and Rinke, Patrick},
  journal={Advanced Science},
  volume={6},
  number={21},
  pages={1900808},
  year={2019},
  publisher={Wiley Online Library}
}
@article{morgan2020opportunities,
  title={Opportunities and challenges for machine learning in materials science},
  author={Morgan, Dane and Jacobs, Ryan},
  journal={Annual Review of Materials Research},
  volume={50},
  pages={71--103},
  year={2020},
  publisher={Annual Reviews}
}
@article{wang2020machine,
  title={Machine learning for materials scientists: An introductory guide toward best practices},
  author={Wang, Anthony Yu-Tung and Murdock, Ryan J and Kauwe, Steven K and Oliynyk, Anton O and Gurlo, Aleksander and Brgoch, Jakoah and Persson, Kristin A and Sparks, Taylor D},
  journal={Chemistry of Materials},
  volume={32},
  number={12},
  pages={4954--4965},
  year={2020},
  publisher={ACS Publications}
}
@article{jha2019enhancing,
  title={Enhancing materials property prediction by leveraging computational and experimental data using deep transfer learning},
  author={Jha, Dipendra and Choudhary, Kamal and Tavazza, Francesca and Liao, Wei-keng and Choudhary, Alok and Campbell, Carelyn and Agrawal, Ankit},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{cubuk2019screening,
  title={Screening billions of candidates for solid lithium-ion conductors: A transfer learning approach for small data},
  author={Cubuk, Ekin D and Sendek, Austin D and Reed, Evan J},
  journal={The Journal of chemical physics},
  volume={150},
  number={21},
  pages={214701},
  year={2019},
  publisher={AIP Publishing LLC}
}
@article{klicpera2020directional,
  title={Directional message passing for molecular graphs},
  author={Klicpera, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2003.03123},
  year={2020}
}

@article{unke2019physnet,
  title={PhysNet: a neural network for predicting energies, forces, dipole moments, and partial charges},
  author={Unke, Oliver T and Meuwly, Markus},
  journal={Journal of chemical theory and computation},
  volume={15},
  number={6},
  pages={3678--3693},
  year={2019},
  publisher={ACS Publications}
}
@article{behler2007generalized,
  title={Generalized neural-network representation of high-dimensional potential-energy surfaces},
  author={Behler, J{\"o}rg and Parrinello, Michele},
  journal={Physical review letters},
  volume={98},
  number={14},
  pages={146401},
  year={2007},
  publisher={APS}
}

@article{wang2018deepmd,
  title={DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics},
  author={Wang, Han and Zhang, Linfeng and Han, Jiequn and Weinan, E},
  journal={Computer Physics Communications},
  volume={228},
  pages={178--184},
  year={2018},
  publisher={Elsevier}
}

@article{decost2021atomistic,
  title={Atomistic Line Graph Neural Network for Improved Materials Property Predictions},
  author={DeCost, Brian and Choudhary, Kamal},
  journal={arXiv preprint arXiv:2106.01829},
  year={2021}
}
@article{wallach2015atomnet,
  title={AtomNet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery},
  author={Wallach, Izhar and Dzamba, Michael and Heifets, Abraham},
  journal={arXiv preprint arXiv:1510.02855},
  year={2015}
}
@article{jain2013commentary,
  title={Commentary: The Materials Project: A materials genome approach to accelerating materials innovation},
  author={Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and others},
  journal={APL materials},
  volume={1},
  number={1},
  pages={011002},
  year={2013},
  publisher={American Institute of PhysicsAIP}
}

@article{curtarolo2012aflow,
  title={AFLOW: An automatic framework for high-throughput materials discovery},
  author={Curtarolo, Stefano and Setyawan, Wahyu and Hart, Gus LW and Jahnatek, Michal and Chepulskii, Roman V and Taylor, Richard H and Wang, Shidong and Xue, Junkai and Yang, Kesong and Levy, Ohad and others},
  journal={Computational Materials Science},
  volume={58},
  pages={218--226},
  year={2012},
  publisher={Elsevier}
}

@article{choudhary2020high,
  title={High-throughput density functional perturbation theory and machine learning predictions of infrared, piezoelectric, and dielectric responses},
  author={Choudhary, Kamal and Garrity, Kevin F and Sharma, Vinit and Biacchi, Adam J and Walker, Angela R Hight and Tavazza, Francesca},
  journal={NPJ Computational Materials},
  volume={6},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{chen2021database,
  title={Database of ab initio L-edge X-ray absorption near edge structure},
  author={Chen, Yiming and Chen, Chi and Zheng, Chen and Dwaraknath, Shyam and Horton, Matthew K and Cabana, Jordi and Rehr, John and Vinson, John and Dozier, Alan and Kas, Joshua J and others},
  journal={Scientific Data},
  volume={8},
  number={1},
  pages={1--8},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{fremout2012identification,
  title={Identification of synthetic organic pigments: the role of a comprehensive digital Raman spectral library},
  author={Fremout, Wim and Saverwyns, Steven},
  journal={Journal of Raman spectroscopy},
  volume={43},
  number={11},
  pages={1536--1544},
  year={2012},
  publisher={Wiley Online Library}
}
@article{steinbeck2003nmrshiftdb,
  title={NMRShiftDB constructing a free chemical information system with open-source components},
  author={Steinbeck, Christoph and Krause, Stefan and Kuhn, Stefan},
  journal={Journal of chemical information and computer sciences},
  volume={43},
  number={6},
  pages={1733--1739},
  year={2003},
  publisher={ACS Publications}
}
@article{el2019raman,
  title={Raman Open Database: first interconnected Raman--X-ray diffraction open-access resource for material identification},
  author={El Mendili, Yassine and Vaitkus, Antanas and Merkys, Andrius and Gra{\v{z}}ulis, Saulius and Chateigner, Daniel and Mathevet, Fabrice and Gascoin, St{\'e}phanie and Petit, Sebastien and Bardeau, J-F and Zanatta, Marco and others},
  journal={Journal of applied crystallography},
  volume={52},
  number={3},
  pages={618--625},
  year={2019},
  publisher={International Union of Crystallography}
}
@incollection{lafuente20151,
  title={1. The power of databases: The RRUFF project},
  author={Lafuente, Barbara and Downs, Robert T and Yang, Hexiong and Stone, Nate},
  booktitle={Highlights in mineralogical crystallography},
  pages={1--30},
  year={2015},
  publisher={De Gruyter (O)}
}
@article{mathew2018high,
  title={High-throughput computational X-ray absorption spectroscopy},
  author={Mathew, Kiran and Zheng, Chen and Winston, Donald and Chen, Chi and Dozier, Alan and Rehr, John J and Ong, Shyue Ping and Persson, Kristin A},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--8},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{choudhary2018computational,
  title={Computational screening of high-performance optoelectronic materials using OptB88vdW and TB-mBJ formalisms},
  author={Choudhary, Kamal and Zhang, Qin and Reid, Andrew CE and Chowdhury, Sugata and Van Nguyen, Nhan and Trautt, Zachary and Newrock, Marcus W and Congo, Faical Yannick and Tavazza, Francesca},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{zhou2018learning,
  title={Learning atoms for materials discovery},
  author={Zhou, Quan and Tang, Peizhe and Liu, Shenxiu and Pan, Jinbo and Yan, Qimin and Zhang, Shou-Cheng},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={28},
  pages={E6411--E6417},
  year={2018},
  publisher={National Acad Sciences}
}
@article{oliynyk2016high,
  title={High-throughput machine-learning-driven synthesis of full-Heusler compounds},
  author={Oliynyk, Anton O and Antono, Erin and Sparks, Taylor D and Ghadbeigi, Leila and Gaultois, Michael W and Meredig, Bryce and Mar, Arthur},
  journal={Chemistry of Materials},
  volume={28},
  number={20},
  pages={7324--7331},
  year={2016},
  publisher={ACS Publications}
}
@article{choudhary2018machine,
  title={Machine learning with force-field-inspired descriptors for materials: Fast screening and mapping energy landscape},
  author={Choudhary, Kamal and DeCost, Brian and Tavazza, Francesca},
  journal={Physical review materials},
  volume={2},
  number={8},
  pages={083801},
  year={2018},
  publisher={APS}
}
@article{bang2021accelerated,
  title={Accelerated mapping of electronic density of states patterns of metallic nanoparticles via machine-learning},
  author={Bang, Kihoon and Yeo, Byung Chul and Kim, Donghun and Han, Sang Soo and Lee, Hyuck Mo},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{fung2021machine,
  title={Machine learned features from density of states for accurate adsorption energy prediction},
  author={Fung, Victor and Hu, Guoxiang and Ganesh, Panchapakesan and Sumpter, Bobby G},
  journal={Nature Communications},
  volume={12},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{choudhary2020joint,
  title={The joint automated repository for various integrated simulations (JARVIS) for data-driven materials design},
  author={Choudhary, Kamal and Garrity, Kevin F and Reid, Andrew CE and DeCost, Brian and Biacchi, Adam J and Walker, Angela R Hight and Trautt, Zachary and Hattrick-Simpers, Jason and Kusne, A Gilad and Centrone, Andrea and others},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{ramakrishnan2014quantum,
  title={Quantum chemistry structures and properties of 134 kilo molecules},
  author={Ramakrishnan, Raghunathan and Dral, Pavlo O and Rupp, Matthias and Von Lilienfeld, O Anatole},
  journal={Scientific data},
  volume={1},
  number={1},
  pages={1--7},
  year={2014},
  publisher={Nature Publishing Group}
}

@article{draxl2018nomad,
  title={NOMAD: The FAIR concept for big data-driven materials science},
  author={Draxl, Claudia and Scheffler, Matthias},
  journal={Mrs Bulletin},
  volume={43},
  number={9},
  pages={676--682},
  year={2018},
  publisher={Cambridge University Press}
}
@article{wang2005pdbbind,
  title={The PDBbind database: methodologies and updates},
  author={Wang, Renxiao and Fang, Xueliang and Lu, Yipin and Yang, Chao-Yie and Wang, Shaomeng},
  journal={Journal of medicinal chemistry},
  volume={48},
  number={12},
  pages={4111--4119},
  year={2005},
  publisher={ACS Publications}
}
@article{belsky2002new,
  title={New developments in the Inorganic Crystal Structure Database (ICSD): accessibility in support of materials research and design},
  author={Belsky, Alec and Hellenbrandt, Mariette and Karen, Vicky Lynn and Luksch, Peter},
  journal={Acta Crystallographica Section B: Structural Science},
  volume={58},
  number={3},
  pages={364--369},
  year={2002},
  publisher={International Union of Crystallography}
}
@article{zakutayev2018open,
  title={An open experimental database for exploring inorganic materials},
  author={Zakutayev, Andriy and Wunder, Nick and Schwarting, Marcus and Perkins, John D and White, Robert and Munch, Kristin and Tumas, William and Phillips, Caleb},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{wilkinson2016fair,
  title={The FAIR Guiding Principles for scientific data management and stewardship},
  author={Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and others},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--9},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{vasudevan2019materials,
  title={Materials science in the artificial intelligence age: high-throughput library generation, machine learning, and a pathway from correlations to the underpinning physics},
  author={Vasudevan, Rama K and Choudhary, Kamal and Mehta, Apurva and Smith, Ryan and Kusne, Gilad and Tavazza, Francesca and Vlcek, Lukas and Ziatdinov, Maxim and Kalinin, Sergei V and Hattrick-Simpers, Jason},
  journal={MRS communications},
  volume={9},
  number={3},
  pages={821--838},
  year={2019},
  publisher={Cambridge University Press}
}
@article{liu2020machine,
  title={Machine learning in materials genome initiative: A review},
  author={Liu, Yingli and Niu, Chen and Wang, Zhuo and Gan, Yong and Zhu, Yan and Sun, Shuhong and Shen, Tao},
  journal={Journal of Materials Science \& Technology},
  volume={57},
  pages={113--122},
  year={2020},
  publisher={Elsevier}
}

@article{wei2019machine,
  title={Machine learning in materials science},
  author={Wei, Jing and Chu, Xuan and Sun, Xiang-Yu and Xu, Kun and Deng, Hui-Xiong and Chen, Jigen and Wei, Zhongming and Lei, Ming},
  journal={InfoMat},
  volume={1},
  number={3},
  pages={338--358},
  year={2019},
  publisher={Wiley Online Library}
}
@article{mueller2016machine,
  title={Machine learning in materials science: Recent progress and emerging applications},
  author={Mueller, Tim and Kusne, Aaron Gilad and Ramprasad, Rampi},
  journal={Reviews in Computational Chemistry},
  volume={29},
  pages={186--273},
  year={2016},
  publisher={Wiley Hoboken, NJ}
}
@article{schmidt2019recent,
  title={Recent advances and applications of machine learning in solid-state materials science},
  author={Schmidt, Jonathan and Marques, M{\'a}rio RG and Botti, Silvana and Marques, Miguel AL},
  journal={npj Computational Materials},
  volume={5},
  number={1},
  pages={1--36},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{butler2018machine,
  title={Machine learning for molecular and materials science},
  author={Butler, Keith T and Davies, Daniel W and Cartwright, Hugh and Isayev, Olexandr and Walsh, Aron},
  journal={Nature},
  volume={559},
  number={7715},
  pages={547--555},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{xu2020deep,
  title={Deep dive into machine learning models for protein engineering},
  author={Xu, Yuting and Verma, Deeptak and Sheridan, Robert P and Liaw, Andy and Ma, Junshui and Marshall, Nicholas M and McIntosh, John and Sherer, Edward C and Svetnik, Vladimir and Johnston, Jennifer M},
  journal={Journal of chemical information and modeling},
  volume={60},
  number={6},
  pages={2773--2790},
  year={2020},
  publisher={ACS Publications}
}
@article{schleder2019dft,
  title={From DFT to machine learning: recent approaches to materials science--a review},
  author={Schleder, Gabriel R and Padilha, Antonio CM and Acosta, Carlos Mera and Costa, Marcio and Fazzio, Adalberto},
  journal={Journal of Physics: Materials},
  volume={2},
  number={3},
  pages={032001},
  year={2019},
  publisher={IOP Publishing}
}
@article{agrawal2019deep,
  title={Deep materials informatics: Applications of deep learning in materials science},
  author={Agrawal, Ankit and Choudhary, Alok},
  journal={MRS Communications},
  volume={9},
  number={3},
  pages={779--792},
  year={2019},
  publisher={Cambridge University Press}
}
@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert and others},
  volume={1},
  number={10},
  year={2001},
  publisher={Springer series in statistics New York}
}
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@article{gibney2016google,
  title={Google AI algorithm masters ancient game of Go},
  author={Gibney, Elizabeth},
  journal={Nature News},
  volume={529},
  number={7587},
  pages={445},
  year={2016}
}
@inproceedings{kidger2020universal,
  title={Universal approximation with deep narrow networks},
  author={Kidger, Patrick and Lyons, Terry},
  booktitle={Conference on learning theory},
  pages={2306--2327},
  year={2020},
  organization={PMLR}
}
@book{minsky2017perceptrons,
  title={Perceptrons: An introduction to computational geometry},
  author={Minsky, Marvin and Papert, Seymour A},
  year={2017},
  publisher={MIT press}
}
@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
}

@book{west2001introduction,
  title={Introduction to graph theory},
  author={West, Douglas Brent and others},
  volume={2},
  year={2001},
  publisher={Prentice hall Upper Saddle River}
}
@article{wang2019deep,
  title={Deep graph library: A graph-centric, highly-performant package for graph neural networks},
  author={Wang, Minjie and Zheng, Da and Ye, Zihao and Gan, Quan and Li, Mufei and Song, Xiang and Zhou, Jinjing and Ma, Chao and Yu, Lingfan and Gai, Yu and others},
  journal={arXiv preprint arXiv:1909.01315},
  year={2019}
}
@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}
@article{xu2018powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}
@article{jing2018deep,
  title={Deep learning for drug design: an artificial intelligence paradigm for drug discovery in the big data era},
  author={Jing, Yankang and Bian, Yuemin and Hu, Ziheng and Wang, Lirong and Xie, Xiang-Qun Sean},
  journal={The AAPS journal},
  volume={20},
  number={3},
  pages={1--10},
  year={2018},
  publisher={Springer}
}
@article{chen2017supervised,
  title={Supervised community detection with line graph neural networks},
  author={Chen, Zhengdao and Li, Xiang and Bruna, Joan},
  journal={arXiv preprint arXiv:1705.08415},
  year={2017}
}
@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}
@inproceedings{ramos2017detecting,
  title={Detecting unexpected obstacles for self-driving cars: Fusing deep learning and geometric modeling},
  author={Ramos, Sebastian and Gehrig, Stefan and Pinggera, Peter and Franke, Uwe and Rother, Carsten},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1025--1032},
  year={2017},
  organization={IEEE}
}

@book{buduma2017fundamentals,
  title={Fundamentals of deep learning: Designing next-generation machine intelligence algorithms},
  author={Buduma, Nikhil and Locascio, Nicholas},
  year={2017},
  publisher={" O'Reilly Media, Inc."}
}
@article{faber2017prediction,
  title={Prediction errors of molecular machine learning models lower than hybrid DFT error},
  author={Faber, Felix A and Hutchison, Luke and Huang, Bing and Gilmer, Justin and Schoenholz, Samuel S and Dahl, George E and Vinyals, Oriol and Kearnes, Steven and Riley, Patrick F and Von Lilienfeld, O Anatole},
  journal={Journal of chemical theory and computation},
  volume={13},
  number={11},
  pages={5255--5264},
  year={2017},
  publisher={ACS Publications}
}

@article{liu2019using,
  title={Using a machine learning approach to determine the space group of a structure from the atomic pair distribution function},
  author={Liu, C-H and Tao, Yunzhe and Hsu, Daniel and Du, Qiang and Billinge, Simon JL},
  journal={Acta Crystallographica Section A: Foundations and Advances},
  volume={75},
  number={4},
  pages={633--643},
  year={2019},
  publisher={International Union of Crystallography}
}
@article{isayev2017universal,
  title={Universal fragment descriptors for predicting properties of inorganic crystals},
  author={Isayev, Olexandr and Oses, Corey and Toher, Cormac and Gossett, Eric and Curtarolo, Stefano and Tropsha, Alexander},
  journal={Nature communications},
  volume={8},
  number={1},
  pages={1--12},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{wong2001jcpds,
  title={JCPDS-ICDD research associateship (cooperative program with NBS/NIST)},
  author={Wong-Ng, Winnie and McMurdie, HF and Hubbard, CR and Mighell, Alan D},
  journal={Journal of research of the National Institute of Standards and Technology},
  volume={106},
  number={6},
  pages={1013},
  year={2001},
  publisher={National Institute of Standards and Technology}
}
@inproceedings{russell2005nist,
  title={NIST Computational Chemistry Comparison and Benchmark Database},
  author={Russell Johnson, NIST},
  booktitle={The 4th Joint Meeting of the US Sections of the Combustion Institute},
  year={2005}
}
@article{lopez2016harvard,
  title={The Harvard organic photovoltaic dataset},
  author={Lopez, Steven A and Pyzer-Knapp, Edward O and Simm, Gregor N and Lutzow, Trevor and Li, Kewei and Seress, Laszlo R and Hachmann, Johannes and Aspuru-Guzik, Al{\'a}n},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--7},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{albrecht2017deep,
  title={Deep learning for single-molecule science},
  author={Albrecht, Tim and Slabaugh, Gregory and Alonso, Eduardo and Al-Arif, SM Masudur R},
  journal={Nanotechnology},
  volume={28},
  number={42},
  pages={423001},
  year={2017},
  publisher={IOP Publishing}
}

@article{ge2020deep,
  title={Deep learning analysis on microscopic imaging in materials science},
  author={Ge, M and Su, F and Zhao, Z and Su, D},
  journal={Materials Today Nano},
  volume={11},
  pages={100087},
  year={2020},
  publisher={Elsevier}
}

@article{yang;aca21,
 author = {Long Yang and Elizabeth A. Culbertson and Nancy K. Thomas and Hung T. Vuong and Emil T. S. Kj{\ae}r and Kirsten M. {\O}. Jensen and Matthew G. Tucker and Simon J. L. Billinge},
 doi = {10.1107/S2053273320013066},
 journal = {Acta Crystallogr. A},
 month = {Jan},
 number = {1},
 pages = {2-6},
 title = {A cloud platform for atomic pair distribution function analysis: PDFitc},
 url = {https://journals.iucr.org/a/issues/2021/01/00/ae5091/index.html},
 volume = {77},
 wwwemail = {},
 year = {2021}
}

@article{rakit;jacs20,
author = {Rakita, Yevgeny and O'Nolan, Daniel and McAuliffe, Rebecca and Veith, Gabriel and Chupas, Peter and Billinge, Simon and Chapman, Karena},
 doi = {10.1021/jacs.0c09418},
 journal = {J. Am. Chem. Soc.},
 month = {Nov},
 number = {44},
 optannote = {},
pages = {18758–18762},
 title = {Active Reaction Control of Cu Redox State Based on Real-Time Feedback from {\it in situ} Synchrotron Measurements},
 url = {https://pubs.acs.org/doi/10.1021/jacs.0c09418},
 volume = {142},
 year = {2020}
}

@article{stach;m21,
 author = {Eric A. Stach and Brian DeCost and A. Gilad Kusne and Jason Hattrick-Simpers and Keith A. Brown and Kristofer G. Reyes and Joshua Schrier and \textbf{Simon J. L. Billinge} and Tonio Buonassisi and Ian Foster and Carla P. Gomes and John M. Gregoire and Apurva Mehta and Joseph Montoya and Elsa Olivetti and Chiwoo Park and Eli Rotenberg and Semion K. Saikin and Sylvia Smullin and Valentin Stanev and Benji Maruyama},
 day = {26},
 doi = {10.1016/j.matt.2021.06.036},
 journal = {Matter},
 month = {July},
 number = {},
 pages = {},
title = {Autonomous experimentation systems for materials development: A community perspective},
 url = {https://www.cell.com/matter/fulltext/S2590-2385(21)00306-4},
 volume = {},
 wwwemail = {},
 wwwpub = {},
 year = {2021}
}

@article{rakit;arxiv21,
 author = {Yevgeny Rakita and James L. Hart and Partha Pratim Das and Daniel L. Foley and Stavros Nicolopoulos and Sina Shahrezaei and Suveen Nigel Mathaudhu and Mitra L. Taheri and Simon J. L. Billinge},
 doi = {},
 journal = {arXiv},
 month = {Oct},
 nb = {},
 number = {},
 optnote = {Submitted},
 pages = {},
 title = {Studying Heterogeneities in Local Nanostructure with Scanning Nanostructure Electron Microscopy (SNEM)},
 url = {https://arxiv.org/abs/2110.03589},
 volume = {2110.03589},
 wwwemail = {},
 wwwpub = {},
 year = {2021}
}

@article{liu;jac21,
 author = {Chia-Hao Liu and Christopher J. Wright and Ran Gu and Sasaank Bandi and Allison Wustrow and Paul K. Todd and Daniel O'Nolan and Michelle L. Beauvais and James R. Neilson and Peter J. Chupas and Karena W. Chapman and \textbf{Simon J. L. Billinge}},
 doi = {10.1107/S160057672100265X.},
 facility = {aps, 11idb},
 grant = {efrc18},
 journal = {J. Appl. Crystallogr.},
 month = {may},
 nb = {fy21, typeA},
 number = {3},
 pages = {768-775},
 title = {Validation of non-negative matrix factorization for rapid assessment of large sets of atomic pair-distribution function (PDF) data},
 url = {https://doi.org/10.1107/S160057672100265X},
 volume = {54},
 year = {2021}
}


@misc{erdmann2021deep,
  title={Deep Learning for Physics Research},
  author={Erdmann, Martin and Glombitza, Jonas and Kasieczka, Gregor and Klemradt, Uwe},
  year={2021},
  publisher={World Scientific}
}
@misc{mpcontribs2019,
  author		= "Patrick Huck and Kristin A Persson",
  title			= "MPContribs: user contributed data to the Materials Project database", 
  year			= "2019",
  note			= "\url{https://docs.mpcontribs.org/}"
}

%% Journal article
@article{bib1,
  author		= "Campbell, S. L. and Gear, C. W.",
  title			= "The index of general nonlinear {D}{A}{E}{S}",
  journal		= "Numer. {M}ath.",
  volume		= "72",
  number		= "2",
  pages			= "173--196",
  year			= "1995"
}

%% Journal article with DOI
@article{bib2,
  author		= "Slifka, M. K. and Whitton, J. L.",
  title			= "Clinical implications of dysregulated cytokine production",
  journal		= "J. {M}ol. {M}ed.",
  volume		= "78",
  pages			= "74--80",
  year			= "2000",
  doi			= "10.1007/s001090000086"
}

%% Journal article
@article{bib3,
  author		= "Hamburger, C.",
  title			= "Quasimonotonicity, regularity and duality for nonlinear systems of 
					partial differential equations",
  journal		= "Ann. Mat. Pura. Appl.",
  volume		= "169",
  number		= "2",
  pages			= "321--354",
  year			= "1995"
}

%% book, authored
@book{bib4,
  author		= "Geddes, K. O. and Czapor, S. R. and Labahn, G.",
  title			= "Algorithms for {C}omputer {A}lgebra",
  address		= "Boston",
  publisher		= "Kluwer",
  year			= "1992"
}

%% Item 8. Book, chapter
@incollection{bib5,
  author		= "Broy, M.",
  title			= "Software engineering---from auxiliary to key technologies",
  editor		= "Broy, M. and Denert, E.",
  booktitle		= "Software Pioneers",
  pages			= "10--13",
  address		= "New {Y}ork",
  publisher		= "Springer",
  year			= "1992"
}

%% Book, edited
@book{bib6,
  editor		= "Seymour, R. S.",
  title			= "Conductive {P}olymers",
  address		= "New {Y}ork",
  publisher		= "Plenum",
  year			= "1981"
}

%% Chapter in a book in a series with volume titles
@inproceedings{bib7,
  author		= "Smith, S. E.",
  title			= "Neuromuscular blocking drugs in man",
  editor		= "Zaimis, E.",
  volume		= "42",
  booktitle		= "Neuromuscular junction. {H}andbook of experimental pharmacology",
  pages			= "593--660",
  address		= "Heidelberg",
  publisher		= "Springer",
  year			= "1976"
}

%% Paper presented at a conference
@misc{bib8,
  author		= "Chung, S. T. and Morris, R. L.",
  title			= "Isolation and characterization of plasmid deoxyribonucleic acid from 
					Streptomyces fradiae",
  year			= "1978",
  note			= "Paper presented at the 3rd international symposium on the genetics 
					of industrial microorganisms, University of {W}isconsin, {M}adison, 
					4--9 June 1978"
}

%% Data citation example
@misc{bib9,
  author		= "Hao, Z. and AghaKouchak, A. and Nakhjiri, N. and Farahmand, A.",
  title			= "Global integrated drought monitoring and prediction system (GIDMaPS) data sets", 
  year			= "2014",
  note			= "figshare \url{https://doi.org/10.6084/m9.figshare.853801}"
}

%% Preprint citation example
@misc{bib10, 
  author		= "Babichev, S. A. and Ries, J. and Lvovsky, A. I.",
  title			= "Quantum scissors: teleportation of single-mode optical states by means 
					of a nonlocal single photon", 
  year			= "2002",
  note			= "Preprint at \url{https://arxiv.org/abs/quant-ph/0208066v1}"
}

@article{bib11,
  author		= "Beneke, M. and Buchalla, G. and Dunietz, I.",
  title			= "Mixing induced {CP} asymmetries in inclusive {B} decays",
  journal		= "Phys. {L}ett.",
  volume		= "B393",
  year			= "1997",
  pages			= "132-142",
  archivePrefix		= "arXiv",
  eprint		= "0707.3168",
  primaryClass		= "gr-gc"
}

@softmisc{bib12,
  author		= "Stahl, B.",
  title			= "deep{SIP}: deep learning of {S}upernova {I}a {P}arameters",
  version		= "0.42",
  keywords		= "Software",
  howpublished		= "Astrophysics {S}ource {C}ode {L}ibrary",
  year			= "2020",
  month			= "Jun",
  eid			= "ascl:2006.023",
  pages			= "ascl:2006.023",
  archivePrefix		= "ascl",
  eprint		= "2006.023",
  adsurl		= "{https://ui.adsabs.harvard.edu/abs/2020ascl.soft06023S}",
  adsnote		= "Provided by the SAO/NASA Astrophysics Data System"
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{Ovchinnikov2020,
  doi = {10.1186/s40679-020-00070-x},
  url = {https://doi.org/10.1186/s40679-020-00070-x},
  year = {2020},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {6},
  number = {1},
  author = {Oleg S. Ovchinnikov and Andrew O'Hara and Stephen Jesse and Bethany M. Hudak and Shi-Ze Yang and Andrew R. Lupini and Matthew F. Chisholm and Wu Zhou and Sergei V. Kalinin and Albina Y. Borisevich and Sokrates T. Pantelides},
  title = {Detection of defects in atomic-resolution images of materials using cycle analysis},
  journal = {Advanced Structural and Chemical Imaging}
}
@article{vonChamier2021,
  doi = {10.1038/s41467-021-22518-0},
  url = {https://doi.org/10.1038/s41467-021-22518-0},
  year = {2021},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {12},
  number = {1},
  author = {Lucas von Chamier and Romain F. Laine and Johanna Jukkala and Christoph Spahn and Daniel Krentzel and Elias Nehme and Martina Lerche and Sara Hern{\'{a}}ndez-P{\'{e}}rez and Pieta K. Mattila and Eleni Karinou and S{\'{e}}amus Holden and Ahmet Can Solak and Alexander Krull and Tim-Oliver Buchholz and Martin L. Jones and Loïc A. Royer and Christophe Leterrier and Yoav Shechtman and Florian Jug and Mike Heilemann and Guillaume Jacquemet and Ricardo Henriques},
  title = {Democratising deep learning for microscopy with {ZeroCostDL}4Mic},
  journal = {Nature Communications}
}
@misc{goetz2021,
      title={Addressing materials' microstructure diversity using transfer learning}, 
      author={Aurèle Goetz and Ali Riza Durmaz and Martin Müller and Akhil Thomas and Dominik Britz and Pierre Kerfriden and Chris Eberl},
      year={2021},
      eprint={2107.13841},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci}
}

@article{Hsu2020,
  doi = {10.1007/s11837-020-04484-y},
  url = {https://doi.org/10.1007/s11837-020-04484-y},
  year = {2020},
  month = dec,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {73},
  number = {1},
  pages = {90--102},
  author = {Tim Hsu and William K. Epting and Hokon Kim and Harry W. Abernathy and Gregory A. Hackett and Anthony D. Rollett and Paul A. Salvador and Elizabeth A. Holm},
  title = {Microstructure Generation via Generative Adversarial Network for Heterogeneous,  Topologically Complex 3D Materials},
  journal = {{JOM}}
}

@article{Cohn2021,
  doi = {10.1007/s11837-021-04713-y},
  url = {https://doi.org/10.1007/s11837-021-04713-y},
  year = {2021},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {73},
  number = {7},
  pages = {2159--2172},
  author = {Ryan Cohn and Iver Anderson and Tim Prost and Jordan Tiarks and Emma White and Elizabeth Holm},
  title = {Instance Segmentation for Direct Measurements of Satellites in Metal Powders and Automated Microstructural Characterization from Image Data},
  journal = {{JOM}}
}

@article{Holm2020overview,
  doi = {10.1007/s11661-020-06008-4},
  url = {https://doi.org/10.1007/s11661-020-06008-4},
  year = {2020},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {51},
  number = {12},
  pages = {5985--5999},
  author = {Elizabeth A. Holm and Ryan Cohn and Nan Gao and Andrew R. Kitahara and Thomas P. Matson and Bo Lei and Srujana Rao Yarasi},
  title = {Overview: Computer Vision and Machine Learning for Microstructural Characterization and Analysis},
  journal = {Metallurgical and Materials Transactions A}
}
@article{stan2020optimizing,
  title={Optimizing convolutional neural networks to perform semantic segmentation on large materials imaging datasets: X-ray tomography and serial sectioning},
  author={Stan, Tiberiu and Thompson, Zachary T and Voorhees, Peter W},
  journal={Materials Characterization},
  volume={160},
  pages={110119},
  year={2020},
  publisher={Elsevier}
}
@article{Kautz2020,
  doi = {10.1016/j.matchar.2020.110379},
  url = {https://doi.org/10.1016/j.matchar.2020.110379},
  year = {2020},
  month = aug,
  publisher = {Elsevier {BV}},
  volume = {166},
  pages = {110379},
  author = {Elizabeth Kautz and Wufei Ma and Saumyadeep Jana and Arun Devaraj and Vineet Joshi and B\"{u}lent Yener and Daniel Lewis},
  title = {An image-driven machine learning approach to kinetic modeling of a discontinuous precipitation reaction},
  journal = {Materials Characterization}
}
@article{Long2021,
  doi = {10.1038/s41524-021-00526-4},
  url = {https://doi.org/10.1038/s41524-021-00526-4},
  year = {2021},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {7},
  number = {1},
  author = {Teng Long and Nuno M. Fortunato and Ingo Opahle and Yixuan Zhang and Ilias Samathrakis and Chen Shen and Oliver Gutfleisch and Hongbin Zhang},
  title = {Constrained crystals deep convolutional generative adversarial network for the inverse design of crystal structures},
  journal = {npj Computational Materials}
}
@article{DBLP:journals/corr/abs-1810-11203,
  author    = {Asma Nouira and
               Jean{-}Claude Crivello and
               Nataliya Sokolovska},
  title     = {CrystalGAN: Learning to Discover Crystallographic Structures with
               Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1810.11203},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.11203},
  eprinttype = {arXiv},
  eprint    = {1810.11203},
  timestamp = {Wed, 31 Oct 2018 14:24:29 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-11203.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Kitahara2018,
  doi = {10.1007/s40192-018-0116-9},
  url = {https://doi.org/10.1007/s40192-018-0116-9},
  year = {2018},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {7},
  number = {3},
  pages = {148--156},
  author = {Andrew R. Kitahara and Elizabeth A. Holm},
  title = {Microstructure Cluster Analysis with Transfer Learning and Unsupervised Learning},
  journal = {Integrating Materials and Manufacturing Innovation}
}

@article{Ko2021,
  doi = {10.1038/s41467-020-20427-2},
  url = {https://doi.org/10.1038/s41467-020-20427-2},
  year = {2021},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {12},
  number = {1},
  author = {Tsz Wai Ko and Jonas A. Finkler and Stefan Goedecker and J\"{o}rg Behler},
  title = {A fourth-generation high-dimensional neural network potential with accurate electrostatics including non-local charge transfer},
  journal = {Nature Communications}
}

@article{Jha2018,
  doi = {10.1017/s1431927618015131},
  url = {https://doi.org/10.1017/s1431927618015131},
  year = {2018},
  month = oct,
  publisher = {Cambridge University Press ({CUP})},
  volume = {24},
  number = {5},
  pages = {497--502},
  author = {Dipendra Jha and Saransh Singh and Reda Al-Bahrani and Wei-keng Liao and Alok Choudhary and Marc De Graef and Ankit Agrawal},
  title = {Extracting Grain Orientations from {EBSD} Patterns of Polycrystalline Materials Using Convolutional Neural Networks},
  journal = {Microscopy and Microanalysis}
}

%%============================================================================%%
%% while using chicago reference style, both abbreviated and expanded form of %%
%% author name format is acceptable. Refer below example for expanded form    %%
%%============================================================================%%

%%  author		= "{Cameron, Deborah}", - single author
%%  author		= "{Saito, Yukio} and {Hyuga, Hiroyuki}", - double author 

%%======================================%%
%% Example for author names with suffix %%
%%======================================%%

%%  author		= "{Price, R. A. Jr} and {Curry, N. {III}} and McCann, K. E. and 
%%					Fielding, J. L. and {Abercrombie, E. Jr}",

@article{Ede2020,
abstract = {Compressed sensing algorithms are used to decrease electron microscope scan time and electron beam exposure with minimal information loss. Following successful applications of deep learning to compressed sensing, we have developed a two-stage multiscale generative adversarial neural network to complete realistic 512 × 512 scanning transmission electron micrographs from spiral, jittered gridlike, and other partial scans. For spiral scans and mean squared error based pre-training, this enables electron beam coverage to be decreased by 17.9× with a 3.8% test set root mean squared intensity error, and by 87.0× with a 6.2% error. Our generator networks are trained on partial scans created from a new dataset of 16227 scanning transmission electron micrographs. High performance is achieved with adaptive learning rate clipping of loss spikes and an auxiliary trainer network. Our source code, new dataset, and pre-trained models are publicly available.},
annote = {reduce scan time in situ},
author = {Ede, Jeffrey M. and Beanland, Richard},
doi = {10.1038/s41598-020-65261-0},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ede, Beanland - 2020 - Partial Scanning Transmission Electron Microscopy with Deep Learning.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Imaging techniques,Microscopy,Scientific data},
mendeley-groups = {npj review paper articles},
month = may,
number = {1},
pages = {1--10},
publisher = {Nature Publishing Group},
title = {{Partial Scanning Transmission Electron Microscopy with Deep Learning}},
url = {https://www.nature.com/articles/s41598-020-65261-0},
volume = {10},
year = {2020}
}

@article{Song2013,
abstract = {Automatic recognition method for hot-rolled steel strip surface defects is important to the steel surface inspection system. In order to improve the recognition rate, a new, simple, yet robust feature descriptor against noise named the adjacent evaluation completed local binary patterns (AECLBPs) is proposed for defect recognition. In the proposed approach, an adjacent evaluation window which is around the neighbor is constructed to modify the threshold scheme of the completed local binary pattern (CLBP). Experimental results demonstrate that the proposed approach presents the performance of defect recognition under the influence of the feature variations of the intra-class changes, the illumination and grayscale changes. Even in the toughest situation with additive Gaussian noise, the AECLBP can still achieve the moderate recognition accuracy. In addition, the strategy of using adjacent evaluation window can also be used in other methods of local binary pattern (LBP) variants.},
author = {Song, Kechen and Yan, Yunhui},
doi = {10.1016/J.APSUSC.2013.09.002},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Yan - 2013 - A noise robust method based on completed local binary patterns for hot-rolled steel strip surface defects.pdf:pdf},
issn = {0169-4332},
journal = {Applied Surface Science},
mendeley-groups = {Thesis},
month = nov,
pages = {858--864},
publisher = {North-Holland},
title = {{A noise robust method based on completed local binary patterns for hot-rolled steel strip surface defects}},
url = {https://www.sciencedirect.com/science/article/pii/S0169433213016437},
volume = {285},
year = {2013}
}


@article{Ziletti2018,
abstract = {Computational methods that automatically extract knowledge from data are critical for enabling data-driven materials science. A reliable identification of lattice symmetry is a crucial first step for materials characterization and analytics. Current methods require a user-specified threshold, and are unable to detect average symmetries for defective structures. Here, we propose a machine learning-based approach to automatically classify structures by crystal symmetry. First, we represent crystals by calculating a diffraction image, then construct a deep learning neural network model for classification. Our approach is able to correctly classify a dataset comprising more than 100,000 simulated crystal structures, including heavily defective ones. The internal operations of the neural network are unraveled through attentive response maps, demonstrating that it uses the same landmarks a materials scientist would use, although never explicitly instructed to do so. Our study paves the way for crystal structure recognition of - possibly noisy and incomplete - three-dimensional structural data in big-data materials science.},
archivePrefix = {arXiv},
arxivId = {1709.02298},
author = {Ziletti, Angelo and Kumar, Devinder and Scheffler, Matthias and Ghiringhelli, Luca M.},
doi = {10.1038/s41467-018-05169-6},
eprint = {1709.02298},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ziletti et al. - 2018 - Insightful classification of crystal structures using deep learning.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
mendeley-groups = {Thesis,Computer Vision in Materials Science},
month = {dec},
number = {1},
publisher = {Nature Publishing Group},
title = {{Insightful classification of crystal structures using deep learning}},
volume = {9},
year = {2018}
}

@article{Russakovsky2015,
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge(2).pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
mendeley-groups = {RPE/Computer Vision,Thesis},
month = dec,
number = {3},
pages = {211--252},
publisher = {Springer New York LLC},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
volume = {115},
year = {2015}
}

@article{Eppel2020,
abstract = {This work presents a machine learning approach for the computer vision-based recognition of materials inside vessels in the chemistry lab and other settings. In addition, we release a data set asso...},
author = {Eppel, Sagi and Xu, Haoping and Bismuth, Mor and Aspuru-Guzik, Alan},
doi = {10.1021/ACSCENTSCI.0C00460},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eppel et al. - 2020 - Computer Vision for Recognition of Materials and Vessels in Chemistry Lab Settings and the Vector-LabPics Data Set.pdf:pdf},
journal = {ACS Central Science},
mendeley-groups = {npj review paper articles},
month = oct,
number = {10},
pages = {1743--1752},
publisher = {American Chemical Society},
title = {{Computer Vision for Recognition of Materials and Vessels in Chemistry Lab Settings and the Vector-LabPics Data Set}},
url = {https://pubs.acs.org/doi/full/10.1021/acscentsci.0c00460},
volume = {6},
year = {2020}
}

@article{Taller2021,
abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS143192762101076X/resource/name/firstPage-S143192762101076Xa.jpg},
author = {Taller, Stephen and Scime, Luke and Terrani, Kurt},
doi = {10.1017/S143192762101076X},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taller, Scime, Terrani - 2021 - Utilizing a Dynamic Segmentation Convolutional Neural Network for Microstructure Analysis of Additively.pdf:pdf},
issn = {1431-9276},
journal = {Microscopy and Microanalysis},
mendeley-groups = {npj review paper articles},
month = aug,
number = {S1},
pages = {3110--3112},
publisher = {Cambridge University Press},
title = {{Utilizing a Dynamic Segmentation Convolutional Neural Network for Microstructure Analysis of Additively Manufactured Superalloy 718}},
url = {https://www.cambridge.org/core/journals/microscopy-and-microanalysis/article/utilizing-a-dynamic-segmentation-convolutional-neural-network-for-microstructure-analysis-of-additively-manufactured-superalloy-718/6AE14D9B000351E5C4FB8D8C3A9256EF},
volume = {27},
year = {2021}
}

@article{LiW2018,
abstract = {Electron microscopy and defect analysis are a cornerstone of materials science, as they offer detailed insights on the microstructure and performance of a wide range of materials and material systems. Building a robust and flexible platform for automated defect recognition and classification in electron microscopy will result in the completion of analysis orders of magnitude faster after images are recorded, or even online during image acquisition. Automated analysis has the potential to be significantly more efficient, accurate, and repeatable than human analysis, and it can scale with the increasingly important methods of automated data generation. Herein, an automated recognition tool is developed based on a computer vison-based approach; it sequentially applies a cascade object detector, convolutional neural network, and local image analysis methods. We demonstrate that the automated tool performs as well as or better than manual human detection in terms of recall and precision and achieves quantitative image/defect analysis metrics close to the human average. The proposed approach works for images of varying contrast, brightness, and magnification. These promising results suggest that this and similar approaches are worth exploring for detecting multiple defect types and have the potential to locate, classify, and measure quantitative features for a range of defect types, materials, and electron microscopic techniques.},
annote = {Network does detection and then uses watershed in each bounding box to detect the loop defects.

Table 1- comparison of human segmentation to neural net segmentation},
author = {Li, Wei and Field, Kevin G. and Morgan, Dane},
doi = {10.1038/s41524-018-0093-8},
file = {:home/ryan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Field, Morgan - 2018 - Automated defect analysis in electron microscopic images.pdf:pdf},
issn = {20573960},
journal = {npj Computational Materials},
keywords = {Characterization and analytical techniques,Microscopy},
mendeley-groups = {npj review paper articles,Thesis},
month = dec,
number = {1},
pages = {1--9},
publisher = {Nature Publishing Group},
title = {{Automated defect analysis in electron microscopic images}},
volume = {4},
year = {2018}
}

@article{osti_1779073,
abstract = {This dataset contains layer-wise powder bed images from three different powder bed printing technologies {\^{a}} laser powder bed fusion, electron beam powder bed fusion, and binder jetting. This dataset was collected and annotated using the internally-developed Peregrine software tool and is designed primarily to facilitate research into anomaly defect detection using image segmentation or similar techniques. A total of 20 layers are provided for each printing technology, with each layer of data consisting of one or more calibrated images and an annotation file containing pixel-wise ground truth labels. The ground truths were labeled by domain experts, typically printer technicians. Data in this release were collected at Oak Ridge National Laboratory between 2016 and 2020 and were compiled in March 2021.},
author = {Scime, Luke and Paquit, Vincent and Joslin, Chase and Richardson, Dylan and Goldsby, Desarae and Lowe, Larry},
doi = {10.13139/ORNLNCCS/1779073},
keywords = {image segmentation,in-situ process monitoring,machine learning,materials science,mathematics and computing,powder bed additive manufacturing},
mendeley-groups = {npj review paper articles},
month = apr,
publisher = {Oak Ridge National Laboratory},
title = {{Layer-wise Imaging Dataset from Powder Bed Additive Manufacturing Processes for Machine Learning Applications (Peregrine v2021-03)}},
url = {https://doi.ccs.ornl.gov/ui/doi/341},
year = {2021}
}

@article{Ede2020db,
abstract = {Compressed sensing algorithms are used to decrease electron microscope scan time and electron beam exposure with minimal information loss. Following successful applications of deep learning to compressed sensing, we have developed a two-stage multiscale generative adversarial neural network to complete realistic 512 × 512 scanning transmission electron micrographs from spiral, jittered gridlike, and other partial scans. For spiral scans and mean squared error based pre-training, this enables electron beam coverage to be decreased by 17.9× with a 3.8{\%} test set root mean squared intensity error, and by 87.0× with a 6.2{\%} error. Our generator networks are trained on partial scans created from a new dataset of 16227 scanning transmission electron micrographs. High performance is achieved with adaptive learning rate clipping of loss spikes and an auxiliary trainer network. Our source code, new dataset, and pre-trained models are publicly available.},
annote = {reduce scan time in situ},
author = {Ede, Jeffrey M. and Beanland, Richard},
doi = {10.1038/s41598-020-65261-0},
file = {:home/ryan/Documents/Mendeley Desktop/Ede, Beanland - 2020 - Partial Scanning Transmission Electron Microscopy with Deep Learning.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Imaging techniques,Microscopy,Scientific data},
mendeley-groups = {npj review paper articles},
month = may,
number = {1},
pages = {1--10},
publisher = {Nature Publishing Group},
title = {{Partial Scanning Transmission Electron Microscopy with Deep Learning}},
url = {https://www.nature.com/articles/s41598-020-65261-0},
volume = {10},
year = {2020}
}

@article{Scime2020,
abstract = {Increasing industry acceptance of powder bed metal Additive Manufacturing requires improved real-time detection and classification of anomalies. Many of these anomalies, such as recoater blade impacts, binder deposition issues, spatter generation, and some porosities, are surface-visible at each layer of the building process. In this work, the authors present a novel Convolutional Neural Network architecture for pixel-wise localization (semantic segmentation) of layer-wise powder bed imaging data. Key advantages of the algorithm include its ability to return segmentation results at the native resolution of the imaging sensor, seamlessly transfer learned knowledge between different Additive Manufacturing machines, and provide real-time performance. The algorithm is demonstrated on six different machines spanning three technologies: laser fusion, binder jetting, and electron beam fusion. Finally, the performance of the algorithm is shown to be superior to that of previous algorithms presented by the authors with respect to localization, accuracy, computation time, and generalizability.},
author = {Scime, Luke and Siddel, Derek and Baird, Seth and Paquit, Vincent},
doi = {10.1016/J.ADDMA.2020.101453},
file = {:home/ryan/Documents/Mendeley Desktop/Scime et al. - 2020 - Layer-wise anomaly detection and classification for powder bed additive manufacturing processes A machine-agnostic.pdf:pdf},
issn = {2214-8604},
journal = {Additive Manufacturing},
keywords = {Additive manufacturing,Convolutional neural network,In-situ anomaly detection,Machine learning,Semantic segmentation},
mendeley-groups = {npj review paper articles},
month = dec,
pages = {101453},
publisher = {Elsevier},
title = {{Layer-wise anomaly detection and classification for powder bed additive manufacturing processes: A machine-agnostic algorithm for real-time pixel-wise semantic segmentation}},
volume = {36},
year = {2020}
}

@article{Varela2005,
abstract = {In the nanoscience era, the properties of many exciting new materials and devices will depend on the details of their composition down to the level of single atoms. Thus the characterization of the structure and electronic properties of matter at the atomic scale is becoming ever more vital for economic and technological as well as for scientific reasons. The combination of atomic-resolution Z-contrast scanning transmission electron microscopy (STEM) and electron energy loss spectroscopy (EELS) represents a powerful method to link the atomic and electronic structure to macroscopic properties, allowing materials, nanoscale systems, and interfaces to be probed in unprecedented detail. Z-contrast STEM uses electrons that have been scattered to large angles for imaging. The relative intensity of each atomic column is roughly proportional to Z 2, where Z is the atomic number. Recent developments in correcting the aberrations of the lenses in the electron microscope have pushed the achievable spatial resolution and the sensitivity for imaging and spectroscopy in the STEM into the sub-{\AA}ngstrom (sub-{\AA}) regime, providing a new level of insight into the structure/property relations of complex materials. Images acquired with an aberration-corrected instrument show greatly improved contrast. The signal-to-noise ratio is sufficiently high to allow sensitivity even to single atoms in both imaging and spectroscopy. This is a key achievement because the detection and measurement of the response of individual atoms has become a challenging issue to provide new insight into many fields, such as catalysis, ceramic materials, complex oxide interfaces, or grain boundaries. In this article, the state-of-the-art for the characterization of all of these different types of materials by means of aberration-corrected STEM and EELS are reviewed. Copyright {\textcopyright} 2005 by Annual Reviews. All rights reserved.},
author = {Varela, M. and Lupini, A. R. and {Van Benthem}, K. and Borisevich, A. Y. and Chisholm, M. F. and Shibata, N. and Abe, E. and Pennycook, S. J.},
doi = {10.1146/annurev.matsci.35.102103.090513},
file = {:home/ryan/Documents/Mendeley Desktop/Varela et al. - 2005 - MATERIALS CHARACTERIZATION IN THE ABERRATION-CORRECTED SCANNING TRANSMISSION ELECTRON MICROSCOPE.pdf:pdf},
issn = {15317331},
journal = {Annual Review of Materials Research},
keywords = {Catalysis,Complex oxides,Electron energy loss spectroscopy,Nanotechnology,Semiconductors,Z-contrast microscopy},
month = jun,
pages = {539--569},
publisher = {Annual Reviews},
title = {{Materials characterization in the aberration-corrected scanning transmission electron microscope}},
url = {https://www.annualreviews.org/doi/abs/10.1146/annurev.matsci.35.102103.090513},
volume = {35},
year = {2005}
}

@article{Larmuseau2020,
abstract = {The microstructure of a material, typically characterized through a set of microscopy images of two-dimensional cross-sections, is a valuable source of information about the material and its properties. Every pixel of the image is a degree of freedom causing the dimensionality of the information space to be extremely high. This makes it difficult to recognize and extract all relevant information from the images. Human experts circumvent this by manually creating a lower-dimensional representation of the microstructure. However, the question of how a microstructure image can be best represented remains open. From the field of deep learning, we present triplet networks as a method to build highly compact representations of the microstructure, condensing the relevant information into a much smaller number of dimensions. We demonstrate that these representations can be created even with a limited amount of example images, and that they are able to distinguish between visually very similar microstructures. We discuss the interpretability and generalization of the representations. Having compact microstructure representations, it becomes easier to establish processing–structure–property links that are key to rational materials design.},
author = {Larmuseau, Michiel and Sluydts, Michael and Theuwissen, Koenraad and Duprez, Lode and Dhaene, Tom and Cottenier, Stefaan},
doi = {10.1038/s41524-020-00423-2},
file = {:home/ryan/Documents/Mendeley Desktop/Larmuseau et al. - 2020 - Compact representations of microstructure images using triplet networks.pdf:pdf},
issn = {2057-3960},
journal = {npj Computational Materials 2020 6:1},
keywords = {Computational methods,Metals and alloys},
mendeley-groups = {npj review paper articles},
month = oct,
number = {1},
pages = {1--11},
publisher = {Nature Publishing Group},
title = {{Compact representations of microstructure images using triplet networks}},
url = {https://www.nature.com/articles/s41524-020-00423-2},
volume = {6},
year = {2020}
}

@article{Sardeshmukh2020,
abstract = {Obtaining a good statistical representation of material microstructures is crucial for establishing robust process–structure–property linkages and machine learning techniques can bridge this gap. One major difficulty in leveraging recent advances in deep learning for this purpose is the scarcity of good quality data with enough metadata. In machine learning, similarity metric learning using Siamese networks has been used to deal with sparse data. Inspired by this, the authors propose a Siamese architecture to learn microstructure representations. The authors show that analysis tasks such as the classification of microstructures can be done more efficiently in the learned representation space.},
author = {Sardeshmukh, Avadhut and Reddy, Sreedhar and Gautham, B. P. and Bhattacharyya, Pushpak},
doi = {10.1557/MRC.2020.55},
issn = {2159-6867},
journal = {MRS Communications 2020 10:4},
keywords = {Biomaterials,Characterization and Evaluation of Materials,Materials Engineering,Materials Science,Nanotechnology,Polymer Sciences,general},
mendeley-groups = {npj review paper articles},
month = {dec},
number = {4},
pages = {613--619},
publisher = {Springer},
title = {{Microstructure representation learning using Siamese networks}},
url = {https://link.springer.com/article/10.1557/mrc.2020.55},
volume = {10},
year = {2020}
}


@article{Chun2020,
abstract = {The sensitivity of heterogeneous energetic (HE) materials (propellants, explosives, and pyrotechnics) is critically dependent on their microstructure. Initiation of chemical reactions occurs at hot spots due to energy localization at sites of porosities and other defects. Emerging multi-scale predictive models of HE response to loads account for the physics at the meso-scale, i.e. at the scale of statistically representative clusters of particles and other features in the microstructure. Meso-scale physics is infused in machine-learned closure models informed by resolved meso-scale simulations. Since microstructures are stochastic, ensembles of meso-scale simulations are required to quantify hot spot ignition and growth and to develop models for microstructure-dependent energy deposition rates. We propose utilizing generative adversarial networks (GAN) to spawn ensembles of synthetic heterogeneous energetic material microstructures. The method generates qualitatively and quantitatively realistic microstructures by learning from images of HE microstructures. We show that the proposed GAN method also permits the generation of new morphologies, where the porosity distribution can be controlled and spatially manipulated. Such control paves the way for the design of novel microstructures to engineer HE materials for targeted performance in a materials-by-design framework.},
author = {Chun, Sehyun and Roy, Sidhartha and Nguyen, Yen Thi and Choi, Joseph B. and Udaykumar, H. S. and Baek, Stephen S.},
doi = {10.1038/s41598-020-70149-0},
file = {:home/ryan/Documents/Mendeley Desktop/Chun et al. - 2020 - Deep learning for synthetic microstructure generation in a materials-by-design framework for heterogeneous energeti.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports 2020 10:1},
keywords = {Computational methods,Design,Mechanical engineering,synthesis and processing},
month = aug,
number = {1},
pages = {1--15},
publisher = {Nature Publishing Group},
title = {{Deep learning for synthetic microstructure generation in a materials-by-design framework for heterogeneous energetic materials}},
url = {https://www.nature.com/articles/s41598-020-70149-0},
volume = {10},
year = {2020}
}
